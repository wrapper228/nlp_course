{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HmsFABwClrsS"
   },
   "source": [
    "## Seminar and homework (10 points total)\n",
    "\n",
    "Today we shall compose encoder-decoder neural networks and apply them to the task of machine translation.\n",
    "\n",
    "![img](https://esciencegroup.files.wordpress.com/2016/03/seq2seq.jpg)\n",
    "_(img: esciencegroup.files.wordpress.com)_\n",
    "\n",
    "\n",
    "Encoder-decoder architectures are about converting anything to anything, including\n",
    " * Machine translation and spoken dialogue systems\n",
    " * [Image captioning](http://mscoco.org/dataset/#captions-challenge2015) and [image2latex](https://openai.com/requests-for-research/#im2latex) (convolutional encoder, recurrent decoder)\n",
    " * Generating [images by captions](https://arxiv.org/abs/1511.02793) (recurrent encoder, convolutional decoder)\n",
    " * Grapheme2phoneme - convert words to transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4N9AD2dlrsU"
   },
   "source": [
    "## Our task: machine translation\n",
    "\n",
    "We gonna try our encoder-decoder models on russian to english machine translation problem. More specifically, we'll translate hotel and hostel descriptions. This task shows the scale of machine translation while not requiring you to train your model for weeks if you don't use GPU.\n",
    "\n",
    "Before we get to the architecture, there's some preprocessing to be done. ~~Go tokenize~~ Alright, this time we've done preprocessing for you. As usual, the data will be tokenized with WordPunctTokenizer.\n",
    "\n",
    "However, there's one more thing to do. Our data lines contain unique rare words. If we operate on a word level, we will have to deal with large vocabulary size. If instead we use character-level models, it would take lots of iterations to process a sequence. This time we're gonna pick something inbetween.\n",
    "\n",
    "One popular approach is called [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt) aka __BPE__. The algorithm starts with a character-level tokenization and then iteratively merges most frequent pairs for N iterations. This results in frequent words being merged into a single token and rare words split into syllables or even characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CfvojjHQlrsU"
   },
   "outputs": [],
   "source": [
    "# !pip install torch>=1.3.0\n",
    "# !pip install subword-nmt\n",
    "# !python -m wget https://www.dropbox.com/s/yy2zqh34dyhv07i/data.txt?dl=1 -o data.txt\n",
    "# !python -m wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/2020/week04_seq2seq/vocab.py -o vocab.py\n",
    "# thanks to tilda and deephack teams for the data, Dmitry Emelyanenko for the code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9kP0SdxlrsY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:07<00:00, 1079.88it/s]\n",
      "100%|██████████| 8000/8000 [00:07<00:00, 1024.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "tokenizer = WordPunctTokenizer()\n",
    "def tokenize(x):\n",
    "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
    "\n",
    "# split and tokenize the data\n",
    "with open('train.en', 'w', encoding=\"utf-8\") as f_src,  open('train.ru', 'w', encoding=\"utf-8\") as f_dst:\n",
    "    for line in open('data.txt', encoding=\"utf-8\"):\n",
    "        src_line, dst_line = line.strip().split('\\t')\n",
    "        f_src.write(tokenize(src_line) + '\\n')\n",
    "        f_dst.write(tokenize(dst_line) + '\\n')\n",
    "\n",
    "# build and apply bpe vocs\n",
    "bpe = {}\n",
    "for lang in ['en', 'ru']:\n",
    "    learn_bpe(open('./train.' + lang, encoding=\"utf-8\"), open('bpe_rules.' + lang, 'w', encoding=\"utf-8\"), num_symbols=8000)\n",
    "    bpe[lang] = BPE(open('./bpe_rules.' + lang, encoding=\"utf-8\"))\n",
    "    \n",
    "    with open('train.bpe.' + lang, 'w', encoding=\"utf-8\") as f_out:\n",
    "        for line in open('train.' + lang, encoding=\"utf-8\"):\n",
    "            f_out.write(bpe[lang].process_line(line.strip()) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0UPW3sV8lrsb"
   },
   "source": [
    "### Building vocabularies\n",
    "\n",
    "We now need to build vocabularies that map strings to token ids and vice versa. We're gonna need these fellas when we feed training data into model or convert output matrices into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmTy_m_olrsb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PskgBSxlrsd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp: на территории обустроена бесплатная частная парковка .\n",
      "out: free private parking is available on site .\n",
      "\n",
      "inp: кроме того , в 5 минутах ходьбы работают многочисленные бары и рестораны .\n",
      "out: guests can find many bars and restaurants within a 5 - minute walk .\n",
      "\n",
      "inp: отель san mi@@ gu@@ el расположен в центре мор@@ ели@@ и , в 750 метрах от главной площади города и кафедрального собора .\n",
      "out: hotel san miguel is located in central more@@ lia , 750 metres from the city ’ s main square and cathedral .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_inp = np.array(open('./train.bpe.ru', encoding=\"utf-8\").read().split('\\n'))\n",
    "data_out = np.array(open('./train.bpe.en', encoding=\"utf-8\").read().split('\\n'))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inp, dev_inp, train_out, dev_out = train_test_split(data_inp, data_out, test_size=3000,\n",
    "                                                          random_state=42)\n",
    "for i in range(3):\n",
    "    print('inp:', train_inp[i])\n",
    "    print('out:', train_out[i], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vipg4O61lrsg"
   },
   "outputs": [],
   "source": [
    "from vocab import Vocab\n",
    "inp_voc = Vocab.from_lines(train_inp)\n",
    "out_voc = Vocab.from_lines(train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwOoHfuhlrsi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n",
      "\n",
      "words to ids (0 = bos, 1 = eos):\n",
      "tensor([[   0, 2688, 2943, 1108,   29,    1,    1,    1],\n",
      "        [   0, 2922, 1834, 8035,   59, 3800,   29,    1],\n",
      "        [   0, 6030, 2083,   29,    1,    1,    1,    1],\n",
      "        [   0, 4927, 1870,   29,    1,    1,    1,    1],\n",
      "        [   0, 5549, 1453,   27,  592,   29,    1,    1]])\n",
      "\n",
      "back to words\n",
      "['гостевой дом r .', 'до афин — 20 км .', 'работает боулинг .', 'оборудован балкон .', 'подключен wi - fi .']\n"
     ]
    }
   ],
   "source": [
    "# Here's how you cast lines into ids and backwards.\n",
    "batch_lines = sorted(train_inp, key=len)[5:10]\n",
    "batch_ids = inp_voc.to_matrix(batch_lines)\n",
    "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
    "\n",
    "print(\"lines\")\n",
    "print(batch_lines)\n",
    "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
    "print(batch_ids)\n",
    "print(\"\\nback to words\")\n",
    "print(batch_lines_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSYu-MkElrsk"
   },
   "source": [
    "Draw source and translation length distributions to estimate the scope of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLLl9cSNlrsl"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(map(len, map(str.split, train_inp))), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(map(len, map(str.split, train_out))), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHWgx34flrsn"
   },
   "source": [
    "### Encoder-decoder model\n",
    "\n",
    "The code below contains a template for a simple encoder-decoder model: single GRU encoder/decoder, no attention or anything. This model is implemented for you as a reference and a baseline for your homework assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pd_rDRm9lrso"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgfN5-F7lrst"
   },
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    def __init__(self, inp_voc, out_voc, emb_size=64, hid_size=128):\n",
    "        \"\"\"\n",
    "        A simple encoder-decoder seq2seq model\n",
    "        \"\"\"\n",
    "        super().__init__() # initialize base class to track sub-layers, parameters, etc.\n",
    "\n",
    "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
    "        self.hid_size = hid_size\n",
    "        \n",
    "        self.emb_inp = nn.Embedding(len(inp_voc), emb_size)\n",
    "        self.emb_out = nn.Embedding(len(out_voc), emb_size)\n",
    "        self.enc0 = nn.GRU(emb_size, hid_size, batch_first=True)\n",
    "\n",
    "        self.dec_start = nn.Linear(hid_size, hid_size)\n",
    "        self.dec0 = nn.GRUCell(emb_size, hid_size)\n",
    "        self.logits = nn.Linear(hid_size, len(out_voc))\n",
    "        \n",
    "    def forward(self, inp, out):\n",
    "        \"\"\" Apply model in training mode \"\"\"\n",
    "        initial_state = self.encode(inp)\n",
    "        return self.decode(initial_state, out)\n",
    "\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Takes symbolic input sequence, computes initial state\n",
    "        :param inp: matrix of input tokens [batch, time]\n",
    "        :returns: initial decoder state tensors, one or many\n",
    "        \"\"\"\n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        batch_size = inp.shape[0]\n",
    "        \n",
    "        enc_seq, [last_state_but_not_really] = self.enc0(inp_emb)\n",
    "        # enc_seq: [batch, time, hid_size], last_state: [batch, hid_size]\n",
    "        \n",
    "        # note: last_state is not _actually_ last because of padding, let's find the real last_state\n",
    "        lengths = (inp != self.inp_voc.eos_ix).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 1)\n",
    "        last_state = enc_seq[torch.arange(len(enc_seq)), lengths]\n",
    "        # ^-- shape: [batch_size, hid_size]\n",
    "        \n",
    "        dec_start = self.dec_start(last_state)\n",
    "        return [dec_start]\n",
    "\n",
    "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Takes previous decoder state and tokens, returns new state and logits for next tokens\n",
    "        :param prev_state: a list of previous decoder state tensors, same as returned by encode(...)\n",
    "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
    "        :return: a list of next decoder state tensors, a tensor of logits [batch, len(out_voc)]\n",
    "        \"\"\"\n",
    "        prev_gru0_state = prev_state[0]\n",
    "        \n",
    "        prev_embs = self.emb_out(prev_tokens)\n",
    "        \n",
    "        new_dec_state = self.dec0(prev_embs, prev_gru0_state) # токен, стейт\n",
    "        output_logits = self.logits(new_dec_state)\n",
    "         \n",
    "        return [new_dec_state], output_logits\n",
    "\n",
    "    def decode(self, initial_state, out_tokens, **flags):\n",
    "        \"\"\" Iterate over reference tokens (out_tokens) with decode_step \"\"\"\n",
    "        batch_size = out_tokens.shape[0]\n",
    "        state = initial_state\n",
    "        \n",
    "        # initial logits: always predict BOS\n",
    "        onehot_bos = F.one_hot(torch.full([batch_size], self.out_voc.bos_ix, dtype=torch.int64),\n",
    "                               num_classes=len(self.out_voc)).to(device=out_tokens.device)\n",
    "        first_logits = torch.log(onehot_bos.to(torch.float32) + 1e-9)\n",
    "        \n",
    "        logits_sequence = [first_logits]\n",
    "        for i in range(out_tokens.shape[1] - 1):\n",
    "            state, logits = self.decode_step(state, out_tokens[:, i]) # модель обучилась круто, если logits похожи на out_tokens[:, i+1]\n",
    "            logits_sequence.append(logits)\n",
    "        return torch.stack(logits_sequence, dim=1)\n",
    "\n",
    "    def decode_inference(self, initial_state, max_len=100, **flags):\n",
    "        \"\"\" Generate translations from model (greedy version) \"\"\"\n",
    "        batch_size, device = len(initial_state[0]), initial_state[0].device\n",
    "        state = initial_state\n",
    "        outputs = [torch.full([batch_size], self.out_voc.bos_ix, dtype=torch.int64, \n",
    "                              device=device)]\n",
    "        all_states = [initial_state]\n",
    "\n",
    "        for i in range(max_len):\n",
    "            state, logits = self.decode_step(state, outputs[-1])\n",
    "            outputs.append(logits.argmax(dim=-1))\n",
    "            all_states.append(state)\n",
    "        \n",
    "        return torch.stack(outputs, dim=1), all_states\n",
    "\n",
    "    def translate_lines(self, inp_lines, **kwargs):\n",
    "        inp = self.inp_voc.to_matrix(inp_lines).to(device)\n",
    "        initial_state = self.encode(inp)\n",
    "        out_ids, states = self.decode_inference(initial_state, **kwargs)\n",
    "        return self.out_voc.to_lines(out_ids.cpu().numpy()), states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging area\n",
    "model = BasicModel(inp_voc, out_voc).to(device)\n",
    "\n",
    "dummy_inp_tokens = inp_voc.to_matrix(sorted(train_inp, key=len)[5:10]).to(device)\n",
    "dummy_out_tokens = out_voc.to_matrix(sorted(train_out, key=len)[5:10]).to(device)\n",
    "\n",
    "h0 = model.encode(dummy_inp_tokens)\n",
    "h1, logits1 = model.decode_step(h0, torch.arange(len(dummy_inp_tokens), device=device))\n",
    "\n",
    "assert isinstance(h1, list) and len(h1) == len(h0)\n",
    "assert h1[0].shape == h0[0].shape and not torch.allclose(h1[0], h0[0])\n",
    "assert logits1.shape == (len(dummy_inp_tokens), len(out_voc))\n",
    "\n",
    "logits_seq = model.decode(h0, dummy_out_tokens)\n",
    "assert logits_seq.shape == (dummy_out_tokens.shape[0], dummy_out_tokens.shape[1], len(out_voc))\n",
    "\n",
    "# full forward\n",
    "logits_seq2 = model(dummy_inp_tokens, dummy_out_tokens)\n",
    "assert logits_seq2.shape == logits_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translations without training:\n",
      "libr@@ falcone polish silver méri@@ after@@ que@@ acre wu@@ ho@@ fier elena decor@@ running clean vegetarian impres@@ ye@@ monit@@ john@@ reen walesa beat@@ bre mosa\n",
      "including glaz@@ 95 colo aç@@ usian cell@@ trail center standing nel nel ío sø@@ elephant flower sseldorf imp@@ units flamen@@ moskovsky augu@@ gest '@@ ey\n",
      "including glaz@@ 95 colo aç@@ usian cell@@ trail center standing nel nel ío sø@@ elephant flower sseldorf imp@@ units flamen@@ moskovsky augu@@ gest '@@ ey\n"
     ]
    }
   ],
   "source": [
    "dummy_translations, dummy_states = model.translate_lines(train_inp[:3], max_len=25)\n",
    "print(\"Translations without training:\")\n",
    "print('\\n'.join([line for line in dummy_translations]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wuv1-aVlrs0"
   },
   "source": [
    "### Training loss (2 points)\n",
    "\n",
    "Our training objective is almost the same as it was for neural language models:\n",
    "$$ L = {\\frac1{|D|}} \\sum_{X, Y \\in D} \\sum_{y_t \\in Y} - \\log p(y_t \\mid y_1, \\dots, y_{t-1}, X, \\theta) $$\n",
    "\n",
    "where $|D|$ is the __total length of all sequences__, including BOS and first EOS, but excluding PAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8XPV8sWlrs5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_loss(model, inp, out, **flags):\n",
    "    \"\"\"\n",
    "    Compute loss (float32 scalar) as in the formula above\n",
    "    :param inp: input tokens matrix, int32[batch, time]\n",
    "    :param out: reference tokens matrix, int32[batch, time]\n",
    "    \n",
    "    In order to pass the tests, your function should\n",
    "    * include loss at first EOS but not the subsequent ones\n",
    "    * divide sum of losses by a sum of input lengths (use voc.compute_mask)\n",
    "    \"\"\"\n",
    "    mask = model.out_voc.compute_mask(out) # [batch_size, out_len]\n",
    "    targets_1hot = F.one_hot(out, len(model.out_voc)).to(torch.float32)\n",
    "    \n",
    "    # outputs of the model, [batch_size, out_len, num_tokens]\n",
    "    h0 = model.encode(inp)\n",
    "    logits_seq = model.decode(h0, out)\n",
    "    \n",
    "    print(logits_seq.shape)\n",
    "    print(out.shape)\n",
    "    print(targets_1hot.shape)\n",
    "\n",
    "    # log-probabilities of all tokens at all steps, [batch_size, out_len, num_tokens]\n",
    "#     logprobs_seq = <YOUR CODE HERE>\n",
    "   \n",
    "    # log-probabilities of correct outputs, [batch_size, out_len]\n",
    "#     logp_out = (logprobs_seq * targets_1hot).sum(dim=-1)\n",
    "    # ^-- this will select the probability of the actual next token.\n",
    "    # Note: you can compute loss more efficiently using using F.cross_entropy ВОТ ИМЕННО, ЗАЧЕМ ЭТИ ЛОГПРОБС ДРОЧИТЬ\n",
    "    \n",
    "#     loss = F.cross_entropy(logits_seq[:, :-1].transpose(-1, -2), out[:, 1:], reduction=\"none\") # я всё еще не понимаю почему я из 3x14x136 должен делать 3x136x14\n",
    "    \n",
    "#     masked_loss = loss * mask[:, 1:]\n",
    "    \n",
    "#     nonzero_mask = masked_loss != 0\n",
    "#     masked_loss_mean = (masked_loss * nonzero_mask).sum() / nonzero_mask.sum()\n",
    "    \n",
    "#     # average cross-entropy over tokens where mask == True\n",
    "#     return masked_loss_mean # average loss, scalar\n",
    "\n",
    "# так. это не сработало, хотя должно было. предикты вида batchs X seq_len X num_of_tokens мэтчатся с таргетами вида batchs X seq_len. Но оно говорит что посчитался плохой лосс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, inp, out, **flags):\n",
    "    \"\"\"\n",
    "    Compute loss (float32 scalar) as in the formula above\n",
    "    :param inp: input tokens matrix, int32[batch, time]\n",
    "    :param out: reference tokens matrix, int32[batch, time]\n",
    "    \n",
    "    In order to pass the tests, your function should\n",
    "    * include loss at first EOS but not the subsequent ones\n",
    "    * divide sum of losses by a sum of input lengths (use voc.compute_mask)\n",
    "    \"\"\"\n",
    "    mask = model.out_voc.compute_mask(out)\n",
    "    targets_1hot = F.one_hot(out, len(model.out_voc)).to(torch.float32)\n",
    "\n",
    "    h0 = model.encode(inp)\n",
    "    logits_seq = model.decode(h0, out)\n",
    "    \n",
    "    loss = F.cross_entropy(logits_seq.transpose(-1, -2), out, reduction=\"none\")\n",
    "    \n",
    "    masked_loss = loss * mask\n",
    "    nonzero_mask = masked_loss != 0\n",
    "    masked_loss_mean = (masked_loss * nonzero_mask).sum() / nonzero_mask.sum()\n",
    "    \n",
    "    return masked_loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ME_LWUeklrs7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(7.5059, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_loss = compute_loss(model, dummy_inp_tokens, dummy_out_tokens)\n",
    "print(\"Loss:\", dummy_loss)\n",
    "assert np.allclose(dummy_loss.item(), 7.5, rtol=0.1, atol=0.1), \"We're sorry for your loss\"\n",
    "\n",
    "# test autograd\n",
    "dummy_loss.backward()\n",
    "for name, param in model.named_parameters():\n",
    "    assert param.grad is not None and abs(param.grad.max()) != 0, f\"Param {name} received no gradients\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpbaBpW7lrs-"
   },
   "source": [
    "### Evaluation: BLEU\n",
    "\n",
    "Machine translation is commonly evaluated with [BLEU](https://en.wikipedia.org/wiki/BLEU) score. This metric simply computes which fraction of predicted n-grams is actually present in the reference translation. It does so for n=1,2,3 and 4 and computes the geometric average with penalty if translation is shorter than reference.\n",
    "\n",
    "While BLEU [has many drawbacks](http://www.cs.jhu.edu/~ccb/publications/re-evaluating-the-role-of-bleu-in-mt-research.pdf), it still remains the most commonly used metric and one of the simplest to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gb1-PhKIlrs-"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "def compute_bleu(model, inp_lines, out_lines, bpe_sep='@@ ', **flags):\n",
    "    \"\"\"\n",
    "    Estimates corpora-level BLEU score of model's translations given inp and reference out\n",
    "    Note: if you're serious about reporting your results, use https://pypi.org/project/sacrebleu\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "        translations = [line.replace(bpe_sep, '') for line in translations]\n",
    "        actual = [line.replace(bpe_sep, '') for line in out_lines]\n",
    "        return corpus_bleu(\n",
    "            [[ref.split()] for ref in actual],\n",
    "            [trans.split() for trans in translations],\n",
    "            smoothing_function=lambda precisions, **kw: [p + 1.0 / p.denominator for p in precisions]\n",
    "            ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZvfid1RlrtA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001927761221667042"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu(model, dev_inp, dev_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQDhGwg4lrtC"
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Training encoder-decoder models isn't that different from any other models: sample batches, compute loss, backprop and update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yfwIaixHlrtI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "metrics = {'train_loss': [], 'dev_bleu': [] }\n",
    "\n",
    "model = BasicModel(inp_voc, out_voc).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlDT6eDUlrtL",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss=1.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [4:36:28<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(25000):\n",
    "    step = len(metrics['train_loss']) + 1\n",
    "    batch_ix = np.random.randint(len(train_inp), size=batch_size)\n",
    "    batch_inp = inp_voc.to_matrix(train_inp[batch_ix]).to(device)\n",
    "    batch_out = out_voc.to_matrix(train_out[batch_ix]).to(device)\n",
    "    \n",
    "    loss_t = compute_loss(model, batch_inp, batch_out)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss_t.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    metrics['train_loss'].append((step, loss_t.item()))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        metrics['dev_bleu'].append((step, compute_bleu(model, dev_inp, dev_out)))\n",
    "        \n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,4))\n",
    "        for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "            plt.subplot(1, len(metrics), i + 1)\n",
    "            plt.title(name)\n",
    "            plt.plot(*zip(*history))\n",
    "            plt.grid()\n",
    "        plt.show()\n",
    "        print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0)[1], flush=True)\n",
    "        \n",
    "# Note: it's okay if bleu oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ahuhKVhlrtP"
   },
   "outputs": [],
   "source": [
    "assert np.mean(metrics['dev_bleu'][-10:], axis=0)[1] > 15, \"We kind of need a higher bleu BLEU from you. Kind of right now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyaHOpealrtS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в распоряжении гостей общая кухня и общая гостиная .\n",
      "guests can make use of the shared kitchen and a shared kitchen .\n",
      "\n",
      "кроме того , предоставляется прокат велосипедов , услуги трансфера и бесплатная парковка .\n",
      "car hire , car rental , laundry services and free parking are also available .\n",
      "\n",
      "расстояние до города ки@@ сси@@ м@@ ми составляет 26 км .\n",
      "the scenic town of chi@@ anti is 26 km away .\n",
      "\n",
      "апартаменты в пент@@ хаусе с общим открытым бассейном , садом , кондиционером и террасой для загара расположены в 5 минутах ходьбы от пляжа на курорте ка@@ бо - рой .\n",
      "located in a quiet area , a 5 - minute walk from the beach , the black sea garden is a 5 - minute walk from the beach and the black sea .\n",
      "\n",
      "апартаменты mo@@ s@@ co@@ w point - loft red square находятся в москве , в 200 метрах от большого театра .\n",
      "a 200 metres from the black sea embankment in prague .\n",
      "\n",
      "в вашем распоряжении собственная ванная комната с душем и полотенцами .\n",
      "featuring a shower , private bathrooms also come with towels .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inp_line, trans_line in zip(dev_inp[::500], model.translate_lines(dev_inp[::500])[0]):\n",
    "    print(inp_line)\n",
    "    print(trans_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"saved25kmodel\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tv0s8qxOXp5y"
   },
   "source": [
    "# Homework code templates will appear here soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edk_oVg0lrtW"
   },
   "source": [
    "### Your Attention Required\n",
    "\n",
    "In this section we want you to improve over the basic model by implementing a simple attention mechanism.\n",
    "\n",
    "This is gonna be a two-parter: building the __attention layer__ and using it for an __attentive seq2seq model__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qz9aROAIlrtX"
   },
   "source": [
    "### Attention layer (3 points)\n",
    "\n",
    "Here you will have to implement a layer that computes a simple additive attention:\n",
    "\n",
    "Given encoder sequence $ h^e_0, h^e_1, h^e_2, ..., h^e_T$ and a single decoder state $h^d$,\n",
    "\n",
    "* Compute logits with a 2-layer neural network\n",
    "$$a_t = linear_{out}(tanh(linear_{e}(h^e_t) + linear_{d}(h_d)))$$\n",
    "* Get probabilities from logits, \n",
    "$$ p_t = {{e ^ {a_t}} \\over { \\sum_\\tau e^{a_\\tau} }} $$\n",
    "\n",
    "* Add up encoder states with probabilities to get __attention response__\n",
    "$$ attn = \\sum_t p_t \\cdot h^e_t $$\n",
    "\n",
    "You can learn more about attention layers in the lecture slides or [from this post](https://distill.pub/2016/augmented-rnns/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, name, enc_size, dec_size, hid_size, activ=torch.tanh):\n",
    "        \"\"\" A layer that computes additive attention response and weights \"\"\"\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.enc_size = enc_size # num units in encoder state\n",
    "        self.dec_size = dec_size # num units in decoder state\n",
    "        \n",
    "        assert self.enc_size == self.dec_size # как бы костыль,но дальнейшая модель подразумевает что hid_size это один параметр и для enc, и для dec \n",
    "                                              # для отладки работы слоя можно убрать\n",
    "        \n",
    "        self.hid_size = hid_size # attention layer hidden units\n",
    "        self.dimension_of_score = 1 # размерность a_t - [batch_size, n_inp, 1], типа, а как иначе ставить \n",
    "                                    # в соответствие каждому batch_i, token_j какой-то скор? только сжимая hid_size до 1.\n",
    "        self.activ = activ       # attention layer hidden nonlinearity\n",
    "        \n",
    "        # create trainable paramteres like this:\n",
    "        self.linear_ht_enc = nn.Linear(self.enc_size, hid_size)\n",
    "        self.linear_hd_dec = nn.Linear(self.dec_size, hid_size)\n",
    "\n",
    "        self.at = nn.Linear(hid_size, self.dimension_of_score)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1) # софтмаксим [batch_size, n_inp, 1] по второму измерению: \"количество токенов в предложении\"\n",
    "\n",
    "    def forward(self, enc, dec, inp_mask):\n",
    "        \"\"\"\n",
    "        Computes attention response and weights\n",
    "        :param enc: encoder activation sequence, float32[batch_size, ninp, enc_size]\n",
    "        :param dec: single decoder state used as \"query\", float32[batch_size, dec_size]\n",
    "        :param inp_mask: mask on enc activatons (0 after first eos), float32 [batch_size, ninp]\n",
    "        :returns: attn[batch_size, enc_size], probs[batch_size, ninp]\n",
    "            - attn - attention response vector (weighted sum of enc)\n",
    "            - probs - attention weights after softmax\n",
    "        \"\"\"\n",
    "#         print(inp_mask)\n",
    "        dec = dec[:, None, :]\n",
    "        \n",
    "        # Compute logits\n",
    "        at = self.at(self.activ(self.linear_ht_enc(enc) + self.linear_hd_dec(dec))) # [batch_size, n_inp, 1]\n",
    "#         print(at.shape)\n",
    "\n",
    "        # Apply mask - if mask is 0, logits should be -inf or -1e9\n",
    "        # You may need torch.where\n",
    "        print(\"че происходит в AttentionLayer: at до применения маски:\")\n",
    "        print(at.type())\n",
    "        print(at)\n",
    "        at[~inp_mask] = float('-inf')\n",
    "        print(\"после применения:\")\n",
    "        print(at.type())\n",
    "        print(at)\n",
    "        \n",
    "        # Compute attention probabilities (softmax)\n",
    "        probs = self.softmax(at)\n",
    "#         print(probs.shape)\n",
    "        \n",
    "        # Compute attention response using enc and probs\n",
    "#         print((probs * enc).shape)\n",
    "        attn_response = (probs * enc).sum(dim=1) # enc были [batch_size, ninp, enc_size], attn_response теперь [batch_size, enc_size]\n",
    "#         print(attn_response.shape)\n",
    "        \n",
    "        return attn_response, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "как работает функция рассчёта a_t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "n_inp = 15\n",
    "enc_size = 128\n",
    "\n",
    "hid_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_e = torch.rand(batch_size, n_inp, enc_size)\n",
    "\n",
    "h_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first term:  torch.Size([8, 15, 16])\n"
     ]
    }
   ],
   "source": [
    "linear_h_enc = nn.Linear(enc_size, hid_size)\n",
    "\n",
    "h_e = linear_h_enc(h_e)\n",
    "\n",
    "print(\"first term: \", h_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_d = torch.rand(batch_size, 1, dec_size)\n",
    "\n",
    "h_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second term:  torch.Size([8, 1, 16])\n"
     ]
    }
   ],
   "source": [
    "linear_h_dec = nn.Linear(dec_size, hid_size)\n",
    "\n",
    "h_d = linear_h_dec(h_d)\n",
    "\n",
    "print(\"second term: \", h_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ну и как их сложить? бродкастинг - если тензоры отличаются только в одной размерности и у одного из слагаемых она - единица, то пайторч осилит складывание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h_e + h_d).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IalfpdAelrtb"
   },
   "source": [
    "### Seq2seq model with attention (3 points)\n",
    "\n",
    "You can now use the attention layer to build a network. The simplest way to implement attention is to use it in decoder phase:\n",
    "![img](https://i.imgur.com/6fKHlHb.png)\n",
    "_image from distill.pub [article](https://distill.pub/2016/augmented-rnns/)_\n",
    "\n",
    "On every step, use __previous__ decoder state to obtain attention response. Then feed concat this response to the inputs of next attention layer.\n",
    "\n",
    "The key implementation detail here is __model state__. Put simply, you can add any tensor into the list of `encode` outputs. You will then have access to them at each `decode` step. This may include:\n",
    "* Last RNN hidden states (as in basic model)\n",
    "* The whole sequence of encoder outputs (to attend to) and mask\n",
    "* Attention probabilities (to visualize)\n",
    "\n",
    "_There are, of course, alternative ways to wire attention into your network and different kinds of attention. Take a look at [this](https://arxiv.org/abs/1609.08144), [this](https://arxiv.org/abs/1706.03762) and [this](https://arxiv.org/abs/1808.03867) for ideas. And for image captioning/im2latex there's [visual attention](https://arxiv.org/abs/1502.03044)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCKPB5JmcE6j"
   },
   "outputs": [],
   "source": [
    "class AttentiveModel(BasicModel):\n",
    "    def __init__(self, name, inp_voc, out_voc,\n",
    "                 emb_size=4, hid_size=8, attn_size=8):\n",
    "        \"\"\" Translation model that uses attention. See instructions above. \"\"\"\n",
    "        nn.Module.__init__(self)  # initialize base class to track sub-layers, trainable variables, etc.\n",
    "        self.inp_voc, self.out_voc = inp_voc, out_voc\n",
    "        self.hid_size = hid_size\n",
    "        \n",
    "        self.emb_inp = nn.Embedding(len(inp_voc), emb_size)\n",
    "        self.enc0 = nn.GRU(emb_size, hid_size, batch_first=True)\n",
    "\n",
    "        self.dec_start = nn.Linear(hid_size, hid_size)\n",
    "        self.emb_out = nn.Embedding(len(out_voc), emb_size)\n",
    "        self.dec0 = nn.GRUCell(emb_size + attn_size, hid_size)\n",
    "        self.attn = AttentionLayer(\"attention\", hid_size, hid_size, attn_size)\n",
    "        \n",
    "        self.logits = nn.Linear(hid_size, len(out_voc))\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Takes symbolic input sequence, computes initial state\n",
    "        :param inp: matrix of input tokens [batch, time]\n",
    "        :return: a list of initial decoder state tensors\n",
    "        \"\"\"\n",
    "        \n",
    "        # encode input sequence, create initial decoder states\n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        batch_size = inp.shape[0]\n",
    "        \n",
    "        enc_seq, [last_state_but_not_really] = self.enc0(inp_emb)\n",
    "        \n",
    "        lengths = (inp != self.inp_voc.eos_ix).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 1)\n",
    "        last_state = enc_seq[torch.arange(len(enc_seq)), lengths]\n",
    "        \n",
    "#         dec_start = self.dec_start(last_state)\n",
    "        dec_start = self.dec_start(torch.zeros(batch_size, self.hid_size))\n",
    "        \n",
    "        # apply attention layer from initial decoder hidden state\n",
    "        mask = model.out_voc.compute_mask(inp)\n",
    "        print(\"вот в AttentiveModel сделали mask. Она выглядит так:\")\n",
    "        print(mask.type())\n",
    "        print(mask)\n",
    "        attn_response, first_attn_probas = self.attn(enc_seq, dec_start, mask)\n",
    "        \n",
    "        # Build first state: include\n",
    "        # * initial states for decoder recurrent layers\n",
    "        # * encoder sequence and encoder attn mask (for attention)\n",
    "        # * make sure that last state item is attention probabilities tensor\n",
    "        \n",
    "        first_state = [dec_start, enc_seq, mask, attn_response, first_attn_probas]\n",
    "        return first_state\n",
    "   \n",
    "    def decode_step(self, prev_state, prev_tokens, **flags):\n",
    "        \"\"\"\n",
    "        Takes previous decoder state and tokens, returns new state and logits for next tokens\n",
    "        :param prev_state: a list of previous decoder state tensors\n",
    "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
    "        :return: a list of next decoder state tensors, a tensor of logits [batch, n_tokens]\n",
    "        \"\"\"\n",
    "        prev_embs = self.emb_out(prev_tokens)\n",
    "        \n",
    "        attn_response = prev_state[3]\n",
    "        combined_embs = torch.concat([prev_embs, attn_response], dim=-1)\n",
    "        \n",
    "        prev_gru0_state = prev_state[0]\n",
    "    \n",
    "        new_dec_state = self.dec0(combined_embs, prev_gru0_state) # токен, стейт\n",
    "        output_logits = self.logits(new_dec_state)\n",
    "        \n",
    "        attn_response, attn_probas = self.attn(prev_state[1], new_dec_state, prev_state[2])\n",
    "        new_model_state = [new_dec_state, prev_state[1], prev_state[2],  attn_response, attn_probas]\n",
    "        \n",
    "        return new_model_state, output_logits\n",
    "#         return [new_dec_state, output_logits]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryZCOTEslrtf"
   },
   "source": [
    "### Training attentive model\n",
    "\n",
    "Please reuse the infrastructure you've built for the regular model. I hope you didn't hard-code anything :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "attn_metrics = {'train_loss': [], 'dev_bleu': [] }\n",
    "\n",
    "attn_model = AttentiveModel(\"terminator\", inp_voc, out_voc).to(device)\n",
    "opt = torch.optim.Adam(attn_model.parameters(), lr=1e-3)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот в AttentiveModel сделали mask. Она выглядит так:\n",
      "torch.BoolTensor\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2083],\n",
      "         [0.1061],\n",
      "         [0.1306],\n",
      "         ...,\n",
      "         [0.2238],\n",
      "         [0.2238],\n",
      "         [0.2238]],\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.1270],\n",
      "         [0.1737],\n",
      "         ...,\n",
      "         [0.1587],\n",
      "         [0.1770],\n",
      "         [0.1907]],\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.2201],\n",
      "         [0.2123],\n",
      "         ...,\n",
      "         [0.2238],\n",
      "         [0.2238],\n",
      "         [0.2238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.1270],\n",
      "         [0.1676],\n",
      "         ...,\n",
      "         [0.2237],\n",
      "         [0.2237],\n",
      "         [0.2237]],\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.1290],\n",
      "         [0.1189],\n",
      "         ...,\n",
      "         [0.2238],\n",
      "         [0.2238],\n",
      "         [0.2238]],\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.0895],\n",
      "         [0.1474],\n",
      "         ...,\n",
      "         [0.2238],\n",
      "         [0.2238],\n",
      "         [0.2238]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2083],\n",
      "         [0.1061],\n",
      "         [0.1306],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.1270],\n",
      "         [0.1737],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.2201],\n",
      "         [0.2123],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.1270],\n",
      "         [0.1676],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.1290],\n",
      "         [0.1189],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2083],\n",
      "         [0.0895],\n",
      "         [0.1474],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1289],\n",
      "         [0.0273],\n",
      "         [0.0532],\n",
      "         ...,\n",
      "         [0.1459],\n",
      "         [0.1459],\n",
      "         [0.1459]],\n",
      "\n",
      "        [[0.1530],\n",
      "         [0.0702],\n",
      "         [0.1176],\n",
      "         ...,\n",
      "         [0.1033],\n",
      "         [0.1220],\n",
      "         [0.1361]],\n",
      "\n",
      "        [[0.1484],\n",
      "         [0.1596],\n",
      "         [0.1514],\n",
      "         ...,\n",
      "         [0.1655],\n",
      "         [0.1655],\n",
      "         [0.1655]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1519],\n",
      "         [0.0692],\n",
      "         [0.1093],\n",
      "         ...,\n",
      "         [0.1691],\n",
      "         [0.1691],\n",
      "         [0.1692]],\n",
      "\n",
      "        [[0.1418],\n",
      "         [0.0633],\n",
      "         [0.0518],\n",
      "         ...,\n",
      "         [0.1588],\n",
      "         [0.1588],\n",
      "         [0.1588]],\n",
      "\n",
      "        [[0.1466],\n",
      "         [0.0263],\n",
      "         [0.0870],\n",
      "         ...,\n",
      "         [0.1636],\n",
      "         [0.1636],\n",
      "         [0.1636]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1289],\n",
      "         [0.0273],\n",
      "         [0.0532],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1530],\n",
      "         [0.0702],\n",
      "         [0.1176],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1484],\n",
      "         [0.1596],\n",
      "         [0.1514],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1519],\n",
      "         [0.0692],\n",
      "         [0.1093],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1418],\n",
      "         [0.0633],\n",
      "         [0.0518],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1466],\n",
      "         [0.0263],\n",
      "         [0.0870],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0980],\n",
      "         [ 0.0022],\n",
      "         [ 0.0308],\n",
      "         ...,\n",
      "         [ 0.1126],\n",
      "         [ 0.1126],\n",
      "         [ 0.1126]],\n",
      "\n",
      "        [[ 0.1345],\n",
      "         [ 0.0523],\n",
      "         [ 0.0996],\n",
      "         ...,\n",
      "         [ 0.0864],\n",
      "         [ 0.1050],\n",
      "         [ 0.1190]],\n",
      "\n",
      "        [[ 0.0755],\n",
      "         [ 0.0913],\n",
      "         [ 0.0848],\n",
      "         ...,\n",
      "         [ 0.0893],\n",
      "         [ 0.0893],\n",
      "         [ 0.0893]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0648],\n",
      "         [-0.0141],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [ 0.0801],\n",
      "         [ 0.0801],\n",
      "         [ 0.0802]],\n",
      "\n",
      "        [[-0.0085],\n",
      "         [-0.0805],\n",
      "         [-0.0935],\n",
      "         ...,\n",
      "         [ 0.0053],\n",
      "         [ 0.0053],\n",
      "         [ 0.0053]],\n",
      "\n",
      "        [[ 0.1468],\n",
      "         [ 0.0278],\n",
      "         [ 0.0842],\n",
      "         ...,\n",
      "         [ 0.1652],\n",
      "         [ 0.1652],\n",
      "         [ 0.1652]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0980],\n",
      "         [ 0.0022],\n",
      "         [ 0.0308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1345],\n",
      "         [ 0.0523],\n",
      "         [ 0.0996],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0755],\n",
      "         [ 0.0913],\n",
      "         [ 0.0848],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0648],\n",
      "         [-0.0141],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0085],\n",
      "         [-0.0805],\n",
      "         [-0.0935],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1468],\n",
      "         [ 0.0278],\n",
      "         [ 0.0842],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1028],\n",
      "         [ 0.0032],\n",
      "         [ 0.0290],\n",
      "         ...,\n",
      "         [ 0.1200],\n",
      "         [ 0.1200],\n",
      "         [ 0.1200]],\n",
      "\n",
      "        [[ 0.1243],\n",
      "         [ 0.0416],\n",
      "         [ 0.0885],\n",
      "         ...,\n",
      "         [ 0.0742],\n",
      "         [ 0.0930],\n",
      "         [ 0.1071]],\n",
      "\n",
      "        [[ 0.0322],\n",
      "         [ 0.0458],\n",
      "         [ 0.0382],\n",
      "         ...,\n",
      "         [ 0.0473],\n",
      "         [ 0.0473],\n",
      "         [ 0.0473]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0093],\n",
      "         [-0.0887],\n",
      "         [-0.0519],\n",
      "         ...,\n",
      "         [ 0.0061],\n",
      "         [ 0.0062],\n",
      "         [ 0.0062]],\n",
      "\n",
      "        [[ 0.0772],\n",
      "         [-0.0043],\n",
      "         [-0.0138],\n",
      "         ...,\n",
      "         [ 0.0957],\n",
      "         [ 0.0957],\n",
      "         [ 0.0957]],\n",
      "\n",
      "        [[ 0.0459],\n",
      "         [-0.0711],\n",
      "         [-0.0121],\n",
      "         ...,\n",
      "         [ 0.0626],\n",
      "         [ 0.0626],\n",
      "         [ 0.0626]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1028],\n",
      "         [ 0.0032],\n",
      "         [ 0.0290],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1243],\n",
      "         [ 0.0416],\n",
      "         [ 0.0885],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0322],\n",
      "         [ 0.0458],\n",
      "         [ 0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0093],\n",
      "         [-0.0887],\n",
      "         [-0.0519],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0772],\n",
      "         [-0.0043],\n",
      "         [-0.0138],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0459],\n",
      "         [-0.0711],\n",
      "         [-0.0121],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1721],\n",
      "         [ 0.0717],\n",
      "         [ 0.0981],\n",
      "         ...,\n",
      "         [ 0.1912],\n",
      "         [ 0.1912],\n",
      "         [ 0.1912]],\n",
      "\n",
      "        [[ 0.0415],\n",
      "         [-0.0395],\n",
      "         [ 0.0062],\n",
      "         ...,\n",
      "         [-0.0071],\n",
      "         [ 0.0111],\n",
      "         [ 0.0248]],\n",
      "\n",
      "        [[-0.0033],\n",
      "         [ 0.0082],\n",
      "         [-0.0003],\n",
      "         ...,\n",
      "         [ 0.0115],\n",
      "         [ 0.0115],\n",
      "         [ 0.0115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0107],\n",
      "         [-0.0886],\n",
      "         [-0.0525],\n",
      "         ...,\n",
      "         [ 0.0002],\n",
      "         [ 0.0003],\n",
      "         [ 0.0003]],\n",
      "\n",
      "        [[ 0.0884],\n",
      "         [ 0.0088],\n",
      "         [-0.0026],\n",
      "         ...,\n",
      "         [ 0.1068],\n",
      "         [ 0.1068],\n",
      "         [ 0.1068]],\n",
      "\n",
      "        [[ 0.0175],\n",
      "         [-0.1000],\n",
      "         [-0.0368],\n",
      "         ...,\n",
      "         [ 0.0323],\n",
      "         [ 0.0323],\n",
      "         [ 0.0323]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1721],\n",
      "         [ 0.0717],\n",
      "         [ 0.0981],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0415],\n",
      "         [-0.0395],\n",
      "         [ 0.0062],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0033],\n",
      "         [ 0.0082],\n",
      "         [-0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0107],\n",
      "         [-0.0886],\n",
      "         [-0.0525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0884],\n",
      "         [ 0.0088],\n",
      "         [-0.0026],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0175],\n",
      "         [-0.1000],\n",
      "         [-0.0368],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.2489],\n",
      "         [ 0.1440],\n",
      "         [ 0.1667],\n",
      "         ...,\n",
      "         [ 0.2705],\n",
      "         [ 0.2705],\n",
      "         [ 0.2705]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.1051],\n",
      "         [-0.0611],\n",
      "         ...,\n",
      "         [-0.0740],\n",
      "         [-0.0564],\n",
      "         [-0.0431]],\n",
      "\n",
      "        [[ 0.1895],\n",
      "         [ 0.2011],\n",
      "         [ 0.1923],\n",
      "         ...,\n",
      "         [ 0.2084],\n",
      "         [ 0.2084],\n",
      "         [ 0.2084]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0623],\n",
      "         [-0.0165],\n",
      "         [ 0.0209],\n",
      "         ...,\n",
      "         [ 0.0784],\n",
      "         [ 0.0784],\n",
      "         [ 0.0784]],\n",
      "\n",
      "        [[ 0.1097],\n",
      "         [ 0.0348],\n",
      "         [ 0.0212],\n",
      "         ...,\n",
      "         [ 0.1270],\n",
      "         [ 0.1270],\n",
      "         [ 0.1270]],\n",
      "\n",
      "        [[ 0.0025],\n",
      "         [-0.1158],\n",
      "         [-0.0496],\n",
      "         ...,\n",
      "         [ 0.0154],\n",
      "         [ 0.0154],\n",
      "         [ 0.0154]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.2489],\n",
      "         [ 0.1440],\n",
      "         [ 0.1667],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.1051],\n",
      "         [-0.0611],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1895],\n",
      "         [ 0.2011],\n",
      "         [ 0.1923],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0623],\n",
      "         [-0.0165],\n",
      "         [ 0.0209],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1097],\n",
      "         [ 0.0348],\n",
      "         [ 0.0212],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0025],\n",
      "         [-0.1158],\n",
      "         [-0.0496],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1841],\n",
      "         [ 0.0798],\n",
      "         [ 0.1035],\n",
      "         ...,\n",
      "         [ 0.2055],\n",
      "         [ 0.2055],\n",
      "         [ 0.2055]],\n",
      "\n",
      "        [[ 0.0073],\n",
      "         [-0.0754],\n",
      "         [-0.0279],\n",
      "         ...,\n",
      "         [-0.0375],\n",
      "         [-0.0191],\n",
      "         [-0.0052]],\n",
      "\n",
      "        [[ 0.1414],\n",
      "         [ 0.1529],\n",
      "         [ 0.1443],\n",
      "         ...,\n",
      "         [ 0.1600],\n",
      "         [ 0.1600],\n",
      "         [ 0.1600]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0879],\n",
      "         [ 0.0063],\n",
      "         [ 0.0454],\n",
      "         ...,\n",
      "         [ 0.1057],\n",
      "         [ 0.1057],\n",
      "         [ 0.1058]],\n",
      "\n",
      "        [[ 0.0813],\n",
      "         [ 0.0111],\n",
      "         [-0.0038],\n",
      "         ...,\n",
      "         [ 0.0964],\n",
      "         [ 0.0964],\n",
      "         [ 0.0964]],\n",
      "\n",
      "        [[ 0.1694],\n",
      "         [ 0.0483],\n",
      "         [ 0.1054],\n",
      "         ...,\n",
      "         [ 0.1885],\n",
      "         [ 0.1885],\n",
      "         [ 0.1885]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1841],\n",
      "         [ 0.0798],\n",
      "         [ 0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0073],\n",
      "         [-0.0754],\n",
      "         [-0.0279],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1414],\n",
      "         [ 0.1529],\n",
      "         [ 0.1443],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0879],\n",
      "         [ 0.0063],\n",
      "         [ 0.0454],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0813],\n",
      "         [ 0.0111],\n",
      "         [-0.0038],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1694],\n",
      "         [ 0.0483],\n",
      "         [ 0.1054],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1264],\n",
      "         [ 0.0253],\n",
      "         [ 0.0506],\n",
      "         ...,\n",
      "         [ 0.1459],\n",
      "         [ 0.1459],\n",
      "         [ 0.1459]],\n",
      "\n",
      "        [[ 0.0366],\n",
      "         [-0.0450],\n",
      "         [ 0.0028],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [ 0.0123],\n",
      "         [ 0.0260]],\n",
      "\n",
      "        [[ 0.1835],\n",
      "         [ 0.1932],\n",
      "         [ 0.1838],\n",
      "         ...,\n",
      "         [ 0.2037],\n",
      "         [ 0.2037],\n",
      "         [ 0.2037]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0666],\n",
      "         [-0.0142],\n",
      "         [ 0.0242],\n",
      "         ...,\n",
      "         [ 0.0834],\n",
      "         [ 0.0835],\n",
      "         [ 0.0835]],\n",
      "\n",
      "        [[-0.0161],\n",
      "         [-0.0843],\n",
      "         [-0.0996],\n",
      "         ...,\n",
      "         [-0.0032],\n",
      "         [-0.0032],\n",
      "         [-0.0032]],\n",
      "\n",
      "        [[ 0.2338],\n",
      "         [ 0.1147],\n",
      "         [ 0.1672],\n",
      "         ...,\n",
      "         [ 0.2548],\n",
      "         [ 0.2548],\n",
      "         [ 0.2548]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1264],\n",
      "         [ 0.0253],\n",
      "         [ 0.0506],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0366],\n",
      "         [-0.0450],\n",
      "         [ 0.0028],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1835],\n",
      "         [ 0.1932],\n",
      "         [ 0.1838],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0666],\n",
      "         [-0.0142],\n",
      "         [ 0.0242],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0161],\n",
      "         [-0.0843],\n",
      "         [-0.0996],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2338],\n",
      "         [ 0.1147],\n",
      "         [ 0.1672],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1084],\n",
      "         [ 0.0078],\n",
      "         [ 0.0337],\n",
      "         ...,\n",
      "         [ 0.1271],\n",
      "         [ 0.1271],\n",
      "         [ 0.1271]],\n",
      "\n",
      "        [[-0.0500],\n",
      "         [-0.1309],\n",
      "         [-0.0844],\n",
      "         ...,\n",
      "         [-0.0926],\n",
      "         [-0.0749],\n",
      "         [-0.0617]],\n",
      "\n",
      "        [[ 0.1652],\n",
      "         [ 0.1773],\n",
      "         [ 0.1695],\n",
      "         ...,\n",
      "         [ 0.1844],\n",
      "         [ 0.1844],\n",
      "         [ 0.1844]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1136],\n",
      "         [ 0.0327],\n",
      "         [ 0.0718],\n",
      "         ...,\n",
      "         [ 0.1302],\n",
      "         [ 0.1302],\n",
      "         [ 0.1302]],\n",
      "\n",
      "        [[ 0.0131],\n",
      "         [-0.0584],\n",
      "         [-0.0730],\n",
      "         ...,\n",
      "         [ 0.0286],\n",
      "         [ 0.0286],\n",
      "         [ 0.0286]],\n",
      "\n",
      "        [[ 0.1380],\n",
      "         [ 0.0165],\n",
      "         [ 0.0776],\n",
      "         ...,\n",
      "         [ 0.1573],\n",
      "         [ 0.1573],\n",
      "         [ 0.1573]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1084],\n",
      "         [ 0.0078],\n",
      "         [ 0.0337],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0500],\n",
      "         [-0.1309],\n",
      "         [-0.0844],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1652],\n",
      "         [ 0.1773],\n",
      "         [ 0.1695],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1136],\n",
      "         [ 0.0327],\n",
      "         [ 0.0718],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0131],\n",
      "         [-0.0584],\n",
      "         [-0.0730],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1380],\n",
      "         [ 0.0165],\n",
      "         [ 0.0776],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0133],\n",
      "         [-0.0798],\n",
      "         [-0.0505],\n",
      "         ...,\n",
      "         [ 0.0257],\n",
      "         [ 0.0257],\n",
      "         [ 0.0257]],\n",
      "\n",
      "        [[-0.0567],\n",
      "         [-0.1371],\n",
      "         [-0.0923],\n",
      "         ...,\n",
      "         [-0.1038],\n",
      "         [-0.0863],\n",
      "         [-0.0731]],\n",
      "\n",
      "        [[ 0.0903],\n",
      "         [ 0.1051],\n",
      "         [ 0.0989],\n",
      "         ...,\n",
      "         [ 0.1059],\n",
      "         [ 0.1059],\n",
      "         [ 0.1059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0215],\n",
      "         [-0.1004],\n",
      "         [-0.0641],\n",
      "         ...,\n",
      "         [-0.0089],\n",
      "         [-0.0089],\n",
      "         [-0.0089]],\n",
      "\n",
      "        [[ 0.0518],\n",
      "         [-0.0292],\n",
      "         [-0.0390],\n",
      "         ...,\n",
      "         [ 0.0718],\n",
      "         [ 0.0718],\n",
      "         [ 0.0718]],\n",
      "\n",
      "        [[ 0.0513],\n",
      "         [-0.0670],\n",
      "         [-0.0025],\n",
      "         ...,\n",
      "         [ 0.0668],\n",
      "         [ 0.0668],\n",
      "         [ 0.0668]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0133],\n",
      "         [-0.0798],\n",
      "         [-0.0505],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0567],\n",
      "         [-0.1371],\n",
      "         [-0.0923],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0903],\n",
      "         [ 0.1051],\n",
      "         [ 0.0989],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0215],\n",
      "         [-0.1004],\n",
      "         [-0.0641],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0518],\n",
      "         [-0.0292],\n",
      "         [-0.0390],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0513],\n",
      "         [-0.0670],\n",
      "         [-0.0025],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0408],\n",
      "         [-0.0531],\n",
      "         [-0.0252],\n",
      "         ...,\n",
      "         [ 0.0543],\n",
      "         [ 0.0543],\n",
      "         [ 0.0543]],\n",
      "\n",
      "        [[ 0.1152],\n",
      "         [ 0.0336],\n",
      "         [ 0.0805],\n",
      "         ...,\n",
      "         [ 0.0675],\n",
      "         [ 0.0862],\n",
      "         [ 0.1002]],\n",
      "\n",
      "        [[ 0.0879],\n",
      "         [ 0.1002],\n",
      "         [ 0.0923],\n",
      "         ...,\n",
      "         [ 0.1052],\n",
      "         [ 0.1052],\n",
      "         [ 0.1052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0762],\n",
      "         [-0.0045],\n",
      "         [ 0.0338],\n",
      "         ...,\n",
      "         [ 0.0927],\n",
      "         [ 0.0927],\n",
      "         [ 0.0927]],\n",
      "\n",
      "        [[ 0.0829],\n",
      "         [ 0.0014],\n",
      "         [-0.0077],\n",
      "         ...,\n",
      "         [ 0.1036],\n",
      "         [ 0.1036],\n",
      "         [ 0.1036]],\n",
      "\n",
      "        [[ 0.0801],\n",
      "         [-0.0385],\n",
      "         [ 0.0274],\n",
      "         ...,\n",
      "         [ 0.0945],\n",
      "         [ 0.0946],\n",
      "         [ 0.0946]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0408],\n",
      "         [-0.0531],\n",
      "         [-0.0252],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1152],\n",
      "         [ 0.0336],\n",
      "         [ 0.0805],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0879],\n",
      "         [ 0.1002],\n",
      "         [ 0.0923],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0762],\n",
      "         [-0.0045],\n",
      "         [ 0.0338],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0829],\n",
      "         [ 0.0014],\n",
      "         [-0.0077],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0801],\n",
      "         [-0.0385],\n",
      "         [ 0.0274],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0459],\n",
      "         [-0.0514],\n",
      "         [-0.0246],\n",
      "         ...,\n",
      "         [ 0.0622],\n",
      "         [ 0.0622],\n",
      "         [ 0.0622]],\n",
      "\n",
      "        [[ 0.1380],\n",
      "         [ 0.0561],\n",
      "         [ 0.1027],\n",
      "         ...,\n",
      "         [ 0.0883],\n",
      "         [ 0.1073],\n",
      "         [ 0.1216]],\n",
      "\n",
      "        [[ 0.1432],\n",
      "         [ 0.1551],\n",
      "         [ 0.1474],\n",
      "         ...,\n",
      "         [ 0.1627],\n",
      "         [ 0.1627],\n",
      "         [ 0.1627]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0065],\n",
      "         [-0.0721],\n",
      "         [-0.0358],\n",
      "         ...,\n",
      "         [ 0.0189],\n",
      "         [ 0.0189],\n",
      "         [ 0.0189]],\n",
      "\n",
      "        [[ 0.0845],\n",
      "         [ 0.0084],\n",
      "         [-0.0038],\n",
      "         ...,\n",
      "         [ 0.1019],\n",
      "         [ 0.1019],\n",
      "         [ 0.1019]],\n",
      "\n",
      "        [[ 0.0278],\n",
      "         [-0.0889],\n",
      "         [-0.0252],\n",
      "         ...,\n",
      "         [ 0.0414],\n",
      "         [ 0.0414],\n",
      "         [ 0.0414]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0459],\n",
      "         [-0.0514],\n",
      "         [-0.0246],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1380],\n",
      "         [ 0.0561],\n",
      "         [ 0.1027],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1432],\n",
      "         [ 0.1551],\n",
      "         [ 0.1474],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0065],\n",
      "         [-0.0721],\n",
      "         [-0.0358],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0845],\n",
      "         [ 0.0084],\n",
      "         [-0.0038],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0278],\n",
      "         [-0.0889],\n",
      "         [-0.0252],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0057],\n",
      "         [-0.0889],\n",
      "         [-0.0609],\n",
      "         ...,\n",
      "         [ 0.0194],\n",
      "         [ 0.0194],\n",
      "         [ 0.0194]],\n",
      "\n",
      "        [[-0.0145],\n",
      "         [-0.0939],\n",
      "         [-0.0503],\n",
      "         ...,\n",
      "         [-0.0646],\n",
      "         [-0.0467],\n",
      "         [-0.0332]],\n",
      "\n",
      "        [[ 0.1178],\n",
      "         [ 0.1290],\n",
      "         [ 0.1206],\n",
      "         ...,\n",
      "         [ 0.1369],\n",
      "         [ 0.1369],\n",
      "         [ 0.1369]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0605],\n",
      "         [-0.0202],\n",
      "         [ 0.0177],\n",
      "         ...,\n",
      "         [ 0.0737],\n",
      "         [ 0.0737],\n",
      "         [ 0.0738]],\n",
      "\n",
      "        [[ 0.1078],\n",
      "         [ 0.0353],\n",
      "         [ 0.0213],\n",
      "         ...,\n",
      "         [ 0.1238],\n",
      "         [ 0.1238],\n",
      "         [ 0.1238]],\n",
      "\n",
      "        [[ 0.0990],\n",
      "         [-0.0190],\n",
      "         [ 0.0419],\n",
      "         ...,\n",
      "         [ 0.1154],\n",
      "         [ 0.1154],\n",
      "         [ 0.1154]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0057],\n",
      "         [-0.0889],\n",
      "         [-0.0609],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0145],\n",
      "         [-0.0939],\n",
      "         [-0.0503],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1178],\n",
      "         [ 0.1290],\n",
      "         [ 0.1206],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0605],\n",
      "         [-0.0202],\n",
      "         [ 0.0177],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1078],\n",
      "         [ 0.0353],\n",
      "         [ 0.0213],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0990],\n",
      "         [-0.0190],\n",
      "         [ 0.0419],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-1.6812e-02],\n",
      "         [-1.0934e-01],\n",
      "         [-8.0337e-02],\n",
      "         ...,\n",
      "         [-5.3598e-03],\n",
      "         [-5.3597e-03],\n",
      "         [-5.3597e-03]],\n",
      "\n",
      "        [[ 1.3963e-01],\n",
      "         [ 5.9639e-02],\n",
      "         [ 1.0678e-01],\n",
      "         ...,\n",
      "         [ 9.5715e-02],\n",
      "         [ 1.1414e-01],\n",
      "         [ 1.2789e-01]],\n",
      "\n",
      "        [[ 4.0725e-02],\n",
      "         [ 5.2795e-02],\n",
      "         [ 4.4579e-02],\n",
      "         ...,\n",
      "         [ 5.5570e-02],\n",
      "         [ 5.5571e-02],\n",
      "         [ 5.5572e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.8689e-02],\n",
      "         [-2.2114e-03],\n",
      "         [ 3.6004e-02],\n",
      "         ...,\n",
      "         [ 9.2767e-02],\n",
      "         [ 9.2808e-02],\n",
      "         [ 9.2836e-02]],\n",
      "\n",
      "        [[ 8.8030e-02],\n",
      "         [ 1.3207e-02],\n",
      "         [-5.6989e-05],\n",
      "         ...,\n",
      "         [ 1.0522e-01],\n",
      "         [ 1.0522e-01],\n",
      "         [ 1.0522e-01]],\n",
      "\n",
      "        [[ 4.4364e-02],\n",
      "         [-7.3589e-02],\n",
      "         [-9.2870e-03],\n",
      "         ...,\n",
      "         [ 5.8757e-02],\n",
      "         [ 5.8762e-02],\n",
      "         [ 5.8765e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-1.6812e-02],\n",
      "         [-1.0934e-01],\n",
      "         [-8.0337e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 1.3963e-01],\n",
      "         [ 5.9639e-02],\n",
      "         [ 1.0678e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 4.0725e-02],\n",
      "         [ 5.2795e-02],\n",
      "         [ 4.4579e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.8689e-02],\n",
      "         [-2.2114e-03],\n",
      "         [ 3.6004e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 8.8030e-02],\n",
      "         [ 1.3207e-02],\n",
      "         [-5.6989e-05],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 4.4364e-02],\n",
      "         [-7.3589e-02],\n",
      "         [-9.2870e-03],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0296],\n",
      "         [-0.1210],\n",
      "         [-0.0913],\n",
      "         ...,\n",
      "         [-0.0195],\n",
      "         [-0.0195],\n",
      "         [-0.0195]],\n",
      "\n",
      "        [[ 0.2180],\n",
      "         [ 0.1387],\n",
      "         [ 0.1853],\n",
      "         ...,\n",
      "         [ 0.1727],\n",
      "         [ 0.1916],\n",
      "         [ 0.2057]],\n",
      "\n",
      "        [[ 0.0730],\n",
      "         [ 0.0855],\n",
      "         [ 0.0775],\n",
      "         ...,\n",
      "         [ 0.0887],\n",
      "         [ 0.0887],\n",
      "         [ 0.0887]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0828],\n",
      "         [ 0.0014],\n",
      "         [ 0.0401],\n",
      "         ...,\n",
      "         [ 0.0993],\n",
      "         [ 0.0994],\n",
      "         [ 0.0994]],\n",
      "\n",
      "        [[ 0.0374],\n",
      "         [-0.0343],\n",
      "         [-0.0484],\n",
      "         ...,\n",
      "         [ 0.0522],\n",
      "         [ 0.0522],\n",
      "         [ 0.0522]],\n",
      "\n",
      "        [[ 0.0448],\n",
      "         [-0.0752],\n",
      "         [-0.0104],\n",
      "         ...,\n",
      "         [ 0.0598],\n",
      "         [ 0.0598],\n",
      "         [ 0.0598]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0296],\n",
      "         [-0.1210],\n",
      "         [-0.0913],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2180],\n",
      "         [ 0.1387],\n",
      "         [ 0.1853],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0730],\n",
      "         [ 0.0855],\n",
      "         [ 0.0775],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0828],\n",
      "         [ 0.0014],\n",
      "         [ 0.0401],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0374],\n",
      "         [-0.0343],\n",
      "         [-0.0484],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0448],\n",
      "         [-0.0752],\n",
      "         [-0.0104],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0370],\n",
      "         [-0.1277],\n",
      "         [-0.0977],\n",
      "         ...,\n",
      "         [-0.0276],\n",
      "         [-0.0276],\n",
      "         [-0.0276]],\n",
      "\n",
      "        [[ 0.1314],\n",
      "         [ 0.0495],\n",
      "         [ 0.0970],\n",
      "         ...,\n",
      "         [ 0.0849],\n",
      "         [ 0.1037],\n",
      "         [ 0.1178]],\n",
      "\n",
      "        [[-0.0043],\n",
      "         [ 0.0114],\n",
      "         [ 0.0053],\n",
      "         ...,\n",
      "         [ 0.0055],\n",
      "         [ 0.0055],\n",
      "         [ 0.0055]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1452],\n",
      "         [ 0.0629],\n",
      "         [ 0.1028],\n",
      "         ...,\n",
      "         [ 0.1643],\n",
      "         [ 0.1643],\n",
      "         [ 0.1643]],\n",
      "\n",
      "        [[ 0.0102],\n",
      "         [-0.0587],\n",
      "         [-0.0737],\n",
      "         ...,\n",
      "         [ 0.0228],\n",
      "         [ 0.0228],\n",
      "         [ 0.0228]],\n",
      "\n",
      "        [[ 0.1843],\n",
      "         [ 0.0630],\n",
      "         [ 0.1195],\n",
      "         ...,\n",
      "         [ 0.2043],\n",
      "         [ 0.2043],\n",
      "         [ 0.2043]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0370],\n",
      "         [-0.1277],\n",
      "         [-0.0977],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1314],\n",
      "         [ 0.0495],\n",
      "         [ 0.0970],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0043],\n",
      "         [ 0.0114],\n",
      "         [ 0.0053],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1452],\n",
      "         [ 0.0629],\n",
      "         [ 0.1028],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0102],\n",
      "         [-0.0587],\n",
      "         [-0.0737],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1843],\n",
      "         [ 0.0630],\n",
      "         [ 0.1195],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.1102e-02],\n",
      "         [-1.3154e-01],\n",
      "         [-1.0132e-01],\n",
      "         ...,\n",
      "         [-3.2078e-02],\n",
      "         [-3.2078e-02],\n",
      "         [-3.2078e-02]],\n",
      "\n",
      "        [[ 6.4507e-02],\n",
      "         [-1.6749e-02],\n",
      "         [ 2.9315e-02],\n",
      "         ...,\n",
      "         [ 1.6182e-02],\n",
      "         [ 3.4598e-02],\n",
      "         [ 4.8475e-02]],\n",
      "\n",
      "        [[-1.4127e-02],\n",
      "         [-6.6034e-05],\n",
      "         [-6.9538e-03],\n",
      "         ...,\n",
      "         [-2.9579e-03],\n",
      "         [-2.9568e-03],\n",
      "         [-2.9560e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3857e-01],\n",
      "         [ 5.7024e-02],\n",
      "         [ 9.6346e-02],\n",
      "         ...,\n",
      "         [ 1.5778e-01],\n",
      "         [ 1.5782e-01],\n",
      "         [ 1.5785e-01]],\n",
      "\n",
      "        [[-4.5573e-03],\n",
      "         [-7.1820e-02],\n",
      "         [-8.7236e-02],\n",
      "         ...,\n",
      "         [ 6.6635e-03],\n",
      "         [ 6.6636e-03],\n",
      "         [ 6.6637e-03]],\n",
      "\n",
      "        [[ 2.3992e-01],\n",
      "         [ 1.2071e-01],\n",
      "         [ 1.7309e-01],\n",
      "         ...,\n",
      "         [ 2.6152e-01],\n",
      "         [ 2.6153e-01],\n",
      "         [ 2.6153e-01]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.1102e-02],\n",
      "         [-1.3154e-01],\n",
      "         [-1.0132e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 6.4507e-02],\n",
      "         [-1.6749e-02],\n",
      "         [ 2.9315e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.4127e-02],\n",
      "         [-6.6034e-05],\n",
      "         [-6.9538e-03],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3857e-01],\n",
      "         [ 5.7024e-02],\n",
      "         [ 9.6346e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-4.5573e-03],\n",
      "         [-7.1820e-02],\n",
      "         [-8.7236e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 2.3992e-01],\n",
      "         [ 1.2071e-01],\n",
      "         [ 1.7309e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0434],\n",
      "         [-0.1337],\n",
      "         [-0.1034],\n",
      "         ...,\n",
      "         [-0.0346],\n",
      "         [-0.0346],\n",
      "         [-0.0346]],\n",
      "\n",
      "        [[ 0.0341],\n",
      "         [-0.0443],\n",
      "         [-0.0009],\n",
      "         ...,\n",
      "         [-0.0156],\n",
      "         [ 0.0024],\n",
      "         [ 0.0161]],\n",
      "\n",
      "        [[ 0.0720],\n",
      "         [ 0.0842],\n",
      "         [ 0.0765],\n",
      "         ...,\n",
      "         [ 0.0874],\n",
      "         [ 0.0874],\n",
      "         [ 0.0874]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0514],\n",
      "         [-0.0286],\n",
      "         [ 0.0090],\n",
      "         ...,\n",
      "         [ 0.0671],\n",
      "         [ 0.0672],\n",
      "         [ 0.0672]],\n",
      "\n",
      "        [[-0.0126],\n",
      "         [-0.0790],\n",
      "         [-0.0946],\n",
      "         ...,\n",
      "         [-0.0021],\n",
      "         [-0.0021],\n",
      "         [-0.0021]],\n",
      "\n",
      "        [[ 0.2363],\n",
      "         [ 0.1165],\n",
      "         [ 0.1748],\n",
      "         ...,\n",
      "         [ 0.2572],\n",
      "         [ 0.2572],\n",
      "         [ 0.2572]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0434],\n",
      "         [-0.1337],\n",
      "         [-0.1034],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0341],\n",
      "         [-0.0443],\n",
      "         [-0.0009],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0720],\n",
      "         [ 0.0842],\n",
      "         [ 0.0765],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0514],\n",
      "         [-0.0286],\n",
      "         [ 0.0090],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0126],\n",
      "         [-0.0790],\n",
      "         [-0.0946],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2363],\n",
      "         [ 0.1165],\n",
      "         [ 0.1748],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0447],\n",
      "         [-0.1350],\n",
      "         [-0.1046],\n",
      "         ...,\n",
      "         [-0.0359],\n",
      "         [-0.0359],\n",
      "         [-0.0359]],\n",
      "\n",
      "        [[-0.0205],\n",
      "         [-0.0996],\n",
      "         [-0.0555],\n",
      "         ...,\n",
      "         [-0.0681],\n",
      "         [-0.0506],\n",
      "         [-0.0374]],\n",
      "\n",
      "        [[ 0.1659],\n",
      "         [ 0.1776],\n",
      "         [ 0.1692],\n",
      "         ...,\n",
      "         [ 0.1850],\n",
      "         [ 0.1850],\n",
      "         [ 0.1850]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0409],\n",
      "         [-0.0396],\n",
      "         [-0.0021],\n",
      "         ...,\n",
      "         [ 0.0558],\n",
      "         [ 0.0558],\n",
      "         [ 0.0559]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [-0.0829],\n",
      "         [-0.0987],\n",
      "         ...,\n",
      "         [-0.0068],\n",
      "         [-0.0068],\n",
      "         [-0.0068]],\n",
      "\n",
      "        [[ 0.2058],\n",
      "         [ 0.0844],\n",
      "         [ 0.1454],\n",
      "         ...,\n",
      "         [ 0.2265],\n",
      "         [ 0.2265],\n",
      "         [ 0.2265]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0447],\n",
      "         [-0.1350],\n",
      "         [-0.1046],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0205],\n",
      "         [-0.0996],\n",
      "         [-0.0555],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1659],\n",
      "         [ 0.1776],\n",
      "         [ 0.1692],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0409],\n",
      "         [-0.0396],\n",
      "         [-0.0021],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [-0.0829],\n",
      "         [-0.0987],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2058],\n",
      "         [ 0.0844],\n",
      "         [ 0.1454],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0453],\n",
      "         [-0.1357],\n",
      "         [-0.1053],\n",
      "         ...,\n",
      "         [-0.0366],\n",
      "         [-0.0366],\n",
      "         [-0.0366]],\n",
      "\n",
      "        [[ 0.0799],\n",
      "         [ 0.0014],\n",
      "         [ 0.0445],\n",
      "         ...,\n",
      "         [ 0.0277],\n",
      "         [ 0.0456],\n",
      "         [ 0.0592]],\n",
      "\n",
      "        [[ 0.1340],\n",
      "         [ 0.1456],\n",
      "         [ 0.1373],\n",
      "         ...,\n",
      "         [ 0.1525],\n",
      "         [ 0.1525],\n",
      "         [ 0.1525]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0552],\n",
      "         [-0.0263],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [ 0.0698],\n",
      "         [ 0.0698],\n",
      "         [ 0.0698]],\n",
      "\n",
      "        [[-0.0192],\n",
      "         [-0.0851],\n",
      "         [-0.1009],\n",
      "         ...,\n",
      "         [-0.0093],\n",
      "         [-0.0093],\n",
      "         [-0.0093]],\n",
      "\n",
      "        [[ 0.2141],\n",
      "         [ 0.0933],\n",
      "         [ 0.1532],\n",
      "         ...,\n",
      "         [ 0.2353],\n",
      "         [ 0.2353],\n",
      "         [ 0.2353]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0453],\n",
      "         [-0.1357],\n",
      "         [-0.1053],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0799],\n",
      "         [ 0.0014],\n",
      "         [ 0.0445],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1340],\n",
      "         [ 0.1456],\n",
      "         [ 0.1373],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0552],\n",
      "         [-0.0263],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0192],\n",
      "         [-0.0851],\n",
      "         [-0.1009],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2141],\n",
      "         [ 0.0933],\n",
      "         [ 0.1532],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0457],\n",
      "         [-0.1360],\n",
      "         [-0.1056],\n",
      "         ...,\n",
      "         [-0.0369],\n",
      "         [-0.0369],\n",
      "         [-0.0369]],\n",
      "\n",
      "        [[ 0.1578],\n",
      "         [ 0.0778],\n",
      "         [ 0.1237],\n",
      "         ...,\n",
      "         [ 0.1093],\n",
      "         [ 0.1280],\n",
      "         [ 0.1420]],\n",
      "\n",
      "        [[ 0.1629],\n",
      "         [ 0.1748],\n",
      "         [ 0.1670],\n",
      "         ...,\n",
      "         [ 0.1826],\n",
      "         [ 0.1826],\n",
      "         [ 0.1826]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1739],\n",
      "         [ 0.0933],\n",
      "         [ 0.1331],\n",
      "         ...,\n",
      "         [ 0.1919],\n",
      "         [ 0.1919],\n",
      "         [ 0.1920]],\n",
      "\n",
      "        [[-0.0204],\n",
      "         [-0.0863],\n",
      "         [-0.1021],\n",
      "         ...,\n",
      "         [-0.0106],\n",
      "         [-0.0106],\n",
      "         [-0.0106]],\n",
      "\n",
      "        [[ 0.1392],\n",
      "         [ 0.0191],\n",
      "         [ 0.0810],\n",
      "         ...,\n",
      "         [ 0.1579],\n",
      "         [ 0.1579],\n",
      "         [ 0.1579]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0457],\n",
      "         [-0.1360],\n",
      "         [-0.1056],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1578],\n",
      "         [ 0.0778],\n",
      "         [ 0.1237],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1629],\n",
      "         [ 0.1748],\n",
      "         [ 0.1670],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1739],\n",
      "         [ 0.0933],\n",
      "         [ 0.1331],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0204],\n",
      "         [-0.0863],\n",
      "         [-0.1021],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1392],\n",
      "         [ 0.0191],\n",
      "         [ 0.0810],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0458],\n",
      "         [-0.1362],\n",
      "         [-0.1058],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0965],\n",
      "         [ 0.0159],\n",
      "         [ 0.0617],\n",
      "         ...,\n",
      "         [ 0.0474],\n",
      "         [ 0.0655],\n",
      "         [ 0.0791]],\n",
      "\n",
      "        [[ 0.0320],\n",
      "         [ 0.0455],\n",
      "         [ 0.0384],\n",
      "         ...,\n",
      "         [ 0.0462],\n",
      "         [ 0.0462],\n",
      "         [ 0.0462]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1361],\n",
      "         [ 0.0544],\n",
      "         [ 0.0938],\n",
      "         ...,\n",
      "         [ 0.1548],\n",
      "         [ 0.1549],\n",
      "         [ 0.1549]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0869],\n",
      "         [-0.1027],\n",
      "         ...,\n",
      "         [-0.0113],\n",
      "         [-0.0113],\n",
      "         [-0.0113]],\n",
      "\n",
      "        [[ 0.0667],\n",
      "         [-0.0523],\n",
      "         [ 0.0122],\n",
      "         ...,\n",
      "         [ 0.0828],\n",
      "         [ 0.0828],\n",
      "         [ 0.0828]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0458],\n",
      "         [-0.1362],\n",
      "         [-0.1058],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0965],\n",
      "         [ 0.0159],\n",
      "         [ 0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0320],\n",
      "         [ 0.0455],\n",
      "         [ 0.0384],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1361],\n",
      "         [ 0.0544],\n",
      "         [ 0.0938],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0869],\n",
      "         [-0.1027],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0667],\n",
      "         [-0.0523],\n",
      "         [ 0.0122],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1363],\n",
      "         [-0.1059],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.1334],\n",
      "         [ 0.0522],\n",
      "         [ 0.0989],\n",
      "         ...,\n",
      "         [ 0.0851],\n",
      "         [ 0.1037],\n",
      "         [ 0.1176]],\n",
      "\n",
      "        [[ 0.0719],\n",
      "         [ 0.0813],\n",
      "         [ 0.0719],\n",
      "         ...,\n",
      "         [ 0.0905],\n",
      "         [ 0.0905],\n",
      "         [ 0.0905]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1358],\n",
      "         [ 0.0536],\n",
      "         [ 0.0933],\n",
      "         ...,\n",
      "         [ 0.1546],\n",
      "         [ 0.1546],\n",
      "         [ 0.1546]],\n",
      "\n",
      "        [[-0.0214],\n",
      "         [-0.0872],\n",
      "         [-0.1030],\n",
      "         ...,\n",
      "         [-0.0116],\n",
      "         [-0.0116],\n",
      "         [-0.0116]],\n",
      "\n",
      "        [[ 0.0285],\n",
      "         [-0.0900],\n",
      "         [-0.0230],\n",
      "         ...,\n",
      "         [ 0.0422],\n",
      "         [ 0.0422],\n",
      "         [ 0.0422]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1363],\n",
      "         [-0.1059],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1334],\n",
      "         [ 0.0522],\n",
      "         [ 0.0989],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0719],\n",
      "         [ 0.0813],\n",
      "         [ 0.0719],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1358],\n",
      "         [ 0.0536],\n",
      "         [ 0.0933],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0214],\n",
      "         [-0.0872],\n",
      "         [-0.1030],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0285],\n",
      "         [-0.0900],\n",
      "         [-0.0230],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5955e-02],\n",
      "         [-1.3637e-01],\n",
      "         [-1.0597e-01],\n",
      "         ...,\n",
      "         [-3.7168e-02],\n",
      "         [-3.7168e-02],\n",
      "         [-3.7167e-02]],\n",
      "\n",
      "        [[ 5.9113e-02],\n",
      "         [-2.0859e-02],\n",
      "         [ 2.5065e-02],\n",
      "         ...,\n",
      "         [ 1.2766e-02],\n",
      "         [ 3.0817e-02],\n",
      "         [ 4.4375e-02]],\n",
      "\n",
      "        [[ 8.6794e-02],\n",
      "         [ 9.6405e-02],\n",
      "         [ 8.7011e-02],\n",
      "         ...,\n",
      "         [ 1.0597e-01],\n",
      "         [ 1.0597e-01],\n",
      "         [ 1.0597e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.3352e-02],\n",
      "         [-3.7950e-02],\n",
      "         [-3.1874e-05],\n",
      "         ...,\n",
      "         [ 6.1034e-02],\n",
      "         [ 6.1075e-02],\n",
      "         [ 6.1103e-02]],\n",
      "\n",
      "        [[-2.1526e-02],\n",
      "         [-8.7425e-02],\n",
      "         [-1.0319e-01],\n",
      "         ...,\n",
      "         [-1.1748e-02],\n",
      "         [-1.1748e-02],\n",
      "         [-1.1748e-02]],\n",
      "\n",
      "        [[ 8.5612e-03],\n",
      "         [-1.0989e-01],\n",
      "         [-4.1038e-02],\n",
      "         ...,\n",
      "         [ 2.0739e-02],\n",
      "         [ 2.0743e-02],\n",
      "         [ 2.0746e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5955e-02],\n",
      "         [-1.3637e-01],\n",
      "         [-1.0597e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 5.9113e-02],\n",
      "         [-2.0859e-02],\n",
      "         [ 2.5065e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 8.6794e-02],\n",
      "         [ 9.6405e-02],\n",
      "         [ 8.7011e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.3352e-02],\n",
      "         [-3.7950e-02],\n",
      "         [-3.1874e-05],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.1526e-02],\n",
      "         [-8.7425e-02],\n",
      "         [-1.0319e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 8.5612e-03],\n",
      "         [-1.0989e-01],\n",
      "         [-4.1038e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0372],\n",
      "         [-0.0372],\n",
      "         [-0.0372]],\n",
      "\n",
      "        [[ 0.0976],\n",
      "         [ 0.0171],\n",
      "         [ 0.0635],\n",
      "         ...,\n",
      "         [ 0.0510],\n",
      "         [ 0.0694],\n",
      "         [ 0.0832]],\n",
      "\n",
      "        [[ 0.0470],\n",
      "         [ 0.0580],\n",
      "         [ 0.0496],\n",
      "         ...,\n",
      "         [ 0.0636],\n",
      "         [ 0.0636],\n",
      "         [ 0.0636]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0826],\n",
      "         [ 0.0012],\n",
      "         [ 0.0398],\n",
      "         ...,\n",
      "         [ 0.1016],\n",
      "         [ 0.1017],\n",
      "         [ 0.1017]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0875],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0118],\n",
      "         [-0.0118],\n",
      "         [-0.0118]],\n",
      "\n",
      "        [[-0.0019],\n",
      "         [-0.1204],\n",
      "         [-0.0505],\n",
      "         ...,\n",
      "         [ 0.0093],\n",
      "         [ 0.0093],\n",
      "         [ 0.0094]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0976],\n",
      "         [ 0.0171],\n",
      "         [ 0.0635],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0470],\n",
      "         [ 0.0580],\n",
      "         [ 0.0496],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0826],\n",
      "         [ 0.0012],\n",
      "         [ 0.0398],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0875],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0019],\n",
      "         [-0.1204],\n",
      "         [-0.0505],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0372],\n",
      "         [-0.0372],\n",
      "         [-0.0372]],\n",
      "\n",
      "        [[-0.0023],\n",
      "         [-0.0832],\n",
      "         [-0.0375],\n",
      "         ...,\n",
      "         [-0.0494],\n",
      "         [-0.0315],\n",
      "         [-0.0181]],\n",
      "\n",
      "        [[ 0.0232],\n",
      "         [ 0.0356],\n",
      "         [ 0.0279],\n",
      "         ...,\n",
      "         [ 0.0377],\n",
      "         [ 0.0377],\n",
      "         [ 0.0377]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0508],\n",
      "         [-0.0307],\n",
      "         [ 0.0075],\n",
      "         ...,\n",
      "         [ 0.0678],\n",
      "         [ 0.0678],\n",
      "         [ 0.0678]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0118],\n",
      "         [-0.0118],\n",
      "         [-0.0118]],\n",
      "\n",
      "        [[-0.0075],\n",
      "         [-0.1261],\n",
      "         [-0.0556],\n",
      "         ...,\n",
      "         [ 0.0033],\n",
      "         [ 0.0033],\n",
      "         [ 0.0033]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0023],\n",
      "         [-0.0832],\n",
      "         [-0.0375],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0232],\n",
      "         [ 0.0356],\n",
      "         [ 0.0279],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0508],\n",
      "         [-0.0307],\n",
      "         [ 0.0075],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0075],\n",
      "         [-0.1261],\n",
      "         [-0.0556],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5960e-02],\n",
      "         [-1.3640e-01],\n",
      "         [-1.0601e-01],\n",
      "         ...,\n",
      "         [-3.7147e-02],\n",
      "         [-3.7147e-02],\n",
      "         [-3.7147e-02]],\n",
      "\n",
      "        [[ 1.2300e-01],\n",
      "         [ 4.2012e-02],\n",
      "         [ 8.7862e-02],\n",
      "         ...,\n",
      "         [ 7.3109e-02],\n",
      "         [ 9.1675e-02],\n",
      "         [ 1.0567e-01]],\n",
      "\n",
      "        [[ 9.5030e-03],\n",
      "         [ 2.2645e-02],\n",
      "         [ 1.5419e-02],\n",
      "         ...,\n",
      "         [ 2.2641e-02],\n",
      "         [ 2.2642e-02],\n",
      "         [ 2.2643e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.9379e-02],\n",
      "         [-5.1721e-02],\n",
      "         [-1.3916e-02],\n",
      "         ...,\n",
      "         [ 4.4572e-02],\n",
      "         [ 4.4612e-02],\n",
      "         [ 4.4641e-02]],\n",
      "\n",
      "        [[-2.1620e-02],\n",
      "         [-8.7583e-02],\n",
      "         [-1.0333e-01],\n",
      "         ...,\n",
      "         [-1.1809e-02],\n",
      "         [-1.1809e-02],\n",
      "         [-1.1809e-02]],\n",
      "\n",
      "        [[-1.0533e-02],\n",
      "         [-1.2910e-01],\n",
      "         [-5.8317e-02],\n",
      "         ...,\n",
      "         [-1.8179e-05],\n",
      "         [-1.3754e-05],\n",
      "         [-1.0654e-05]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1230],\n",
      "         [ 0.0420],\n",
      "         [ 0.0879],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0095],\n",
      "         [ 0.0226],\n",
      "         [ 0.0154],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0294],\n",
      "         [-0.0517],\n",
      "         [-0.0139],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0105],\n",
      "         [-0.1291],\n",
      "         [-0.0583],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0151],\n",
      "         [-0.0643],\n",
      "         [-0.0202],\n",
      "         ...,\n",
      "         [-0.0347],\n",
      "         [-0.0172],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[ 0.0017],\n",
      "         [ 0.0153],\n",
      "         [ 0.0083],\n",
      "         ...,\n",
      "         [ 0.0140],\n",
      "         [ 0.0140],\n",
      "         [ 0.0140]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0160],\n",
      "         [-0.0648],\n",
      "         [-0.0272],\n",
      "         ...,\n",
      "         [ 0.0299],\n",
      "         [ 0.0299],\n",
      "         [ 0.0300]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0118],\n",
      "         [-0.0118],\n",
      "         [-0.0118]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.1307],\n",
      "         [-0.0598],\n",
      "         ...,\n",
      "         [-0.0018],\n",
      "         [-0.0018],\n",
      "         [-0.0018]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0151],\n",
      "         [-0.0643],\n",
      "         [-0.0202],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0017],\n",
      "         [ 0.0153],\n",
      "         [ 0.0083],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0160],\n",
      "         [-0.0648],\n",
      "         [-0.0272],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.1307],\n",
      "         [-0.0598],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0872],\n",
      "         [ 0.0063],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [ 0.0388],\n",
      "         [ 0.0571],\n",
      "         [ 0.0709]],\n",
      "\n",
      "        [[-0.0028],\n",
      "         [ 0.0111],\n",
      "         [ 0.0043],\n",
      "         ...,\n",
      "         [ 0.0091],\n",
      "         [ 0.0091],\n",
      "         [ 0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0078],\n",
      "         [-0.0727],\n",
      "         [-0.0353],\n",
      "         ...,\n",
      "         [ 0.0209],\n",
      "         [ 0.0210],\n",
      "         [ 0.0210]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0118],\n",
      "         [-0.0118],\n",
      "         [-0.0118]],\n",
      "\n",
      "        [[-0.0130],\n",
      "         [-0.1316],\n",
      "         [-0.0606],\n",
      "         ...,\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0027]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0460],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0872],\n",
      "         [ 0.0063],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0028],\n",
      "         [ 0.0111],\n",
      "         [ 0.0043],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0078],\n",
      "         [-0.0727],\n",
      "         [-0.0353],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0130],\n",
      "         [-0.1316],\n",
      "         [-0.0606],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.1347],\n",
      "         [ 0.0531],\n",
      "         [ 0.0993],\n",
      "         ...,\n",
      "         [ 0.0844],\n",
      "         [ 0.1032],\n",
      "         [ 0.1173]],\n",
      "\n",
      "        [[-0.0053],\n",
      "         [ 0.0088],\n",
      "         [ 0.0020],\n",
      "         ...,\n",
      "         [ 0.0063],\n",
      "         [ 0.0063],\n",
      "         [ 0.0063]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0029],\n",
      "         [-0.0774],\n",
      "         [-0.0402],\n",
      "         ...,\n",
      "         [ 0.0155],\n",
      "         [ 0.0156],\n",
      "         [ 0.0156]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0118],\n",
      "         [-0.0118],\n",
      "         [-0.0118]],\n",
      "\n",
      "        [[-0.0135],\n",
      "         [-0.1321],\n",
      "         [-0.0610],\n",
      "         ...,\n",
      "         [-0.0032],\n",
      "         [-0.0032],\n",
      "         [-0.0032]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1347],\n",
      "         [ 0.0531],\n",
      "         [ 0.0993],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0053],\n",
      "         [ 0.0088],\n",
      "         [ 0.0020],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0029],\n",
      "         [-0.0774],\n",
      "         [-0.0402],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0135],\n",
      "         [-0.1321],\n",
      "         [-0.0610],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5944e-02],\n",
      "         [-1.3640e-01],\n",
      "         [-1.0601e-01],\n",
      "         ...,\n",
      "         [-3.7116e-02],\n",
      "         [-3.7116e-02],\n",
      "         [-3.7116e-02]],\n",
      "\n",
      "        [[ 3.1353e-02],\n",
      "         [-4.8292e-02],\n",
      "         [-4.3419e-03],\n",
      "         ...,\n",
      "         [-1.9420e-02],\n",
      "         [-1.2582e-03],\n",
      "         [ 1.2481e-02]],\n",
      "\n",
      "        [[-6.6934e-03],\n",
      "         [ 7.4019e-03],\n",
      "         [ 7.1613e-04],\n",
      "         ...,\n",
      "         [ 4.7068e-03],\n",
      "         [ 4.7079e-03],\n",
      "         [ 4.7087e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.1723e-07],\n",
      "         [-8.0272e-02],\n",
      "         [-4.3132e-02],\n",
      "         ...,\n",
      "         [ 1.2292e-02],\n",
      "         [ 1.2333e-02],\n",
      "         [ 1.2360e-02]],\n",
      "\n",
      "        [[-2.1601e-02],\n",
      "         [-8.7599e-02],\n",
      "         [-1.0334e-01],\n",
      "         ...,\n",
      "         [-1.1764e-02],\n",
      "         [-1.1764e-02],\n",
      "         [-1.1764e-02]],\n",
      "\n",
      "        [[-1.3754e-02],\n",
      "         [-1.3238e-01],\n",
      "         [-6.1281e-02],\n",
      "         ...,\n",
      "         [-3.5360e-03],\n",
      "         [-3.5316e-03],\n",
      "         [-3.5286e-03]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5944e-02],\n",
      "         [-1.3640e-01],\n",
      "         [-1.0601e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 3.1353e-02],\n",
      "         [-4.8292e-02],\n",
      "         [-4.3419e-03],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-6.6934e-03],\n",
      "         [ 7.4019e-03],\n",
      "         [ 7.1613e-04],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.1723e-07],\n",
      "         [-8.0272e-02],\n",
      "         [-4.3132e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.1601e-02],\n",
      "         [-8.7599e-02],\n",
      "         [-1.0334e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.3754e-02],\n",
      "         [-1.3238e-01],\n",
      "         [-6.1281e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5942e-02],\n",
      "         [-1.3640e-01],\n",
      "         [-1.0601e-01],\n",
      "         ...,\n",
      "         [-3.7112e-02],\n",
      "         [-3.7112e-02],\n",
      "         [-3.7112e-02]],\n",
      "\n",
      "        [[ 9.4763e-02],\n",
      "         [ 1.4225e-02],\n",
      "         [ 5.9132e-02],\n",
      "         ...,\n",
      "         [ 4.3447e-02],\n",
      "         [ 6.2006e-02],\n",
      "         [ 7.6046e-02]],\n",
      "\n",
      "        [[-7.5111e-03],\n",
      "         [ 6.6267e-03],\n",
      "         [-3.6240e-05],\n",
      "         ...,\n",
      "         [ 3.8046e-03],\n",
      "         [ 3.8057e-03],\n",
      "         [ 3.8065e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7710e-03],\n",
      "         [-8.1990e-02],\n",
      "         [-4.4893e-02],\n",
      "         ...,\n",
      "         [ 1.0338e-02],\n",
      "         [ 1.0378e-02],\n",
      "         [ 1.0406e-02]],\n",
      "\n",
      "        [[-2.1596e-02],\n",
      "         [-8.7599e-02],\n",
      "         [-1.0334e-01],\n",
      "         ...,\n",
      "         [-1.1757e-02],\n",
      "         [-1.1757e-02],\n",
      "         [-1.1757e-02]],\n",
      "\n",
      "        [[-1.3904e-02],\n",
      "         [-1.3254e-01],\n",
      "         [-6.1424e-02],\n",
      "         ...,\n",
      "         [-3.6972e-03],\n",
      "         [-3.6928e-03],\n",
      "         [-3.6897e-03]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5942e-02],\n",
      "         [-1.3640e-01],\n",
      "         [-1.0601e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 9.4763e-02],\n",
      "         [ 1.4225e-02],\n",
      "         [ 5.9132e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-7.5111e-03],\n",
      "         [ 6.6267e-03],\n",
      "         [-3.6240e-05],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7710e-03],\n",
      "         [-8.1990e-02],\n",
      "         [-4.4893e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.1596e-02],\n",
      "         [-8.7599e-02],\n",
      "         [-1.0334e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.3904e-02],\n",
      "         [-1.3254e-01],\n",
      "         [-6.1424e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0614],\n",
      "         [-0.0191],\n",
      "         [ 0.0254],\n",
      "         ...,\n",
      "         [ 0.0097],\n",
      "         [ 0.0284],\n",
      "         [ 0.0426]],\n",
      "\n",
      "        [[-0.0080],\n",
      "         [ 0.0062],\n",
      "         [-0.0005],\n",
      "         ...,\n",
      "         [ 0.0033],\n",
      "         [ 0.0033],\n",
      "         [ 0.0033]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0029],\n",
      "         [-0.0830],\n",
      "         [-0.0460],\n",
      "         ...,\n",
      "         [ 0.0091],\n",
      "         [ 0.0092],\n",
      "         [ 0.0092]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0118],\n",
      "         [-0.0118],\n",
      "         [-0.0118]],\n",
      "\n",
      "        [[-0.0140],\n",
      "         [-0.1326],\n",
      "         [-0.0615],\n",
      "         ...,\n",
      "         [-0.0038],\n",
      "         [-0.0038],\n",
      "         [-0.0038]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0614],\n",
      "         [-0.0191],\n",
      "         [ 0.0254],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0080],\n",
      "         [ 0.0062],\n",
      "         [-0.0005],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0029],\n",
      "         [-0.0830],\n",
      "         [-0.0460],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0140],\n",
      "         [-0.1326],\n",
      "         [-0.0615],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0993],\n",
      "         [ 0.0174],\n",
      "         [ 0.0635],\n",
      "         ...,\n",
      "         [ 0.0491],\n",
      "         [ 0.0680],\n",
      "         [ 0.0823]],\n",
      "\n",
      "        [[-0.0083],\n",
      "         [ 0.0059],\n",
      "         [-0.0007],\n",
      "         ...,\n",
      "         [ 0.0030],\n",
      "         [ 0.0030],\n",
      "         [ 0.0030]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0035],\n",
      "         [-0.0837],\n",
      "         [-0.0466],\n",
      "         ...,\n",
      "         [ 0.0084],\n",
      "         [ 0.0085],\n",
      "         [ 0.0085]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0140],\n",
      "         [-0.1327],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [-0.0038],\n",
      "         [-0.0038],\n",
      "         [-0.0038]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0993],\n",
      "         [ 0.0174],\n",
      "         [ 0.0635],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0083],\n",
      "         [ 0.0059],\n",
      "         [-0.0007],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0035],\n",
      "         [-0.0837],\n",
      "         [-0.0466],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0140],\n",
      "         [-0.1327],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.1072],\n",
      "         [ 0.0246],\n",
      "         [ 0.0713],\n",
      "         ...,\n",
      "         [ 0.0573],\n",
      "         [ 0.0763],\n",
      "         [ 0.0907]],\n",
      "\n",
      "        [[-0.0084],\n",
      "         [ 0.0057],\n",
      "         [-0.0009],\n",
      "         ...,\n",
      "         [ 0.0028],\n",
      "         [ 0.0028],\n",
      "         [ 0.0028]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0039],\n",
      "         [-0.0841],\n",
      "         [-0.0470],\n",
      "         ...,\n",
      "         [ 0.0080],\n",
      "         [ 0.0080],\n",
      "         [ 0.0080]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1327],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1072],\n",
      "         [ 0.0246],\n",
      "         [ 0.0713],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0084],\n",
      "         [ 0.0057],\n",
      "         [-0.0009],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0039],\n",
      "         [-0.0841],\n",
      "         [-0.0470],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1327],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0505],\n",
      "         [-0.0310],\n",
      "         [ 0.0147],\n",
      "         ...,\n",
      "         [ 0.0011],\n",
      "         [ 0.0196],\n",
      "         [ 0.0336]],\n",
      "\n",
      "        [[-0.0085],\n",
      "         [ 0.0056],\n",
      "         [-0.0010],\n",
      "         ...,\n",
      "         [ 0.0027],\n",
      "         [ 0.0027],\n",
      "         [ 0.0027]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0042],\n",
      "         [-0.0843],\n",
      "         [-0.0473],\n",
      "         ...,\n",
      "         [ 0.0077],\n",
      "         [ 0.0077],\n",
      "         [ 0.0077]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1327],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0505],\n",
      "         [-0.0310],\n",
      "         [ 0.0147],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0085],\n",
      "         [ 0.0056],\n",
      "         [-0.0010],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0042],\n",
      "         [-0.0843],\n",
      "         [-0.0473],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1327],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.1224],\n",
      "         [ 0.0407],\n",
      "         [ 0.0872],\n",
      "         ...,\n",
      "         [ 0.0732],\n",
      "         [ 0.0920],\n",
      "         [ 0.1062]],\n",
      "\n",
      "        [[-0.0086],\n",
      "         [ 0.0056],\n",
      "         [-0.0011],\n",
      "         ...,\n",
      "         [ 0.0026],\n",
      "         [ 0.0026],\n",
      "         [ 0.0026]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0044],\n",
      "         [-0.0845],\n",
      "         [-0.0475],\n",
      "         ...,\n",
      "         [ 0.0075],\n",
      "         [ 0.0075],\n",
      "         [ 0.0075]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1224],\n",
      "         [ 0.0407],\n",
      "         [ 0.0872],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0086],\n",
      "         [ 0.0056],\n",
      "         [-0.0011],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0044],\n",
      "         [-0.0845],\n",
      "         [-0.0475],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5936e-02],\n",
      "         [-1.3640e-01],\n",
      "         [-1.0601e-01],\n",
      "         ...,\n",
      "         [-3.7103e-02],\n",
      "         [-3.7103e-02],\n",
      "         [-3.7103e-02]],\n",
      "\n",
      "        [[ 8.1022e-02],\n",
      "         [ 1.0253e-04],\n",
      "         [ 4.5170e-02],\n",
      "         ...,\n",
      "         [ 2.9974e-02],\n",
      "         [ 4.8802e-02],\n",
      "         [ 6.3023e-02]],\n",
      "\n",
      "        [[-8.6441e-03],\n",
      "         [ 5.5400e-03],\n",
      "         [-1.1012e-03],\n",
      "         ...,\n",
      "         [ 2.5790e-03],\n",
      "         [ 2.5801e-03],\n",
      "         [ 2.5808e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.5069e-03],\n",
      "         [-8.4626e-02],\n",
      "         [-4.7601e-02],\n",
      "         ...,\n",
      "         [ 7.3302e-03],\n",
      "         [ 7.3702e-03],\n",
      "         [ 7.3979e-03]],\n",
      "\n",
      "        [[-2.1585e-02],\n",
      "         [-8.7596e-02],\n",
      "         [-1.0333e-01],\n",
      "         ...,\n",
      "         [-1.1738e-02],\n",
      "         [-1.1738e-02],\n",
      "         [-1.1738e-02]],\n",
      "\n",
      "        [[-1.4124e-02],\n",
      "         [-1.3276e-01],\n",
      "         [-6.1640e-02],\n",
      "         ...,\n",
      "         [-3.9235e-03],\n",
      "         [-3.9191e-03],\n",
      "         [-3.9160e-03]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-4.5936e-02],\n",
      "         [-1.3640e-01],\n",
      "         [-1.0601e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 8.1022e-02],\n",
      "         [ 1.0253e-04],\n",
      "         [ 4.5170e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-8.6441e-03],\n",
      "         [ 5.5400e-03],\n",
      "         [-1.1012e-03],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.5069e-03],\n",
      "         [-8.4626e-02],\n",
      "         [-4.7601e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.1585e-02],\n",
      "         [-8.7596e-02],\n",
      "         [-1.0333e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.4124e-02],\n",
      "         [-1.3276e-01],\n",
      "         [-6.1640e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0954],\n",
      "         [ 0.0144],\n",
      "         [ 0.0603],\n",
      "         ...,\n",
      "         [ 0.0466],\n",
      "         [ 0.0654],\n",
      "         [ 0.0795]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0011],\n",
      "         ...,\n",
      "         [ 0.0026],\n",
      "         [ 0.0026],\n",
      "         [ 0.0026]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0046],\n",
      "         [-0.0847],\n",
      "         [-0.0477],\n",
      "         ...,\n",
      "         [ 0.0072],\n",
      "         [ 0.0073],\n",
      "         [ 0.0073]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0954],\n",
      "         [ 0.0144],\n",
      "         [ 0.0603],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0011],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0046],\n",
      "         [-0.0847],\n",
      "         [-0.0477],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0616],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[-0.0466],\n",
      "         [-0.1254],\n",
      "         [-0.0819],\n",
      "         ...,\n",
      "         [-0.0946],\n",
      "         [-0.0772],\n",
      "         [-0.0640]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0011],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0046],\n",
      "         [-0.0848],\n",
      "         [-0.0477],\n",
      "         ...,\n",
      "         [ 0.0072],\n",
      "         [ 0.0072],\n",
      "         [ 0.0072]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0466],\n",
      "         [-0.1254],\n",
      "         [-0.0819],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0011],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0046],\n",
      "         [-0.0848],\n",
      "         [-0.0477],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0286],\n",
      "         [-0.0515],\n",
      "         [-0.0074],\n",
      "         ...,\n",
      "         [-0.0230],\n",
      "         [-0.0051],\n",
      "         [ 0.0085]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0047],\n",
      "         [-0.0848],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [ 0.0071],\n",
      "         [ 0.0072],\n",
      "         [ 0.0072]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0286],\n",
      "         [-0.0515],\n",
      "         [-0.0074],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0047],\n",
      "         [-0.0848],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0649],\n",
      "         [-0.0159],\n",
      "         [ 0.0288],\n",
      "         ...,\n",
      "         [ 0.0132],\n",
      "         [ 0.0313],\n",
      "         [ 0.0451]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0047],\n",
      "         [-0.0848],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [ 0.0071],\n",
      "         [ 0.0071],\n",
      "         [ 0.0072]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0649],\n",
      "         [-0.0159],\n",
      "         [ 0.0288],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0047],\n",
      "         [-0.0848],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0823],\n",
      "         [ 0.0007],\n",
      "         [ 0.0468],\n",
      "         ...,\n",
      "         [ 0.0328],\n",
      "         [ 0.0513],\n",
      "         [ 0.0653]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0047],\n",
      "         [-0.0848],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [ 0.0071],\n",
      "         [ 0.0071],\n",
      "         [ 0.0072]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0823],\n",
      "         [ 0.0007],\n",
      "         [ 0.0468],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0047],\n",
      "         [-0.0848],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0423],\n",
      "         [-0.0389],\n",
      "         [ 0.0064],\n",
      "         ...,\n",
      "         [-0.0080],\n",
      "         [ 0.0102],\n",
      "         [ 0.0240]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0047],\n",
      "         [-0.0848],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [ 0.0071],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0423],\n",
      "         [-0.0389],\n",
      "         [ 0.0064],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0047],\n",
      "         [-0.0848],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0220],\n",
      "         [-0.0589],\n",
      "         [-0.0142],\n",
      "         ...,\n",
      "         [-0.0291],\n",
      "         [-0.0111],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [ 0.0071],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0220],\n",
      "         [-0.0589],\n",
      "         [-0.0142],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0115],\n",
      "         [-0.0691],\n",
      "         [-0.0248],\n",
      "         ...,\n",
      "         [-0.0401],\n",
      "         [-0.0222],\n",
      "         [-0.0087]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [ 0.0071],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0115],\n",
      "         [-0.0691],\n",
      "         [-0.0248],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0060],\n",
      "         [-0.0745],\n",
      "         [-0.0304],\n",
      "         ...,\n",
      "         [-0.0458],\n",
      "         [-0.0280],\n",
      "         [-0.0146]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [ 0.0070],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0060],\n",
      "         [-0.0745],\n",
      "         [-0.0304],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0032],\n",
      "         [-0.0774],\n",
      "         [-0.0333],\n",
      "         ...,\n",
      "         [-0.0488],\n",
      "         [-0.0311],\n",
      "         [-0.0176]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [ 0.0070],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0032],\n",
      "         [-0.0774],\n",
      "         [-0.0333],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0055],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0017],\n",
      "         [-0.0788],\n",
      "         [-0.0348],\n",
      "         ...,\n",
      "         [-0.0504],\n",
      "         [-0.0327],\n",
      "         [-0.0192]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0054],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [ 0.0070],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0017],\n",
      "         [-0.0788],\n",
      "         [-0.0348],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0054],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0009],\n",
      "         [-0.0796],\n",
      "         [-0.0356],\n",
      "         ...,\n",
      "         [-0.0512],\n",
      "         [-0.0334],\n",
      "         [-0.0200]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0054],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [ 0.0070],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0009],\n",
      "         [-0.0796],\n",
      "         [-0.0356],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0054],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[ 0.0006],\n",
      "         [-0.0800],\n",
      "         [-0.0360],\n",
      "         ...,\n",
      "         [-0.0516],\n",
      "         [-0.0338],\n",
      "         [-0.0204]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0054],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [ 0.0025],\n",
      "         [ 0.0025],\n",
      "         [ 0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [ 0.0070],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [-0.0117],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0459],\n",
      "         [-0.1364],\n",
      "         [-0.1060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0006],\n",
      "         [-0.0800],\n",
      "         [-0.0360],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0054],\n",
      "         [-0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0048],\n",
      "         [-0.0849],\n",
      "         [-0.0479],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0876],\n",
      "         [-0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0141],\n",
      "         [-0.1328],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/25000 [00:00<4:25:56,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот в AttentiveModel сделали mask. Она выглядит так:\n",
      "torch.BoolTensor\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2062],\n",
      "         [0.2717],\n",
      "         [0.1635],\n",
      "         ...,\n",
      "         [0.2195],\n",
      "         [0.2196],\n",
      "         [0.2196]],\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.0898],\n",
      "         [0.1821],\n",
      "         ...,\n",
      "         [0.0575],\n",
      "         [0.0918],\n",
      "         [0.0789]],\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.1537],\n",
      "         [0.1700],\n",
      "         ...,\n",
      "         [0.2196],\n",
      "         [0.2196],\n",
      "         [0.2196]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.1137],\n",
      "         [0.2395],\n",
      "         ...,\n",
      "         [0.2196],\n",
      "         [0.2196],\n",
      "         [0.2196]],\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.2205],\n",
      "         [0.1267],\n",
      "         ...,\n",
      "         [0.2196],\n",
      "         [0.2196],\n",
      "         [0.2196]],\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.2728],\n",
      "         [0.2663],\n",
      "         ...,\n",
      "         [0.2196],\n",
      "         [0.2196],\n",
      "         [0.2196]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2062],\n",
      "         [0.2717],\n",
      "         [0.1635],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.0898],\n",
      "         [0.1821],\n",
      "         ...,\n",
      "         [0.0575],\n",
      "         [0.0918],\n",
      "         [0.0789]],\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.1537],\n",
      "         [0.1700],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.1137],\n",
      "         [0.2395],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.2205],\n",
      "         [0.1267],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2062],\n",
      "         [0.2728],\n",
      "         [0.2663],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1490],\n",
      "         [ 0.2148],\n",
      "         [ 0.1045],\n",
      "         ...,\n",
      "         [ 0.1640],\n",
      "         [ 0.1640],\n",
      "         [ 0.1640]],\n",
      "\n",
      "        [[ 0.1414],\n",
      "         [ 0.0236],\n",
      "         [ 0.1167],\n",
      "         ...,\n",
      "         [-0.0065],\n",
      "         [ 0.0286],\n",
      "         [ 0.0139]],\n",
      "\n",
      "        [[ 0.1425],\n",
      "         [ 0.0889],\n",
      "         [ 0.1067],\n",
      "         ...,\n",
      "         [ 0.1573],\n",
      "         [ 0.1573],\n",
      "         [ 0.1573]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1440],\n",
      "         [ 0.0508],\n",
      "         [ 0.1777],\n",
      "         ...,\n",
      "         [ 0.1588],\n",
      "         [ 0.1588],\n",
      "         [ 0.1588]],\n",
      "\n",
      "        [[ 0.1382],\n",
      "         [ 0.1518],\n",
      "         [ 0.0596],\n",
      "         ...,\n",
      "         [ 0.1531],\n",
      "         [ 0.1531],\n",
      "         [ 0.1531]],\n",
      "\n",
      "        [[ 0.1427],\n",
      "         [ 0.2084],\n",
      "         [ 0.2021],\n",
      "         ...,\n",
      "         [ 0.1574],\n",
      "         [ 0.1574],\n",
      "         [ 0.1574]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1490],\n",
      "         [ 0.2148],\n",
      "         [ 0.1045],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1414],\n",
      "         [ 0.0236],\n",
      "         [ 0.1167],\n",
      "         ...,\n",
      "         [-0.0065],\n",
      "         [ 0.0286],\n",
      "         [ 0.0139]],\n",
      "\n",
      "        [[ 0.1425],\n",
      "         [ 0.0889],\n",
      "         [ 0.1067],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1440],\n",
      "         [ 0.0508],\n",
      "         [ 0.1777],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1382],\n",
      "         [ 0.1518],\n",
      "         [ 0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1427],\n",
      "         [ 0.2084],\n",
      "         [ 0.2021],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1233],\n",
      "         [ 0.1877],\n",
      "         [ 0.0773],\n",
      "         ...,\n",
      "         [ 0.1375],\n",
      "         [ 0.1375],\n",
      "         [ 0.1375]],\n",
      "\n",
      "        [[ 0.0508],\n",
      "         [-0.0648],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0871],\n",
      "         [-0.0509],\n",
      "         [-0.0717]],\n",
      "\n",
      "        [[ 0.1131],\n",
      "         [ 0.0581],\n",
      "         [ 0.0807],\n",
      "         ...,\n",
      "         [ 0.1269],\n",
      "         [ 0.1269],\n",
      "         [ 0.1269]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0782],\n",
      "         [-0.0134],\n",
      "         [ 0.1119],\n",
      "         ...,\n",
      "         [ 0.0928],\n",
      "         [ 0.0928],\n",
      "         [ 0.0928]],\n",
      "\n",
      "        [[ 0.0960],\n",
      "         [ 0.1088],\n",
      "         [ 0.0173],\n",
      "         ...,\n",
      "         [ 0.1118],\n",
      "         [ 0.1118],\n",
      "         [ 0.1118]],\n",
      "\n",
      "        [[ 0.1636],\n",
      "         [ 0.2300],\n",
      "         [ 0.2231],\n",
      "         ...,\n",
      "         [ 0.1799],\n",
      "         [ 0.1799],\n",
      "         [ 0.1799]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1233],\n",
      "         [ 0.1877],\n",
      "         [ 0.0773],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0508],\n",
      "         [-0.0648],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0871],\n",
      "         [-0.0509],\n",
      "         [-0.0717]],\n",
      "\n",
      "        [[ 0.1131],\n",
      "         [ 0.0581],\n",
      "         [ 0.0807],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0782],\n",
      "         [-0.0134],\n",
      "         [ 0.1119],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0960],\n",
      "         [ 0.1088],\n",
      "         [ 0.0173],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1636],\n",
      "         [ 0.2300],\n",
      "         [ 0.2231],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1504],\n",
      "         [ 0.2144],\n",
      "         [ 0.1045],\n",
      "         ...,\n",
      "         [ 0.1651],\n",
      "         [ 0.1651],\n",
      "         [ 0.1651]],\n",
      "\n",
      "        [[-0.0217],\n",
      "         [-0.1345],\n",
      "         [-0.0429],\n",
      "         ...,\n",
      "         [-0.1568],\n",
      "         [-0.1224],\n",
      "         [-0.1407]],\n",
      "\n",
      "        [[ 0.0647],\n",
      "         [ 0.0097],\n",
      "         [ 0.0351],\n",
      "         ...,\n",
      "         [ 0.0757],\n",
      "         [ 0.0757],\n",
      "         [ 0.0757]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0090],\n",
      "         [-0.0967],\n",
      "         [ 0.0287],\n",
      "         ...,\n",
      "         [ 0.0019],\n",
      "         [ 0.0019],\n",
      "         [ 0.0019]],\n",
      "\n",
      "        [[ 0.1219],\n",
      "         [ 0.1356],\n",
      "         [ 0.0442],\n",
      "         ...,\n",
      "         [ 0.1381],\n",
      "         [ 0.1381],\n",
      "         [ 0.1381]],\n",
      "\n",
      "        [[ 0.0619],\n",
      "         [ 0.1247],\n",
      "         [ 0.1213],\n",
      "         ...,\n",
      "         [ 0.0752],\n",
      "         [ 0.0752],\n",
      "         [ 0.0752]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1504],\n",
      "         [ 0.2144],\n",
      "         [ 0.1045],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0217],\n",
      "         [-0.1345],\n",
      "         [-0.0429],\n",
      "         ...,\n",
      "         [-0.1568],\n",
      "         [-0.1224],\n",
      "         [-0.1407]],\n",
      "\n",
      "        [[ 0.0647],\n",
      "         [ 0.0097],\n",
      "         [ 0.0351],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0090],\n",
      "         [-0.0967],\n",
      "         [ 0.0287],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1219],\n",
      "         [ 0.1356],\n",
      "         [ 0.0442],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0619],\n",
      "         [ 0.1247],\n",
      "         [ 0.1213],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1482],\n",
      "         [ 0.2119],\n",
      "         [ 0.1019],\n",
      "         ...,\n",
      "         [ 0.1629],\n",
      "         [ 0.1630],\n",
      "         [ 0.1630]],\n",
      "\n",
      "        [[-0.0219],\n",
      "         [-0.1355],\n",
      "         [-0.0407],\n",
      "         ...,\n",
      "         [-0.1527],\n",
      "         [-0.1167],\n",
      "         [-0.1396]],\n",
      "\n",
      "        [[ 0.1169],\n",
      "         [ 0.0618],\n",
      "         [ 0.0909],\n",
      "         ...,\n",
      "         [ 0.1277],\n",
      "         [ 0.1277],\n",
      "         [ 0.1277]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0771],\n",
      "         [-0.0149],\n",
      "         [ 0.1124],\n",
      "         ...,\n",
      "         [ 0.0912],\n",
      "         [ 0.0912],\n",
      "         [ 0.0912]],\n",
      "\n",
      "        [[ 0.0963],\n",
      "         [ 0.1093],\n",
      "         [ 0.0188],\n",
      "         ...,\n",
      "         [ 0.1124],\n",
      "         [ 0.1124],\n",
      "         [ 0.1124]],\n",
      "\n",
      "        [[ 0.0027],\n",
      "         [ 0.0645],\n",
      "         [ 0.0641],\n",
      "         ...,\n",
      "         [ 0.0131],\n",
      "         [ 0.0131],\n",
      "         [ 0.0131]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1482],\n",
      "         [ 0.2119],\n",
      "         [ 0.1019],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0219],\n",
      "         [-0.1355],\n",
      "         [-0.0407],\n",
      "         ...,\n",
      "         [-0.1527],\n",
      "         [-0.1167],\n",
      "         [-0.1396]],\n",
      "\n",
      "        [[ 0.1169],\n",
      "         [ 0.0618],\n",
      "         [ 0.0909],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0771],\n",
      "         [-0.0149],\n",
      "         [ 0.1124],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0963],\n",
      "         [ 0.1093],\n",
      "         [ 0.0188],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0027],\n",
      "         [ 0.0645],\n",
      "         [ 0.0641],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0934],\n",
      "         [ 0.1570],\n",
      "         [ 0.0477],\n",
      "         ...,\n",
      "         [ 0.1073],\n",
      "         [ 0.1073],\n",
      "         [ 0.1073]],\n",
      "\n",
      "        [[ 0.0632],\n",
      "         [-0.0541],\n",
      "         [ 0.0433],\n",
      "         ...,\n",
      "         [-0.0730],\n",
      "         [-0.0360],\n",
      "         [-0.0593]],\n",
      "\n",
      "        [[ 0.0395],\n",
      "         [-0.0170],\n",
      "         [ 0.0141],\n",
      "         ...,\n",
      "         [ 0.0475],\n",
      "         [ 0.0475],\n",
      "         [ 0.0475]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0619],\n",
      "         [-0.0291],\n",
      "         [ 0.1006],\n",
      "         ...,\n",
      "         [ 0.0768],\n",
      "         [ 0.0768],\n",
      "         [ 0.0768]],\n",
      "\n",
      "        [[ 0.0570],\n",
      "         [ 0.0717],\n",
      "         [-0.0148],\n",
      "         ...,\n",
      "         [ 0.0699],\n",
      "         [ 0.0699],\n",
      "         [ 0.0699]],\n",
      "\n",
      "        [[ 0.0891],\n",
      "         [ 0.1530],\n",
      "         [ 0.1474],\n",
      "         ...,\n",
      "         [ 0.1038],\n",
      "         [ 0.1038],\n",
      "         [ 0.1038]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0934],\n",
      "         [ 0.1570],\n",
      "         [ 0.0477],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0632],\n",
      "         [-0.0541],\n",
      "         [ 0.0433],\n",
      "         ...,\n",
      "         [-0.0730],\n",
      "         [-0.0360],\n",
      "         [-0.0593]],\n",
      "\n",
      "        [[ 0.0395],\n",
      "         [-0.0170],\n",
      "         [ 0.0141],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0619],\n",
      "         [-0.0291],\n",
      "         [ 0.1006],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0570],\n",
      "         [ 0.0717],\n",
      "         [-0.0148],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0891],\n",
      "         [ 0.1530],\n",
      "         [ 0.1474],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0511],\n",
      "         [ 0.1136],\n",
      "         [ 0.0045],\n",
      "         ...,\n",
      "         [ 0.0638],\n",
      "         [ 0.0638],\n",
      "         [ 0.0638]],\n",
      "\n",
      "        [[-0.0464],\n",
      "         [-0.1582],\n",
      "         [-0.0657],\n",
      "         ...,\n",
      "         [-0.1745],\n",
      "         [-0.1393],\n",
      "         [-0.1619]],\n",
      "\n",
      "        [[ 0.0878],\n",
      "         [ 0.0353],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [ 0.1031],\n",
      "         [ 0.1031],\n",
      "         [ 0.1031]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0146],\n",
      "         [-0.0757],\n",
      "         [ 0.0456],\n",
      "         ...,\n",
      "         [ 0.0312],\n",
      "         [ 0.0312],\n",
      "         [ 0.0312]],\n",
      "\n",
      "        [[ 0.1375],\n",
      "         [ 0.1519],\n",
      "         [ 0.0631],\n",
      "         ...,\n",
      "         [ 0.1534],\n",
      "         [ 0.1534],\n",
      "         [ 0.1534]],\n",
      "\n",
      "        [[ 0.0731],\n",
      "         [ 0.1368],\n",
      "         [ 0.1343],\n",
      "         ...,\n",
      "         [ 0.0851],\n",
      "         [ 0.0851],\n",
      "         [ 0.0851]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0511],\n",
      "         [ 0.1136],\n",
      "         [ 0.0045],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0464],\n",
      "         [-0.1582],\n",
      "         [-0.0657],\n",
      "         ...,\n",
      "         [-0.1745],\n",
      "         [-0.1393],\n",
      "         [-0.1619]],\n",
      "\n",
      "        [[ 0.0878],\n",
      "         [ 0.0353],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0146],\n",
      "         [-0.0757],\n",
      "         [ 0.0456],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1375],\n",
      "         [ 0.1519],\n",
      "         [ 0.0631],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0731],\n",
      "         [ 0.1368],\n",
      "         [ 0.1343],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0490],\n",
      "         [ 0.1125],\n",
      "         [ 0.0018],\n",
      "         ...,\n",
      "         [ 0.0624],\n",
      "         [ 0.0624],\n",
      "         [ 0.0624]],\n",
      "\n",
      "        [[ 0.0709],\n",
      "         [-0.0446],\n",
      "         [ 0.0476],\n",
      "         ...,\n",
      "         [-0.0709],\n",
      "         [-0.0359],\n",
      "         [-0.0531]],\n",
      "\n",
      "        [[ 0.1195],\n",
      "         [ 0.0658],\n",
      "         [ 0.0845],\n",
      "         ...,\n",
      "         [ 0.1354],\n",
      "         [ 0.1354],\n",
      "         [ 0.1354]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0893],\n",
      "         [-0.0021],\n",
      "         [ 0.1193],\n",
      "         ...,\n",
      "         [ 0.1055],\n",
      "         [ 0.1055],\n",
      "         [ 0.1055]],\n",
      "\n",
      "        [[ 0.0750],\n",
      "         [ 0.0916],\n",
      "         [ 0.0057],\n",
      "         ...,\n",
      "         [ 0.0885],\n",
      "         [ 0.0885],\n",
      "         [ 0.0885]],\n",
      "\n",
      "        [[ 0.0221],\n",
      "         [ 0.0852],\n",
      "         [ 0.0850],\n",
      "         ...,\n",
      "         [ 0.0322],\n",
      "         [ 0.0322],\n",
      "         [ 0.0322]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0490],\n",
      "         [ 0.1125],\n",
      "         [ 0.0018],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0709],\n",
      "         [-0.0446],\n",
      "         [ 0.0476],\n",
      "         ...,\n",
      "         [-0.0709],\n",
      "         [-0.0359],\n",
      "         [-0.0531]],\n",
      "\n",
      "        [[ 0.1195],\n",
      "         [ 0.0658],\n",
      "         [ 0.0845],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0893],\n",
      "         [-0.0021],\n",
      "         [ 0.1193],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0750],\n",
      "         [ 0.0916],\n",
      "         [ 0.0057],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0221],\n",
      "         [ 0.0852],\n",
      "         [ 0.0850],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0543],\n",
      "         [ 0.1158],\n",
      "         [ 0.0066],\n",
      "         ...,\n",
      "         [ 0.0658],\n",
      "         [ 0.0658],\n",
      "         [ 0.0658]],\n",
      "\n",
      "        [[ 0.0400],\n",
      "         [-0.0745],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [-0.1026],\n",
      "         [-0.0688],\n",
      "         [-0.0838]],\n",
      "\n",
      "        [[ 0.0736],\n",
      "         [ 0.0181],\n",
      "         [ 0.0414],\n",
      "         ...,\n",
      "         [ 0.0878],\n",
      "         [ 0.0878],\n",
      "         [ 0.0878]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0401],\n",
      "         [-0.1311],\n",
      "         [-0.0037],\n",
      "         ...,\n",
      "         [-0.0219],\n",
      "         [-0.0219],\n",
      "         [-0.0219]],\n",
      "\n",
      "        [[ 0.0116],\n",
      "         [ 0.0288],\n",
      "         [-0.0525],\n",
      "         ...,\n",
      "         [ 0.0214],\n",
      "         [ 0.0214],\n",
      "         [ 0.0214]],\n",
      "\n",
      "        [[-0.0231],\n",
      "         [ 0.0415],\n",
      "         [ 0.0441],\n",
      "         ...,\n",
      "         [-0.0136],\n",
      "         [-0.0136],\n",
      "         [-0.0136]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0543],\n",
      "         [ 0.1158],\n",
      "         [ 0.0066],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0400],\n",
      "         [-0.0745],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [-0.1026],\n",
      "         [-0.0688],\n",
      "         [-0.0838]],\n",
      "\n",
      "        [[ 0.0736],\n",
      "         [ 0.0181],\n",
      "         [ 0.0414],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0401],\n",
      "         [-0.1311],\n",
      "         [-0.0037],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0116],\n",
      "         [ 0.0288],\n",
      "         [-0.0525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0231],\n",
      "         [ 0.0415],\n",
      "         [ 0.0441],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0055],\n",
      "         [ 0.0671],\n",
      "         [-0.0410],\n",
      "         ...,\n",
      "         [ 0.0184],\n",
      "         [ 0.0184],\n",
      "         [ 0.0184]],\n",
      "\n",
      "        [[ 0.1115],\n",
      "         [-0.0048],\n",
      "         [ 0.0877],\n",
      "         ...,\n",
      "         [-0.0319],\n",
      "         [ 0.0036],\n",
      "         [-0.0135]],\n",
      "\n",
      "        [[ 0.0410],\n",
      "         [-0.0141],\n",
      "         [ 0.0107],\n",
      "         ...,\n",
      "         [ 0.0530],\n",
      "         [ 0.0530],\n",
      "         [ 0.0530]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0055],\n",
      "         [-0.0812],\n",
      "         [ 0.0495],\n",
      "         ...,\n",
      "         [ 0.0167],\n",
      "         [ 0.0167],\n",
      "         [ 0.0167]],\n",
      "\n",
      "        [[ 0.0838],\n",
      "         [ 0.0974],\n",
      "         [ 0.0083],\n",
      "         ...,\n",
      "         [ 0.1000],\n",
      "         [ 0.1000],\n",
      "         [ 0.1000]],\n",
      "\n",
      "        [[ 0.0480],\n",
      "         [ 0.1123],\n",
      "         [ 0.1081],\n",
      "         ...,\n",
      "         [ 0.0624],\n",
      "         [ 0.0624],\n",
      "         [ 0.0624]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0055],\n",
      "         [ 0.0671],\n",
      "         [-0.0410],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1115],\n",
      "         [-0.0048],\n",
      "         [ 0.0877],\n",
      "         ...,\n",
      "         [-0.0319],\n",
      "         [ 0.0036],\n",
      "         [-0.0135]],\n",
      "\n",
      "        [[ 0.0410],\n",
      "         [-0.0141],\n",
      "         [ 0.0107],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0055],\n",
      "         [-0.0812],\n",
      "         [ 0.0495],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0838],\n",
      "         [ 0.0974],\n",
      "         [ 0.0083],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0480],\n",
      "         [ 0.1123],\n",
      "         [ 0.1081],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0738],\n",
      "         [ 0.1379],\n",
      "         [ 0.0271],\n",
      "         ...,\n",
      "         [ 0.0877],\n",
      "         [ 0.0877],\n",
      "         [ 0.0877]],\n",
      "\n",
      "        [[ 0.1015],\n",
      "         [-0.0169],\n",
      "         [ 0.0782],\n",
      "         ...,\n",
      "         [-0.0415],\n",
      "         [-0.0051],\n",
      "         [-0.0241]],\n",
      "\n",
      "        [[-0.0873],\n",
      "         [-0.1406],\n",
      "         [-0.1136],\n",
      "         ...,\n",
      "         [-0.0763],\n",
      "         [-0.0763],\n",
      "         [-0.0763]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0131],\n",
      "         [-0.0750],\n",
      "         [ 0.0513],\n",
      "         ...,\n",
      "         [ 0.0260],\n",
      "         [ 0.0260],\n",
      "         [ 0.0260]],\n",
      "\n",
      "        [[ 0.1064],\n",
      "         [ 0.1220],\n",
      "         [ 0.0352],\n",
      "         ...,\n",
      "         [ 0.1212],\n",
      "         [ 0.1212],\n",
      "         [ 0.1212]],\n",
      "\n",
      "        [[ 0.0303],\n",
      "         [ 0.0925],\n",
      "         [ 0.0877],\n",
      "         ...,\n",
      "         [ 0.0447],\n",
      "         [ 0.0447],\n",
      "         [ 0.0447]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0738],\n",
      "         [ 0.1379],\n",
      "         [ 0.0271],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1015],\n",
      "         [-0.0169],\n",
      "         [ 0.0782],\n",
      "         ...,\n",
      "         [-0.0415],\n",
      "         [-0.0051],\n",
      "         [-0.0241]],\n",
      "\n",
      "        [[-0.0873],\n",
      "         [-0.1406],\n",
      "         [-0.1136],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0131],\n",
      "         [-0.0750],\n",
      "         [ 0.0513],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1064],\n",
      "         [ 0.1220],\n",
      "         [ 0.0352],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0303],\n",
      "         [ 0.0925],\n",
      "         [ 0.0877],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1232],\n",
      "         [ 0.1890],\n",
      "         [ 0.0771],\n",
      "         ...,\n",
      "         [ 0.1389],\n",
      "         [ 0.1389],\n",
      "         [ 0.1389]],\n",
      "\n",
      "        [[ 0.1773],\n",
      "         [ 0.0591],\n",
      "         [ 0.1534],\n",
      "         ...,\n",
      "         [ 0.0315],\n",
      "         [ 0.0675],\n",
      "         [ 0.0500]],\n",
      "\n",
      "        [[-0.0634],\n",
      "         [-0.1192],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0567],\n",
      "         [-0.0567],\n",
      "         [-0.0567]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0430],\n",
      "         [-0.0410],\n",
      "         [ 0.0867],\n",
      "         ...,\n",
      "         [ 0.0516],\n",
      "         [ 0.0516],\n",
      "         [ 0.0516]],\n",
      "\n",
      "        [[ 0.0833],\n",
      "         [ 0.0964],\n",
      "         [ 0.0079],\n",
      "         ...,\n",
      "         [ 0.0997],\n",
      "         [ 0.0997],\n",
      "         [ 0.0997]],\n",
      "\n",
      "        [[-0.0076],\n",
      "         [ 0.0532],\n",
      "         [ 0.0507],\n",
      "         ...,\n",
      "         [ 0.0065],\n",
      "         [ 0.0065],\n",
      "         [ 0.0065]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1232],\n",
      "         [ 0.1890],\n",
      "         [ 0.0771],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1773],\n",
      "         [ 0.0591],\n",
      "         [ 0.1534],\n",
      "         ...,\n",
      "         [ 0.0315],\n",
      "         [ 0.0675],\n",
      "         [ 0.0500]],\n",
      "\n",
      "        [[-0.0634],\n",
      "         [-0.1192],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0430],\n",
      "         [-0.0410],\n",
      "         [ 0.0867],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0833],\n",
      "         [ 0.0964],\n",
      "         [ 0.0079],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0076],\n",
      "         [ 0.0532],\n",
      "         [ 0.0507],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1161],\n",
      "         [ 0.1823],\n",
      "         [ 0.0744],\n",
      "         ...,\n",
      "         [ 0.1338],\n",
      "         [ 0.1338],\n",
      "         [ 0.1339]],\n",
      "\n",
      "        [[ 0.1258],\n",
      "         [ 0.0074],\n",
      "         [ 0.1015],\n",
      "         ...,\n",
      "         [-0.0191],\n",
      "         [ 0.0170],\n",
      "         [-0.0013]],\n",
      "\n",
      "        [[-0.0137],\n",
      "         [-0.0692],\n",
      "         [-0.0419],\n",
      "         ...,\n",
      "         [-0.0038],\n",
      "         [-0.0038],\n",
      "         [-0.0038]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0651],\n",
      "         [-0.0234],\n",
      "         [ 0.1033],\n",
      "         ...,\n",
      "         [ 0.0782],\n",
      "         [ 0.0782],\n",
      "         [ 0.0782]],\n",
      "\n",
      "        [[ 0.0113],\n",
      "         [ 0.0231],\n",
      "         [-0.0648],\n",
      "         ...,\n",
      "         [ 0.0271],\n",
      "         [ 0.0271],\n",
      "         [ 0.0271]],\n",
      "\n",
      "        [[ 0.1557],\n",
      "         [ 0.2193],\n",
      "         [ 0.2116],\n",
      "         ...,\n",
      "         [ 0.1722],\n",
      "         [ 0.1722],\n",
      "         [ 0.1722]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1161],\n",
      "         [ 0.1823],\n",
      "         [ 0.0744],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1258],\n",
      "         [ 0.0074],\n",
      "         [ 0.1015],\n",
      "         ...,\n",
      "         [-0.0191],\n",
      "         [ 0.0170],\n",
      "         [-0.0013]],\n",
      "\n",
      "        [[-0.0137],\n",
      "         [-0.0692],\n",
      "         [-0.0419],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0651],\n",
      "         [-0.0234],\n",
      "         [ 0.1033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0113],\n",
      "         [ 0.0231],\n",
      "         [-0.0648],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1557],\n",
      "         [ 0.2193],\n",
      "         [ 0.2116],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1113],\n",
      "         [ 0.1777],\n",
      "         [ 0.0710],\n",
      "         ...,\n",
      "         [ 0.1300],\n",
      "         [ 0.1300],\n",
      "         [ 0.1300]],\n",
      "\n",
      "        [[ 0.0076],\n",
      "         [-0.1061],\n",
      "         [-0.0148],\n",
      "         ...,\n",
      "         [-0.1275],\n",
      "         [-0.0921],\n",
      "         [-0.1123]],\n",
      "\n",
      "        [[ 0.1088],\n",
      "         [ 0.0554],\n",
      "         [ 0.0737],\n",
      "         ...,\n",
      "         [ 0.1247],\n",
      "         [ 0.1247],\n",
      "         [ 0.1247]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0318],\n",
      "         [-0.0572],\n",
      "         [ 0.0708],\n",
      "         ...,\n",
      "         [ 0.0436],\n",
      "         [ 0.0436],\n",
      "         [ 0.0436]],\n",
      "\n",
      "        [[ 0.0463],\n",
      "         [ 0.0626],\n",
      "         [-0.0223],\n",
      "         ...,\n",
      "         [ 0.0575],\n",
      "         [ 0.0575],\n",
      "         [ 0.0575]],\n",
      "\n",
      "        [[ 0.1235],\n",
      "         [ 0.1872],\n",
      "         [ 0.1804],\n",
      "         ...,\n",
      "         [ 0.1405],\n",
      "         [ 0.1405],\n",
      "         [ 0.1405]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1113],\n",
      "         [ 0.1777],\n",
      "         [ 0.0710],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0076],\n",
      "         [-0.1061],\n",
      "         [-0.0148],\n",
      "         ...,\n",
      "         [-0.1275],\n",
      "         [-0.0921],\n",
      "         [-0.1123]],\n",
      "\n",
      "        [[ 0.1088],\n",
      "         [ 0.0554],\n",
      "         [ 0.0737],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0318],\n",
      "         [-0.0572],\n",
      "         [ 0.0708],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0463],\n",
      "         [ 0.0626],\n",
      "         [-0.0223],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1235],\n",
      "         [ 0.1872],\n",
      "         [ 0.1804],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1123],\n",
      "         [ 0.1775],\n",
      "         [ 0.0684],\n",
      "         ...,\n",
      "         [ 0.1276],\n",
      "         [ 0.1276],\n",
      "         [ 0.1276]],\n",
      "\n",
      "        [[ 0.0362],\n",
      "         [-0.0811],\n",
      "         [ 0.0150],\n",
      "         ...,\n",
      "         [-0.1005],\n",
      "         [-0.0635],\n",
      "         [-0.0861]],\n",
      "\n",
      "        [[ 0.0874],\n",
      "         [ 0.0345],\n",
      "         [ 0.0519],\n",
      "         ...,\n",
      "         [ 0.1036],\n",
      "         [ 0.1036],\n",
      "         [ 0.1036]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0117],\n",
      "         [-0.0764],\n",
      "         [ 0.0523],\n",
      "         ...,\n",
      "         [ 0.0223],\n",
      "         [ 0.0223],\n",
      "         [ 0.0223]],\n",
      "\n",
      "        [[ 0.1027],\n",
      "         [ 0.1173],\n",
      "         [ 0.0286],\n",
      "         ...,\n",
      "         [ 0.1174],\n",
      "         [ 0.1174],\n",
      "         [ 0.1174]],\n",
      "\n",
      "        [[ 0.0690],\n",
      "         [ 0.1325],\n",
      "         [ 0.1277],\n",
      "         ...,\n",
      "         [ 0.0840],\n",
      "         [ 0.0840],\n",
      "         [ 0.0840]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1123],\n",
      "         [ 0.1775],\n",
      "         [ 0.0684],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0362],\n",
      "         [-0.0811],\n",
      "         [ 0.0150],\n",
      "         ...,\n",
      "         [-0.1005],\n",
      "         [-0.0635],\n",
      "         [-0.0861]],\n",
      "\n",
      "        [[ 0.0874],\n",
      "         [ 0.0345],\n",
      "         [ 0.0519],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0117],\n",
      "         [-0.0764],\n",
      "         [ 0.0523],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1027],\n",
      "         [ 0.1173],\n",
      "         [ 0.0286],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0690],\n",
      "         [ 0.1325],\n",
      "         [ 0.1277],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1103],\n",
      "         [ 0.1745],\n",
      "         [ 0.0646],\n",
      "         ...,\n",
      "         [ 0.1242],\n",
      "         [ 0.1242],\n",
      "         [ 0.1242]],\n",
      "\n",
      "        [[-0.0560],\n",
      "         [-0.1694],\n",
      "         [-0.0764],\n",
      "         ...,\n",
      "         [-0.1877],\n",
      "         [-0.1523],\n",
      "         [-0.1738]],\n",
      "\n",
      "        [[ 0.0380],\n",
      "         [-0.0161],\n",
      "         [ 0.0056],\n",
      "         ...,\n",
      "         [ 0.0514],\n",
      "         [ 0.0514],\n",
      "         [ 0.0514]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0003],\n",
      "         [-0.0873],\n",
      "         [ 0.0421],\n",
      "         ...,\n",
      "         [ 0.0100],\n",
      "         [ 0.0100],\n",
      "         [ 0.0100]],\n",
      "\n",
      "        [[ 0.1057],\n",
      "         [ 0.1199],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [ 0.1209],\n",
      "         [ 0.1209],\n",
      "         [ 0.1209]],\n",
      "\n",
      "        [[ 0.0337],\n",
      "         [ 0.0972],\n",
      "         [ 0.0949],\n",
      "         ...,\n",
      "         [ 0.0462],\n",
      "         [ 0.0462],\n",
      "         [ 0.0462]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1103],\n",
      "         [ 0.1745],\n",
      "         [ 0.0646],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0560],\n",
      "         [-0.1694],\n",
      "         [-0.0764],\n",
      "         ...,\n",
      "         [-0.1877],\n",
      "         [-0.1523],\n",
      "         [-0.1738]],\n",
      "\n",
      "        [[ 0.0380],\n",
      "         [-0.0161],\n",
      "         [ 0.0056],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0003],\n",
      "         [-0.0873],\n",
      "         [ 0.0421],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1057],\n",
      "         [ 0.1199],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0337],\n",
      "         [ 0.0972],\n",
      "         [ 0.0949],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0809],\n",
      "         [ 0.1451],\n",
      "         [ 0.0360],\n",
      "         ...,\n",
      "         [ 0.0954],\n",
      "         [ 0.0954],\n",
      "         [ 0.0954]],\n",
      "\n",
      "        [[ 0.0276],\n",
      "         [-0.0900],\n",
      "         [ 0.0032],\n",
      "         ...,\n",
      "         [-0.1181],\n",
      "         [-0.0833],\n",
      "         [-0.0991]],\n",
      "\n",
      "        [[ 0.0120],\n",
      "         [-0.0431],\n",
      "         [-0.0178],\n",
      "         ...,\n",
      "         [ 0.0230],\n",
      "         [ 0.0230],\n",
      "         [ 0.0230]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0060],\n",
      "         [-0.0933],\n",
      "         [ 0.0365],\n",
      "         ...,\n",
      "         [ 0.0032],\n",
      "         [ 0.0032],\n",
      "         [ 0.0032]],\n",
      "\n",
      "        [[ 0.1922],\n",
      "         [ 0.2044],\n",
      "         [ 0.1108],\n",
      "         ...,\n",
      "         [ 0.2111],\n",
      "         [ 0.2111],\n",
      "         [ 0.2111]],\n",
      "\n",
      "        [[ 0.0125],\n",
      "         [ 0.0760],\n",
      "         [ 0.0755],\n",
      "         ...,\n",
      "         [ 0.0231],\n",
      "         [ 0.0231],\n",
      "         [ 0.0231]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0809],\n",
      "         [ 0.1451],\n",
      "         [ 0.0360],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0276],\n",
      "         [-0.0900],\n",
      "         [ 0.0032],\n",
      "         ...,\n",
      "         [-0.1181],\n",
      "         [-0.0833],\n",
      "         [-0.0991]],\n",
      "\n",
      "        [[ 0.0120],\n",
      "         [-0.0431],\n",
      "         [-0.0178],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0060],\n",
      "         [-0.0933],\n",
      "         [ 0.0365],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1922],\n",
      "         [ 0.2044],\n",
      "         [ 0.1108],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0125],\n",
      "         [ 0.0760],\n",
      "         [ 0.0755],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 2.2262e-02],\n",
      "         [ 8.5418e-02],\n",
      "         [-2.3155e-02],\n",
      "         ...,\n",
      "         [ 3.7061e-02],\n",
      "         [ 3.7074e-02],\n",
      "         [ 3.7083e-02]],\n",
      "\n",
      "        [[ 7.5504e-02],\n",
      "         [-4.2765e-02],\n",
      "         [ 5.2343e-02],\n",
      "         ...,\n",
      "         [-6.6893e-02],\n",
      "         [-3.0590e-02],\n",
      "         [-5.0532e-02]],\n",
      "\n",
      "        [[-1.8860e-03],\n",
      "         [-5.7597e-02],\n",
      "         [-3.0134e-02],\n",
      "         ...,\n",
      "         [ 7.6474e-03],\n",
      "         [ 7.6476e-03],\n",
      "         [ 7.6477e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.3844e-03],\n",
      "         [-9.6538e-02],\n",
      "         [ 3.3464e-02],\n",
      "         ...,\n",
      "         [-4.0586e-04],\n",
      "         [-4.0574e-04],\n",
      "         [-4.0568e-04]],\n",
      "\n",
      "        [[ 3.8555e-02],\n",
      "         [ 5.1608e-02],\n",
      "         [-3.3852e-02],\n",
      "         ...,\n",
      "         [ 5.2930e-02],\n",
      "         [ 5.2931e-02],\n",
      "         [ 5.2931e-02]],\n",
      "\n",
      "        [[ 5.0128e-05],\n",
      "         [ 6.3533e-02],\n",
      "         [ 6.4177e-02],\n",
      "         ...,\n",
      "         [ 9.4272e-03],\n",
      "         [ 9.4276e-03],\n",
      "         [ 9.4279e-03]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 2.2262e-02],\n",
      "         [ 8.5418e-02],\n",
      "         [-2.3155e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 7.5504e-02],\n",
      "         [-4.2765e-02],\n",
      "         [ 5.2343e-02],\n",
      "         ...,\n",
      "         [-6.6893e-02],\n",
      "         [-3.0590e-02],\n",
      "         [-5.0532e-02]],\n",
      "\n",
      "        [[-1.8860e-03],\n",
      "         [-5.7597e-02],\n",
      "         [-3.0134e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.3844e-03],\n",
      "         [-9.6538e-02],\n",
      "         [ 3.3464e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 3.8555e-02],\n",
      "         [ 5.1608e-02],\n",
      "         [-3.3852e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 5.0128e-05],\n",
      "         [ 6.3533e-02],\n",
      "         [ 6.4177e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0156],\n",
      "         [ 0.0438],\n",
      "         [-0.0629],\n",
      "         ...,\n",
      "         [-0.0053],\n",
      "         [-0.0052],\n",
      "         [-0.0052]],\n",
      "\n",
      "        [[ 0.2111],\n",
      "         [ 0.0927],\n",
      "         [ 0.1840],\n",
      "         ...,\n",
      "         [ 0.0585],\n",
      "         [ 0.0935],\n",
      "         [ 0.0807]],\n",
      "\n",
      "        [[-0.0094],\n",
      "         [-0.0655],\n",
      "         [-0.0368],\n",
      "         ...,\n",
      "         [-0.0007],\n",
      "         [-0.0007],\n",
      "         [-0.0007]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0112],\n",
      "         [-0.0983],\n",
      "         [ 0.0318],\n",
      "         ...,\n",
      "         [-0.0023],\n",
      "         [-0.0023],\n",
      "         [-0.0023]],\n",
      "\n",
      "        [[ 0.0552],\n",
      "         [ 0.0680],\n",
      "         [-0.0204],\n",
      "         ...,\n",
      "         [ 0.0708],\n",
      "         [ 0.0708],\n",
      "         [ 0.0708]],\n",
      "\n",
      "        [[-0.0072],\n",
      "         [ 0.0563],\n",
      "         [ 0.0576],\n",
      "         ...,\n",
      "         [ 0.0015],\n",
      "         [ 0.0015],\n",
      "         [ 0.0015]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0156],\n",
      "         [ 0.0438],\n",
      "         [-0.0629],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2111],\n",
      "         [ 0.0927],\n",
      "         [ 0.1840],\n",
      "         ...,\n",
      "         [ 0.0585],\n",
      "         [ 0.0935],\n",
      "         [ 0.0807]],\n",
      "\n",
      "        [[-0.0094],\n",
      "         [-0.0655],\n",
      "         [-0.0368],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0112],\n",
      "         [-0.0983],\n",
      "         [ 0.0318],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0552],\n",
      "         [ 0.0680],\n",
      "         [-0.0204],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0072],\n",
      "         [ 0.0563],\n",
      "         [ 0.0576],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0871],\n",
      "         [ 0.1499],\n",
      "         [ 0.0402],\n",
      "         ...,\n",
      "         [ 0.0989],\n",
      "         [ 0.0989],\n",
      "         [ 0.0989]],\n",
      "\n",
      "        [[ 0.0607],\n",
      "         [-0.0540],\n",
      "         [ 0.0360],\n",
      "         ...,\n",
      "         [-0.0804],\n",
      "         [-0.0453],\n",
      "         [-0.0625]],\n",
      "\n",
      "        [[-0.0136],\n",
      "         [-0.0698],\n",
      "         [-0.0405],\n",
      "         ...,\n",
      "         [-0.0053],\n",
      "         [-0.0053],\n",
      "         [-0.0053]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0992],\n",
      "         [ 0.0310],\n",
      "         ...,\n",
      "         [-0.0033],\n",
      "         [-0.0033],\n",
      "         [-0.0033]],\n",
      "\n",
      "        [[ 0.0183],\n",
      "         [ 0.0327],\n",
      "         [-0.0528],\n",
      "         ...,\n",
      "         [ 0.0309],\n",
      "         [ 0.0309],\n",
      "         [ 0.0309]],\n",
      "\n",
      "        [[-0.0113],\n",
      "         [ 0.0522],\n",
      "         [ 0.0538],\n",
      "         ...,\n",
      "         [-0.0031],\n",
      "         [-0.0031],\n",
      "         [-0.0031]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0871],\n",
      "         [ 0.1499],\n",
      "         [ 0.0402],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0607],\n",
      "         [-0.0540],\n",
      "         [ 0.0360],\n",
      "         ...,\n",
      "         [-0.0804],\n",
      "         [-0.0453],\n",
      "         [-0.0625]],\n",
      "\n",
      "        [[-0.0136],\n",
      "         [-0.0698],\n",
      "         [-0.0405],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0992],\n",
      "         [ 0.0310],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0183],\n",
      "         [ 0.0327],\n",
      "         [-0.0528],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0113],\n",
      "         [ 0.0522],\n",
      "         [ 0.0538],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0806],\n",
      "         [ 0.1449],\n",
      "         [ 0.0363],\n",
      "         ...,\n",
      "         [ 0.0947],\n",
      "         [ 0.0947],\n",
      "         [ 0.0947]],\n",
      "\n",
      "        [[ 0.1320],\n",
      "         [ 0.0147],\n",
      "         [ 0.1069],\n",
      "         ...,\n",
      "         [-0.0142],\n",
      "         [ 0.0214],\n",
      "         [ 0.0055]],\n",
      "\n",
      "        [[-0.0158],\n",
      "         [-0.0721],\n",
      "         [-0.0425],\n",
      "         ...,\n",
      "         [-0.0077],\n",
      "         [-0.0077],\n",
      "         [-0.0077]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0125],\n",
      "         [-0.0997],\n",
      "         [ 0.0306],\n",
      "         ...,\n",
      "         [-0.0037],\n",
      "         [-0.0037],\n",
      "         [-0.0037]],\n",
      "\n",
      "        [[-0.0013],\n",
      "         [ 0.0142],\n",
      "         [-0.0697],\n",
      "         ...,\n",
      "         [ 0.0092],\n",
      "         [ 0.0092],\n",
      "         [ 0.0092]],\n",
      "\n",
      "        [[-0.0137],\n",
      "         [ 0.0498],\n",
      "         [ 0.0516],\n",
      "         ...,\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0806],\n",
      "         [ 0.1449],\n",
      "         [ 0.0363],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1320],\n",
      "         [ 0.0147],\n",
      "         [ 0.1069],\n",
      "         ...,\n",
      "         [-0.0142],\n",
      "         [ 0.0214],\n",
      "         [ 0.0055]],\n",
      "\n",
      "        [[-0.0158],\n",
      "         [-0.0721],\n",
      "         [-0.0425],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0125],\n",
      "         [-0.0997],\n",
      "         [ 0.0306],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0013],\n",
      "         [ 0.0142],\n",
      "         [-0.0697],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0137],\n",
      "         [ 0.0498],\n",
      "         [ 0.0516],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0853],\n",
      "         [ 0.1491],\n",
      "         [ 0.0406],\n",
      "         ...,\n",
      "         [ 0.0990],\n",
      "         [ 0.0990],\n",
      "         [ 0.0990]],\n",
      "\n",
      "        [[ 0.0313],\n",
      "         [-0.0830],\n",
      "         [ 0.0095],\n",
      "         ...,\n",
      "         [-0.1036],\n",
      "         [-0.0676],\n",
      "         [-0.0885]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [-0.0733],\n",
      "         [-0.0436],\n",
      "         ...,\n",
      "         [-0.0090],\n",
      "         [-0.0090],\n",
      "         [-0.0090]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.0999],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [ 0.0041],\n",
      "         [-0.0790],\n",
      "         ...,\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0027]],\n",
      "\n",
      "        [[-0.0151],\n",
      "         [ 0.0484],\n",
      "         [ 0.0503],\n",
      "         ...,\n",
      "         [-0.0073],\n",
      "         [-0.0073],\n",
      "         [-0.0073]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0853],\n",
      "         [ 0.1491],\n",
      "         [ 0.0406],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0313],\n",
      "         [-0.0830],\n",
      "         [ 0.0095],\n",
      "         ...,\n",
      "         [-0.1036],\n",
      "         [-0.0676],\n",
      "         [-0.0885]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [-0.0733],\n",
      "         [-0.0436],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.0999],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [ 0.0041],\n",
      "         [-0.0790],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0151],\n",
      "         [ 0.0484],\n",
      "         [ 0.0503],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0148],\n",
      "         [ 0.0755],\n",
      "         [-0.0322],\n",
      "         ...,\n",
      "         [ 0.0262],\n",
      "         [ 0.0262],\n",
      "         [ 0.0262]],\n",
      "\n",
      "        [[ 0.0654],\n",
      "         [-0.0520],\n",
      "         [ 0.0446],\n",
      "         ...,\n",
      "         [-0.0712],\n",
      "         [-0.0340],\n",
      "         [-0.0563]],\n",
      "\n",
      "        [[-0.0175],\n",
      "         [-0.0739],\n",
      "         [-0.0442],\n",
      "         ...,\n",
      "         [-0.0097],\n",
      "         [-0.0097],\n",
      "         [-0.0097]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0040],\n",
      "         [-0.0040],\n",
      "         [-0.0040]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0015],\n",
      "         [-0.0842],\n",
      "         ...,\n",
      "         [-0.0093],\n",
      "         [-0.0093],\n",
      "         [-0.0093]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0475],\n",
      "         [ 0.0495],\n",
      "         ...,\n",
      "         [-0.0082],\n",
      "         [-0.0082],\n",
      "         [-0.0082]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0148],\n",
      "         [ 0.0755],\n",
      "         [-0.0322],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0654],\n",
      "         [-0.0520],\n",
      "         [ 0.0446],\n",
      "         ...,\n",
      "         [-0.0712],\n",
      "         [-0.0340],\n",
      "         [-0.0563]],\n",
      "\n",
      "        [[-0.0175],\n",
      "         [-0.0739],\n",
      "         [-0.0442],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0015],\n",
      "         [-0.0842],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0475],\n",
      "         [ 0.0495],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0174],\n",
      "         [ 0.0430],\n",
      "         [-0.0651],\n",
      "         ...,\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0058]],\n",
      "\n",
      "        [[ 0.0732],\n",
      "         [-0.0446],\n",
      "         [ 0.0528],\n",
      "         ...,\n",
      "         [-0.0629],\n",
      "         [-0.0254],\n",
      "         [-0.0485]],\n",
      "\n",
      "        [[-0.0178],\n",
      "         [-0.0742],\n",
      "         [-0.0445],\n",
      "         ...,\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0040],\n",
      "         [-0.0040],\n",
      "         [-0.0040]],\n",
      "\n",
      "        [[-0.0213],\n",
      "         [-0.0045],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0129],\n",
      "         [-0.0129],\n",
      "         [-0.0129]],\n",
      "\n",
      "        [[-0.0164],\n",
      "         [ 0.0470],\n",
      "         [ 0.0491],\n",
      "         ...,\n",
      "         [-0.0087],\n",
      "         [-0.0087],\n",
      "         [-0.0087]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0174],\n",
      "         [ 0.0430],\n",
      "         [-0.0651],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0732],\n",
      "         [-0.0446],\n",
      "         [ 0.0528],\n",
      "         ...,\n",
      "         [-0.0629],\n",
      "         [-0.0254],\n",
      "         [-0.0485]],\n",
      "\n",
      "        [[-0.0178],\n",
      "         [-0.0742],\n",
      "         [-0.0445],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0213],\n",
      "         [-0.0045],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0164],\n",
      "         [ 0.0470],\n",
      "         [ 0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1097],\n",
      "         [ 0.1750],\n",
      "         [ 0.0651],\n",
      "         ...,\n",
      "         [ 0.1246],\n",
      "         [ 0.1246],\n",
      "         [ 0.1246]],\n",
      "\n",
      "        [[ 0.0524],\n",
      "         [-0.0643],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [-0.0856],\n",
      "         [-0.0492],\n",
      "         [-0.0699]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0446],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0040],\n",
      "         [-0.0040],\n",
      "         [-0.0040]],\n",
      "\n",
      "        [[-0.0231],\n",
      "         [-0.0062],\n",
      "         [-0.0888],\n",
      "         ...,\n",
      "         [-0.0149],\n",
      "         [-0.0149],\n",
      "         [-0.0149]],\n",
      "\n",
      "        [[-0.0167],\n",
      "         [ 0.0468],\n",
      "         [ 0.0488],\n",
      "         ...,\n",
      "         [-0.0090],\n",
      "         [-0.0090],\n",
      "         [-0.0090]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1097],\n",
      "         [ 0.1750],\n",
      "         [ 0.0651],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0524],\n",
      "         [-0.0643],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [-0.0856],\n",
      "         [-0.0492],\n",
      "         [-0.0699]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0446],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0231],\n",
      "         [-0.0062],\n",
      "         [-0.0888],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0167],\n",
      "         [ 0.0468],\n",
      "         [ 0.0488],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0750],\n",
      "         [ 0.1396],\n",
      "         [ 0.0286],\n",
      "         ...,\n",
      "         [ 0.0895],\n",
      "         [ 0.0895],\n",
      "         [ 0.0895]],\n",
      "\n",
      "        [[ 0.0695],\n",
      "         [-0.0480],\n",
      "         [ 0.0460],\n",
      "         ...,\n",
      "         [-0.0731],\n",
      "         [-0.0373],\n",
      "         [-0.0559]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0040],\n",
      "         [-0.0040],\n",
      "         [-0.0040]],\n",
      "\n",
      "        [[-0.0240],\n",
      "         [-0.0071],\n",
      "         [-0.0897],\n",
      "         ...,\n",
      "         [-0.0160],\n",
      "         [-0.0160],\n",
      "         [-0.0160]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [ 0.0466],\n",
      "         [ 0.0486],\n",
      "         ...,\n",
      "         [-0.0092],\n",
      "         [-0.0092],\n",
      "         [-0.0092]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0750],\n",
      "         [ 0.1396],\n",
      "         [ 0.0286],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0695],\n",
      "         [-0.0480],\n",
      "         [ 0.0460],\n",
      "         ...,\n",
      "         [-0.0731],\n",
      "         [-0.0373],\n",
      "         [-0.0559]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0240],\n",
      "         [-0.0071],\n",
      "         [-0.0897],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [ 0.0466],\n",
      "         [ 0.0486],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0178],\n",
      "         [ 0.0413],\n",
      "         [-0.0659],\n",
      "         ...,\n",
      "         [-0.0078],\n",
      "         [-0.0078],\n",
      "         [-0.0078]],\n",
      "\n",
      "        [[ 0.1034],\n",
      "         [-0.0151],\n",
      "         [ 0.0812],\n",
      "         ...,\n",
      "         [-0.0376],\n",
      "         [-0.0008],\n",
      "         [-0.0216]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0040],\n",
      "         [-0.0040],\n",
      "         [-0.0040]],\n",
      "\n",
      "        [[-0.0245],\n",
      "         [-0.0076],\n",
      "         [-0.0902],\n",
      "         ...,\n",
      "         [-0.0165],\n",
      "         [-0.0165],\n",
      "         [-0.0165]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [ 0.0465],\n",
      "         [ 0.0485],\n",
      "         ...,\n",
      "         [-0.0093],\n",
      "         [-0.0093],\n",
      "         [-0.0093]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0178],\n",
      "         [ 0.0413],\n",
      "         [-0.0659],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1034],\n",
      "         [-0.0151],\n",
      "         [ 0.0812],\n",
      "         ...,\n",
      "         [-0.0376],\n",
      "         [-0.0008],\n",
      "         [-0.0216]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0245],\n",
      "         [-0.0076],\n",
      "         [-0.0902],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [ 0.0465],\n",
      "         [ 0.0485],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0117],\n",
      "         [ 0.0424],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [-0.0076],\n",
      "         [-0.0076],\n",
      "         [-0.0076]],\n",
      "\n",
      "        [[-0.0255],\n",
      "         [-0.1384],\n",
      "         [-0.0457],\n",
      "         ...,\n",
      "         [-0.1560],\n",
      "         [-0.1203],\n",
      "         [-0.1428]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0248],\n",
      "         [-0.0079],\n",
      "         [-0.0905],\n",
      "         ...,\n",
      "         [-0.0168],\n",
      "         [-0.0168],\n",
      "         [-0.0168]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0464],\n",
      "         [ 0.0484],\n",
      "         ...,\n",
      "         [-0.0094],\n",
      "         [-0.0094],\n",
      "         [-0.0094]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0117],\n",
      "         [ 0.0424],\n",
      "         [-0.0617],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0255],\n",
      "         [-0.1384],\n",
      "         [-0.0457],\n",
      "         ...,\n",
      "         [-0.1560],\n",
      "         [-0.1203],\n",
      "         [-0.1428]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0248],\n",
      "         [-0.0079],\n",
      "         [-0.0905],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0464],\n",
      "         [ 0.0484],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0674],\n",
      "         [-0.0126],\n",
      "         [-0.1162],\n",
      "         ...,\n",
      "         [-0.0609],\n",
      "         [-0.0609],\n",
      "         [-0.0609]],\n",
      "\n",
      "        [[ 0.0306],\n",
      "         [-0.0849],\n",
      "         [ 0.0096],\n",
      "         ...,\n",
      "         [-0.1049],\n",
      "         [-0.0687],\n",
      "         [-0.0903]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0249],\n",
      "         [-0.0080],\n",
      "         [-0.0906],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0463],\n",
      "         [ 0.0484],\n",
      "         ...,\n",
      "         [-0.0095],\n",
      "         [-0.0095],\n",
      "         [-0.0095]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0674],\n",
      "         [-0.0126],\n",
      "         [-0.1162],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0306],\n",
      "         [-0.0849],\n",
      "         [ 0.0096],\n",
      "         ...,\n",
      "         [-0.1049],\n",
      "         [-0.0687],\n",
      "         [-0.0903]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0249],\n",
      "         [-0.0080],\n",
      "         [-0.0906],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0463],\n",
      "         [ 0.0484],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0265],\n",
      "         [ 0.0319],\n",
      "         [-0.0738],\n",
      "         ...,\n",
      "         [-0.0169],\n",
      "         [-0.0169],\n",
      "         [-0.0169]],\n",
      "\n",
      "        [[ 0.0210],\n",
      "         [-0.0937],\n",
      "         [-0.0023],\n",
      "         ...,\n",
      "         [-0.1184],\n",
      "         [-0.0839],\n",
      "         [-0.1012]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0250],\n",
      "         [-0.0081],\n",
      "         [-0.0907],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0463],\n",
      "         [ 0.0484],\n",
      "         ...,\n",
      "         [-0.0095],\n",
      "         [-0.0095],\n",
      "         [-0.0095]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0265],\n",
      "         [ 0.0319],\n",
      "         [-0.0738],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0210],\n",
      "         [-0.0937],\n",
      "         [-0.0023],\n",
      "         ...,\n",
      "         [-0.1184],\n",
      "         [-0.0839],\n",
      "         [-0.1012]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0250],\n",
      "         [-0.0081],\n",
      "         [-0.0907],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0463],\n",
      "         [ 0.0484],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0474],\n",
      "         [ 0.1115],\n",
      "         [ 0.0027],\n",
      "         ...,\n",
      "         [ 0.0621],\n",
      "         [ 0.0621],\n",
      "         [ 0.0621]],\n",
      "\n",
      "        [[ 0.1039],\n",
      "         [-0.0126],\n",
      "         [ 0.0810],\n",
      "         ...,\n",
      "         [-0.0379],\n",
      "         [-0.0020],\n",
      "         [-0.0203]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0250],\n",
      "         [-0.0081],\n",
      "         [-0.0907],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0463],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0095],\n",
      "         [-0.0095],\n",
      "         [-0.0095]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0474],\n",
      "         [ 0.1115],\n",
      "         [ 0.0027],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1039],\n",
      "         [-0.0126],\n",
      "         [ 0.0810],\n",
      "         ...,\n",
      "         [-0.0379],\n",
      "         [-0.0020],\n",
      "         [-0.0203]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0745],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0250],\n",
      "         [-0.0081],\n",
      "         [-0.0907],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0463],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0262],\n",
      "         [ 0.0886],\n",
      "         [-0.0202],\n",
      "         ...,\n",
      "         [ 0.0391],\n",
      "         [ 0.0392],\n",
      "         [ 0.0392]],\n",
      "\n",
      "        [[ 0.0970],\n",
      "         [-0.0215],\n",
      "         [ 0.0743],\n",
      "         ...,\n",
      "         [-0.0450],\n",
      "         [-0.0082],\n",
      "         [-0.0280]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0171],\n",
      "         [-0.0171],\n",
      "         [-0.0171]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0095],\n",
      "         [-0.0095],\n",
      "         [-0.0095]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0262],\n",
      "         [ 0.0886],\n",
      "         [-0.0202],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0970],\n",
      "         [-0.0215],\n",
      "         [ 0.0743],\n",
      "         ...,\n",
      "         [-0.0450],\n",
      "         [-0.0082],\n",
      "         [-0.0280]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0122],\n",
      "         [ 0.0732],\n",
      "         [-0.0352],\n",
      "         ...,\n",
      "         [ 0.0237],\n",
      "         [ 0.0237],\n",
      "         [ 0.0237]],\n",
      "\n",
      "        [[ 0.1761],\n",
      "         [ 0.0579],\n",
      "         [ 0.1525],\n",
      "         ...,\n",
      "         [ 0.0307],\n",
      "         [ 0.0668],\n",
      "         [ 0.0490]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0171],\n",
      "         [-0.0171],\n",
      "         [-0.0171]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0095]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0122],\n",
      "         [ 0.0732],\n",
      "         [-0.0352],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1761],\n",
      "         [ 0.0579],\n",
      "         [ 0.1525],\n",
      "         ...,\n",
      "         [ 0.0307],\n",
      "         [ 0.0668],\n",
      "         [ 0.0490]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0036],\n",
      "         [ 0.0637],\n",
      "         [-0.0443],\n",
      "         ...,\n",
      "         [ 0.0141],\n",
      "         [ 0.0141],\n",
      "         [ 0.0141]],\n",
      "\n",
      "        [[ 0.1376],\n",
      "         [ 0.0189],\n",
      "         [ 0.1148],\n",
      "         ...,\n",
      "         [-0.0046],\n",
      "         [ 0.0321],\n",
      "         [ 0.0119]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0171],\n",
      "         [-0.0171],\n",
      "         [-0.0171]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0036],\n",
      "         [ 0.0637],\n",
      "         [-0.0443],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1376],\n",
      "         [ 0.0189],\n",
      "         [ 0.1148],\n",
      "         ...,\n",
      "         [-0.0046],\n",
      "         [ 0.0321],\n",
      "         [ 0.0119]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0015],\n",
      "         [ 0.0581],\n",
      "         [-0.0497],\n",
      "         ...,\n",
      "         [ 0.0084],\n",
      "         [ 0.0084],\n",
      "         [ 0.0085]],\n",
      "\n",
      "        [[ 0.0731],\n",
      "         [-0.0423],\n",
      "         [ 0.0488],\n",
      "         ...,\n",
      "         [-0.0686],\n",
      "         [-0.0332],\n",
      "         [-0.0506]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0171],\n",
      "         [-0.0171],\n",
      "         [-0.0171]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0015],\n",
      "         [ 0.0581],\n",
      "         [-0.0497],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0731],\n",
      "         [-0.0423],\n",
      "         [ 0.0488],\n",
      "         ...,\n",
      "         [-0.0686],\n",
      "         [-0.0332],\n",
      "         [-0.0506]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0044],\n",
      "         [ 0.0549],\n",
      "         [-0.0529],\n",
      "         ...,\n",
      "         [ 0.0052],\n",
      "         [ 0.0052],\n",
      "         [ 0.0052]],\n",
      "\n",
      "        [[ 0.1466],\n",
      "         [ 0.0310],\n",
      "         [ 0.1183],\n",
      "         ...,\n",
      "         [-0.0060],\n",
      "         [ 0.0270],\n",
      "         [ 0.0176]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0044],\n",
      "         [ 0.0549],\n",
      "         [-0.0529],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1466],\n",
      "         [ 0.0310],\n",
      "         [ 0.1183],\n",
      "         ...,\n",
      "         [-0.0060],\n",
      "         [ 0.0270],\n",
      "         [ 0.0176]],\n",
      "\n",
      "        [[-0.0181],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0061],\n",
      "         [ 0.0531],\n",
      "         [-0.0546],\n",
      "         ...,\n",
      "         [ 0.0034],\n",
      "         [ 0.0034],\n",
      "         [ 0.0034]],\n",
      "\n",
      "        [[ 0.0949],\n",
      "         [-0.0233],\n",
      "         [ 0.0697],\n",
      "         ...,\n",
      "         [-0.0519],\n",
      "         [-0.0165],\n",
      "         [-0.0333]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0061],\n",
      "         [ 0.0531],\n",
      "         [-0.0546],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0949],\n",
      "         [-0.0233],\n",
      "         [ 0.0697],\n",
      "         ...,\n",
      "         [-0.0519],\n",
      "         [-0.0165],\n",
      "         [-0.0333]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0070],\n",
      "         [ 0.0522],\n",
      "         [-0.0556],\n",
      "         ...,\n",
      "         [ 0.0024],\n",
      "         [ 0.0024],\n",
      "         [ 0.0024]],\n",
      "\n",
      "        [[ 0.2082],\n",
      "         [ 0.0930],\n",
      "         [ 0.1781],\n",
      "         ...,\n",
      "         [ 0.0518],\n",
      "         [ 0.0844],\n",
      "         [ 0.0774]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0070],\n",
      "         [ 0.0522],\n",
      "         [-0.0556],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2082],\n",
      "         [ 0.0930],\n",
      "         [ 0.1781],\n",
      "         ...,\n",
      "         [ 0.0518],\n",
      "         [ 0.0844],\n",
      "         [ 0.0774]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0075],\n",
      "         [ 0.0516],\n",
      "         [-0.0561],\n",
      "         ...,\n",
      "         [ 0.0019],\n",
      "         [ 0.0019],\n",
      "         [ 0.0019]],\n",
      "\n",
      "        [[ 0.0927],\n",
      "         [-0.0211],\n",
      "         [ 0.0641],\n",
      "         ...,\n",
      "         [-0.0570],\n",
      "         [-0.0250],\n",
      "         [-0.0343]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0075],\n",
      "         [ 0.0516],\n",
      "         [-0.0561],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0927],\n",
      "         [-0.0211],\n",
      "         [ 0.0641],\n",
      "         ...,\n",
      "         [-0.0570],\n",
      "         [-0.0250],\n",
      "         [-0.0343]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0078],\n",
      "         [ 0.0514],\n",
      "         [-0.0564],\n",
      "         ...,\n",
      "         [ 0.0016],\n",
      "         [ 0.0016],\n",
      "         [ 0.0016]],\n",
      "\n",
      "        [[ 0.0883],\n",
      "         [-0.0258],\n",
      "         [ 0.0602],\n",
      "         ...,\n",
      "         [-0.0614],\n",
      "         [-0.0295],\n",
      "         [-0.0386]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0078],\n",
      "         [ 0.0514],\n",
      "         [-0.0564],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0883],\n",
      "         [-0.0258],\n",
      "         [ 0.0602],\n",
      "         ...,\n",
      "         [-0.0614],\n",
      "         [-0.0295],\n",
      "         [-0.0386]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0079],\n",
      "         [ 0.0513],\n",
      "         [-0.0565],\n",
      "         ...,\n",
      "         [ 0.0015],\n",
      "         [ 0.0015],\n",
      "         [ 0.0015]],\n",
      "\n",
      "        [[ 0.0853],\n",
      "         [-0.0314],\n",
      "         [ 0.0617],\n",
      "         ...,\n",
      "         [-0.0576],\n",
      "         [-0.0220],\n",
      "         [-0.0399]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0079],\n",
      "         [ 0.0513],\n",
      "         [-0.0565],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0853],\n",
      "         [-0.0314],\n",
      "         [ 0.0617],\n",
      "         ...,\n",
      "         [-0.0576],\n",
      "         [-0.0220],\n",
      "         [-0.0399]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0079],\n",
      "         [ 0.0512],\n",
      "         [-0.0566],\n",
      "         ...,\n",
      "         [ 0.0014],\n",
      "         [ 0.0015],\n",
      "         [ 0.0015]],\n",
      "\n",
      "        [[ 0.0613],\n",
      "         [-0.0573],\n",
      "         [ 0.0385],\n",
      "         ...,\n",
      "         [-0.0810],\n",
      "         [-0.0445],\n",
      "         [-0.0649]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0079],\n",
      "         [ 0.0512],\n",
      "         [-0.0566],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0613],\n",
      "         [-0.0573],\n",
      "         [ 0.0385],\n",
      "         ...,\n",
      "         [-0.0810],\n",
      "         [-0.0445],\n",
      "         [-0.0649]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0079],\n",
      "         [ 0.0512],\n",
      "         [-0.0566],\n",
      "         ...,\n",
      "         [ 0.0014],\n",
      "         [ 0.0015],\n",
      "         [ 0.0015]],\n",
      "\n",
      "        [[ 0.0481],\n",
      "         [-0.0666],\n",
      "         [ 0.0239],\n",
      "         ...,\n",
      "         [-0.0934],\n",
      "         [-0.0588],\n",
      "         [-0.0754]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0079],\n",
      "         [ 0.0512],\n",
      "         [-0.0566],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0481],\n",
      "         [-0.0666],\n",
      "         [ 0.0239],\n",
      "         ...,\n",
      "         [-0.0934],\n",
      "         [-0.0588],\n",
      "         [-0.0754]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0079],\n",
      "         [ 0.0513],\n",
      "         [-0.0566],\n",
      "         ...,\n",
      "         [ 0.0015],\n",
      "         [ 0.0015],\n",
      "         [ 0.0015]],\n",
      "\n",
      "        [[ 0.0700],\n",
      "         [-0.0449],\n",
      "         [ 0.0448],\n",
      "         ...,\n",
      "         [-0.0750],\n",
      "         [-0.0411],\n",
      "         [-0.0553]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0101],\n",
      "         [-0.0101]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0250],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0096],\n",
      "         [-0.0096]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0079],\n",
      "         [ 0.0513],\n",
      "         [-0.0566],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0700],\n",
      "         [-0.0449],\n",
      "         [ 0.0448],\n",
      "         ...,\n",
      "         [-0.0750],\n",
      "         [-0.0411],\n",
      "         [-0.0553]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [-0.0744],\n",
      "         [-0.0447],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0127],\n",
      "         [-0.1000],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0250],\n",
      "         [-0.0081],\n",
      "         [-0.0908],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0462],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/25000 [00:01<3:52:56,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот в AttentiveModel сделали mask. Она выглядит так:\n",
      "torch.BoolTensor\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2034],\n",
      "         [0.1282],\n",
      "         [0.0649],\n",
      "         ...,\n",
      "         [0.2141],\n",
      "         [0.2144],\n",
      "         [0.2145]],\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2056],\n",
      "         [0.1730],\n",
      "         ...,\n",
      "         [0.2149],\n",
      "         [0.2149],\n",
      "         [0.2149]],\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2421],\n",
      "         [0.2450],\n",
      "         ...,\n",
      "         [0.2148],\n",
      "         [0.2148],\n",
      "         [0.2148]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2826],\n",
      "         [0.2815],\n",
      "         ...,\n",
      "         [0.2139],\n",
      "         [0.2142],\n",
      "         [0.2144]],\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2056],\n",
      "         [0.1193],\n",
      "         ...,\n",
      "         [0.2147],\n",
      "         [0.2147],\n",
      "         [0.2148]],\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2202],\n",
      "         [0.2263],\n",
      "         ...,\n",
      "         [0.2149],\n",
      "         [0.2149],\n",
      "         [0.2149]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2034],\n",
      "         [0.1282],\n",
      "         [0.0649],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2056],\n",
      "         [0.1730],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2421],\n",
      "         [0.2450],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2826],\n",
      "         [0.2815],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2056],\n",
      "         [0.1193],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2034],\n",
      "         [0.2202],\n",
      "         [0.2263],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1350],\n",
      "         [ 0.0583],\n",
      "         [-0.0032],\n",
      "         ...,\n",
      "         [ 0.1469],\n",
      "         [ 0.1471],\n",
      "         [ 0.1473]],\n",
      "\n",
      "        [[ 0.1403],\n",
      "         [ 0.1423],\n",
      "         [ 0.1109],\n",
      "         ...,\n",
      "         [ 0.1529],\n",
      "         [ 0.1529],\n",
      "         [ 0.1529]],\n",
      "\n",
      "        [[ 0.1403],\n",
      "         [ 0.1782],\n",
      "         [ 0.1800],\n",
      "         ...,\n",
      "         [ 0.1532],\n",
      "         [ 0.1532],\n",
      "         [ 0.1532]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1409],\n",
      "         [ 0.2193],\n",
      "         [ 0.2173],\n",
      "         ...,\n",
      "         [ 0.1527],\n",
      "         [ 0.1531],\n",
      "         [ 0.1533]],\n",
      "\n",
      "        [[ 0.1373],\n",
      "         [ 0.1392],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [ 0.1500],\n",
      "         [ 0.1500],\n",
      "         [ 0.1501]],\n",
      "\n",
      "        [[ 0.1310],\n",
      "         [ 0.1473],\n",
      "         [ 0.1552],\n",
      "         ...,\n",
      "         [ 0.1435],\n",
      "         [ 0.1435],\n",
      "         [ 0.1435]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1350],\n",
      "         [ 0.0583],\n",
      "         [-0.0032],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1403],\n",
      "         [ 0.1423],\n",
      "         [ 0.1109],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1403],\n",
      "         [ 0.1782],\n",
      "         [ 0.1800],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1409],\n",
      "         [ 0.2193],\n",
      "         [ 0.2173],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1373],\n",
      "         [ 0.1392],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1310],\n",
      "         [ 0.1473],\n",
      "         [ 0.1552],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0803],\n",
      "         [ 0.0045],\n",
      "         [-0.0562],\n",
      "         ...,\n",
      "         [ 0.0925],\n",
      "         [ 0.0927],\n",
      "         [ 0.0929]],\n",
      "\n",
      "        [[ 0.0421],\n",
      "         [ 0.0436],\n",
      "         [ 0.0133],\n",
      "         ...,\n",
      "         [ 0.0543],\n",
      "         [ 0.0543],\n",
      "         [ 0.0543]],\n",
      "\n",
      "        [[ 0.1012],\n",
      "         [ 0.1396],\n",
      "         [ 0.1404],\n",
      "         ...,\n",
      "         [ 0.1133],\n",
      "         [ 0.1133],\n",
      "         [ 0.1134]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1167],\n",
      "         [ 0.1951],\n",
      "         [ 0.1927],\n",
      "         ...,\n",
      "         [ 0.1300],\n",
      "         [ 0.1304],\n",
      "         [ 0.1306]],\n",
      "\n",
      "        [[ 0.0399],\n",
      "         [ 0.0412],\n",
      "         [-0.0438],\n",
      "         ...,\n",
      "         [ 0.0525],\n",
      "         [ 0.0525],\n",
      "         [ 0.0526]],\n",
      "\n",
      "        [[ 0.0977],\n",
      "         [ 0.1154],\n",
      "         [ 0.1265],\n",
      "         ...,\n",
      "         [ 0.1085],\n",
      "         [ 0.1085],\n",
      "         [ 0.1085]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0803],\n",
      "         [ 0.0045],\n",
      "         [-0.0562],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0421],\n",
      "         [ 0.0436],\n",
      "         [ 0.0133],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1012],\n",
      "         [ 0.1396],\n",
      "         [ 0.1404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1167],\n",
      "         [ 0.1951],\n",
      "         [ 0.1927],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0399],\n",
      "         [ 0.0412],\n",
      "         [-0.0438],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0977],\n",
      "         [ 0.1154],\n",
      "         [ 0.1265],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2140],\n",
      "         [0.1390],\n",
      "         [0.0768],\n",
      "         ...,\n",
      "         [0.2308],\n",
      "         [0.2310],\n",
      "         [0.2312]],\n",
      "\n",
      "        [[0.0956],\n",
      "         [0.0949],\n",
      "         [0.0640],\n",
      "         ...,\n",
      "         [0.1097],\n",
      "         [0.1097],\n",
      "         [0.1097]],\n",
      "\n",
      "        [[0.0322],\n",
      "         [0.0707],\n",
      "         [0.0700],\n",
      "         ...,\n",
      "         [0.0424],\n",
      "         [0.0424],\n",
      "         [0.0424]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1356],\n",
      "         [0.2143],\n",
      "         [0.2121],\n",
      "         ...,\n",
      "         [0.1488],\n",
      "         [0.1491],\n",
      "         [0.1493]],\n",
      "\n",
      "        [[0.1024],\n",
      "         [0.1062],\n",
      "         [0.0207],\n",
      "         ...,\n",
      "         [0.1145],\n",
      "         [0.1146],\n",
      "         [0.1146]],\n",
      "\n",
      "        [[0.1774],\n",
      "         [0.1922],\n",
      "         [0.1973],\n",
      "         ...,\n",
      "         [0.1930],\n",
      "         [0.1930],\n",
      "         [0.1930]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2140],\n",
      "         [0.1390],\n",
      "         [0.0768],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.0956],\n",
      "         [0.0949],\n",
      "         [0.0640],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.0322],\n",
      "         [0.0707],\n",
      "         [0.0700],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1356],\n",
      "         [0.2143],\n",
      "         [0.2121],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1024],\n",
      "         [0.1062],\n",
      "         [0.0207],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1774],\n",
      "         [0.1922],\n",
      "         [0.1973],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1634],\n",
      "         [ 0.0869],\n",
      "         [ 0.0270],\n",
      "         ...,\n",
      "         [ 0.1785],\n",
      "         [ 0.1788],\n",
      "         [ 0.1789]],\n",
      "\n",
      "        [[-0.0401],\n",
      "         [-0.0379],\n",
      "         [-0.0664],\n",
      "         ...,\n",
      "         [-0.0241],\n",
      "         [-0.0241],\n",
      "         [-0.0241]],\n",
      "\n",
      "        [[ 0.0574],\n",
      "         [ 0.0975],\n",
      "         [ 0.0961],\n",
      "         ...,\n",
      "         [ 0.0661],\n",
      "         [ 0.0661],\n",
      "         [ 0.0661]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1357],\n",
      "         [ 0.2143],\n",
      "         [ 0.2118],\n",
      "         ...,\n",
      "         [ 0.1490],\n",
      "         [ 0.1493],\n",
      "         [ 0.1495]],\n",
      "\n",
      "        [[-0.0553],\n",
      "         [-0.0493],\n",
      "         [-0.1349],\n",
      "         ...,\n",
      "         [-0.0435],\n",
      "         [-0.0435],\n",
      "         [-0.0435]],\n",
      "\n",
      "        [[ 0.0714],\n",
      "         [ 0.0889],\n",
      "         [ 0.0997],\n",
      "         ...,\n",
      "         [ 0.0827],\n",
      "         [ 0.0827],\n",
      "         [ 0.0827]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1634],\n",
      "         [ 0.0869],\n",
      "         [ 0.0270],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0401],\n",
      "         [-0.0379],\n",
      "         [-0.0664],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0574],\n",
      "         [ 0.0975],\n",
      "         [ 0.0961],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1357],\n",
      "         [ 0.2143],\n",
      "         [ 0.2118],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0553],\n",
      "         [-0.0493],\n",
      "         [-0.1349],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0714],\n",
      "         [ 0.0889],\n",
      "         [ 0.0997],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0819],\n",
      "         [ 0.0065],\n",
      "         [-0.0510],\n",
      "         ...,\n",
      "         [ 0.0934],\n",
      "         [ 0.0936],\n",
      "         [ 0.0938]],\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.0079],\n",
      "         [-0.0362],\n",
      "         ...,\n",
      "         [-0.0012],\n",
      "         [-0.0012],\n",
      "         [-0.0012]],\n",
      "\n",
      "        [[ 0.1567],\n",
      "         [ 0.1955],\n",
      "         [ 0.1962],\n",
      "         ...,\n",
      "         [ 0.1699],\n",
      "         [ 0.1699],\n",
      "         [ 0.1700]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1389],\n",
      "         [ 0.2169],\n",
      "         [ 0.2147],\n",
      "         ...,\n",
      "         [ 0.1514],\n",
      "         [ 0.1517],\n",
      "         [ 0.1519]],\n",
      "\n",
      "        [[ 0.0498],\n",
      "         [ 0.0542],\n",
      "         [-0.0318],\n",
      "         ...,\n",
      "         [ 0.0621],\n",
      "         [ 0.0622],\n",
      "         [ 0.0622]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0090],\n",
      "         [ 0.0224],\n",
      "         ...,\n",
      "         [ 0.0007],\n",
      "         [ 0.0007],\n",
      "         [ 0.0007]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0819],\n",
      "         [ 0.0065],\n",
      "         [-0.0510],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.0079],\n",
      "         [-0.0362],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1567],\n",
      "         [ 0.1955],\n",
      "         [ 0.1962],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1389],\n",
      "         [ 0.2169],\n",
      "         [ 0.2147],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0498],\n",
      "         [ 0.0542],\n",
      "         [-0.0318],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0090],\n",
      "         [ 0.0224],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0040],\n",
      "         [-0.0774],\n",
      "         [-0.1324],\n",
      "         ...,\n",
      "         [ 0.0038],\n",
      "         [ 0.0040],\n",
      "         [ 0.0041]],\n",
      "\n",
      "        [[ 0.0958],\n",
      "         [ 0.1004],\n",
      "         [ 0.0706],\n",
      "         ...,\n",
      "         [ 0.1079],\n",
      "         [ 0.1079],\n",
      "         [ 0.1079]],\n",
      "\n",
      "        [[ 0.1612],\n",
      "         [ 0.1991],\n",
      "         [ 0.2005],\n",
      "         ...,\n",
      "         [ 0.1755],\n",
      "         [ 0.1755],\n",
      "         [ 0.1755]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1283],\n",
      "         [ 0.2062],\n",
      "         [ 0.2034],\n",
      "         ...,\n",
      "         [ 0.1410],\n",
      "         [ 0.1413],\n",
      "         [ 0.1416]],\n",
      "\n",
      "        [[-0.0114],\n",
      "         [-0.0075],\n",
      "         [-0.0942],\n",
      "         ...,\n",
      "         [ 0.0021],\n",
      "         [ 0.0022],\n",
      "         [ 0.0022]],\n",
      "\n",
      "        [[-0.0355],\n",
      "         [-0.0171],\n",
      "         [-0.0023],\n",
      "         ...,\n",
      "         [-0.0274],\n",
      "         [-0.0274],\n",
      "         [-0.0274]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0040],\n",
      "         [-0.0774],\n",
      "         [-0.1324],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0958],\n",
      "         [ 0.1004],\n",
      "         [ 0.0706],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1612],\n",
      "         [ 0.1991],\n",
      "         [ 0.2005],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1283],\n",
      "         [ 0.2062],\n",
      "         [ 0.2034],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0114],\n",
      "         [-0.0075],\n",
      "         [-0.0942],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0355],\n",
      "         [-0.0171],\n",
      "         [-0.0023],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0984],\n",
      "         [ 0.0225],\n",
      "         [-0.0368],\n",
      "         ...,\n",
      "         [ 0.1098],\n",
      "         [ 0.1100],\n",
      "         [ 0.1102]],\n",
      "\n",
      "        [[ 0.0889],\n",
      "         [ 0.0905],\n",
      "         [ 0.0605],\n",
      "         ...,\n",
      "         [ 0.1035],\n",
      "         [ 0.1035],\n",
      "         [ 0.1035]],\n",
      "\n",
      "        [[-0.0145],\n",
      "         [ 0.0248],\n",
      "         [ 0.0229],\n",
      "         ...,\n",
      "         [-0.0060],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0827],\n",
      "         [ 0.1592],\n",
      "         [ 0.1564],\n",
      "         ...,\n",
      "         [ 0.0940],\n",
      "         [ 0.0943],\n",
      "         [ 0.0945]],\n",
      "\n",
      "        [[ 0.1051],\n",
      "         [ 0.1036],\n",
      "         [ 0.0200],\n",
      "         ...,\n",
      "         [ 0.1215],\n",
      "         [ 0.1216],\n",
      "         [ 0.1216]],\n",
      "\n",
      "        [[-0.0879],\n",
      "         [-0.0698],\n",
      "         [-0.0532],\n",
      "         ...,\n",
      "         [-0.0811],\n",
      "         [-0.0811],\n",
      "         [-0.0811]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0984],\n",
      "         [ 0.0225],\n",
      "         [-0.0368],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0889],\n",
      "         [ 0.0905],\n",
      "         [ 0.0605],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0145],\n",
      "         [ 0.0248],\n",
      "         [ 0.0229],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0827],\n",
      "         [ 0.1592],\n",
      "         [ 0.1564],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1051],\n",
      "         [ 0.1036],\n",
      "         [ 0.0200],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0879],\n",
      "         [-0.0698],\n",
      "         [-0.0532],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0573],\n",
      "         [-0.0185],\n",
      "         [-0.0764],\n",
      "         ...,\n",
      "         [ 0.0682],\n",
      "         [ 0.0685],\n",
      "         [ 0.0686]],\n",
      "\n",
      "        [[ 0.0637],\n",
      "         [ 0.0622],\n",
      "         [ 0.0317],\n",
      "         ...,\n",
      "         [ 0.0798],\n",
      "         [ 0.0798],\n",
      "         [ 0.0798]],\n",
      "\n",
      "        [[ 0.0312],\n",
      "         [ 0.0722],\n",
      "         [ 0.0700],\n",
      "         ...,\n",
      "         [ 0.0381],\n",
      "         [ 0.0381],\n",
      "         [ 0.0381]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1550],\n",
      "         [ 0.2341],\n",
      "         [ 0.2309],\n",
      "         ...,\n",
      "         [ 0.1694],\n",
      "         [ 0.1698],\n",
      "         [ 0.1700]],\n",
      "\n",
      "        [[ 0.1408],\n",
      "         [ 0.1395],\n",
      "         [ 0.0556],\n",
      "         ...,\n",
      "         [ 0.1579],\n",
      "         [ 0.1579],\n",
      "         [ 0.1580]],\n",
      "\n",
      "        [[-0.0373],\n",
      "         [-0.0192],\n",
      "         [-0.0044],\n",
      "         ...,\n",
      "         [-0.0295],\n",
      "         [-0.0295],\n",
      "         [-0.0295]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0573],\n",
      "         [-0.0185],\n",
      "         [-0.0764],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0637],\n",
      "         [ 0.0622],\n",
      "         [ 0.0317],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0312],\n",
      "         [ 0.0722],\n",
      "         [ 0.0700],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1550],\n",
      "         [ 0.2341],\n",
      "         [ 0.2309],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1408],\n",
      "         [ 0.1395],\n",
      "         [ 0.0556],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0373],\n",
      "         [-0.0192],\n",
      "         [-0.0044],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0578],\n",
      "         [-0.0171],\n",
      "         [-0.0742],\n",
      "         ...,\n",
      "         [ 0.0682],\n",
      "         [ 0.0684],\n",
      "         [ 0.0686]],\n",
      "\n",
      "        [[ 0.0820],\n",
      "         [ 0.0844],\n",
      "         [ 0.0543],\n",
      "         ...,\n",
      "         [ 0.0964],\n",
      "         [ 0.0964],\n",
      "         [ 0.0964]],\n",
      "\n",
      "        [[-0.0352],\n",
      "         [ 0.0050],\n",
      "         [ 0.0027],\n",
      "         ...,\n",
      "         [-0.0269],\n",
      "         [-0.0269],\n",
      "         [-0.0268]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2304],\n",
      "         [ 0.3111],\n",
      "         [ 0.3065],\n",
      "         ...,\n",
      "         [ 0.2483],\n",
      "         [ 0.2486],\n",
      "         [ 0.2489]],\n",
      "\n",
      "        [[ 0.0935],\n",
      "         [ 0.0950],\n",
      "         [ 0.0115],\n",
      "         ...,\n",
      "         [ 0.1075],\n",
      "         [ 0.1076],\n",
      "         [ 0.1076]],\n",
      "\n",
      "        [[-0.0104],\n",
      "         [ 0.0083],\n",
      "         [ 0.0230],\n",
      "         ...,\n",
      "         [-0.0034],\n",
      "         [-0.0034],\n",
      "         [-0.0034]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0578],\n",
      "         [-0.0171],\n",
      "         [-0.0742],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0820],\n",
      "         [ 0.0844],\n",
      "         [ 0.0543],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0352],\n",
      "         [ 0.0050],\n",
      "         [ 0.0027],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2304],\n",
      "         [ 0.3111],\n",
      "         [ 0.3065],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0935],\n",
      "         [ 0.0950],\n",
      "         [ 0.0115],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0104],\n",
      "         [ 0.0083],\n",
      "         [ 0.0230],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1292],\n",
      "         [ 0.0538],\n",
      "         [-0.0083],\n",
      "         ...,\n",
      "         [ 0.1434],\n",
      "         [ 0.1437],\n",
      "         [ 0.1439]],\n",
      "\n",
      "        [[-0.0517],\n",
      "         [-0.0482],\n",
      "         [-0.0756],\n",
      "         ...,\n",
      "         [-0.0403],\n",
      "         [-0.0403],\n",
      "         [-0.0403]],\n",
      "\n",
      "        [[ 0.0090],\n",
      "         [ 0.0493],\n",
      "         [ 0.0486],\n",
      "         ...,\n",
      "         [ 0.0205],\n",
      "         [ 0.0205],\n",
      "         [ 0.0205]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1269],\n",
      "         [ 0.2056],\n",
      "         [ 0.2024],\n",
      "         ...,\n",
      "         [ 0.1401],\n",
      "         [ 0.1404],\n",
      "         [ 0.1407]],\n",
      "\n",
      "        [[ 0.0970],\n",
      "         [ 0.1002],\n",
      "         [ 0.0148],\n",
      "         ...,\n",
      "         [ 0.1102],\n",
      "         [ 0.1103],\n",
      "         [ 0.1103]],\n",
      "\n",
      "        [[ 0.1446],\n",
      "         [ 0.1602],\n",
      "         [ 0.1666],\n",
      "         ...,\n",
      "         [ 0.1584],\n",
      "         [ 0.1584],\n",
      "         [ 0.1584]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1292],\n",
      "         [ 0.0538],\n",
      "         [-0.0083],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0517],\n",
      "         [-0.0482],\n",
      "         [-0.0756],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0090],\n",
      "         [ 0.0493],\n",
      "         [ 0.0486],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1269],\n",
      "         [ 0.2056],\n",
      "         [ 0.2024],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0970],\n",
      "         [ 0.1002],\n",
      "         [ 0.0148],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1446],\n",
      "         [ 0.1602],\n",
      "         [ 0.1666],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0611],\n",
      "         [-0.0147],\n",
      "         [-0.0752],\n",
      "         ...,\n",
      "         [ 0.0745],\n",
      "         [ 0.0748],\n",
      "         [ 0.0749]],\n",
      "\n",
      "        [[-0.0795],\n",
      "         [-0.0752],\n",
      "         [-0.1028],\n",
      "         ...,\n",
      "         [-0.0696],\n",
      "         [-0.0696],\n",
      "         [-0.0696]],\n",
      "\n",
      "        [[ 0.0253],\n",
      "         [ 0.0619],\n",
      "         [ 0.0629],\n",
      "         ...,\n",
      "         [ 0.0406],\n",
      "         [ 0.0406],\n",
      "         [ 0.0406]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0680],\n",
      "         [ 0.1433],\n",
      "         [ 0.1401],\n",
      "         ...,\n",
      "         [ 0.0783],\n",
      "         [ 0.0786],\n",
      "         [ 0.0788]],\n",
      "\n",
      "        [[ 0.1761],\n",
      "         [ 0.1797],\n",
      "         [ 0.0937],\n",
      "         ...,\n",
      "         [ 0.1909],\n",
      "         [ 0.1910],\n",
      "         [ 0.1910]],\n",
      "\n",
      "        [[ 0.0849],\n",
      "         [ 0.1028],\n",
      "         [ 0.1126],\n",
      "         ...,\n",
      "         [ 0.0979],\n",
      "         [ 0.0979],\n",
      "         [ 0.0979]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0611],\n",
      "         [-0.0147],\n",
      "         [-0.0752],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0795],\n",
      "         [-0.0752],\n",
      "         [-0.1028],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0253],\n",
      "         [ 0.0619],\n",
      "         [ 0.0629],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0680],\n",
      "         [ 0.1433],\n",
      "         [ 0.1401],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1761],\n",
      "         [ 0.1797],\n",
      "         [ 0.0937],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0849],\n",
      "         [ 0.1028],\n",
      "         [ 0.1126],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0550],\n",
      "         [-0.1288],\n",
      "         [-0.1846],\n",
      "         ...,\n",
      "         [-0.0460],\n",
      "         [-0.0458],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0030],\n",
      "         [ 0.0083],\n",
      "         [-0.0185],\n",
      "         ...,\n",
      "         [ 0.0011],\n",
      "         [ 0.0011],\n",
      "         [ 0.0011]],\n",
      "\n",
      "        [[ 0.0823],\n",
      "         [ 0.1215],\n",
      "         [ 0.1223],\n",
      "         ...,\n",
      "         [ 0.0950],\n",
      "         [ 0.0950],\n",
      "         [ 0.0950]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1192],\n",
      "         [ 0.1963],\n",
      "         [ 0.1938],\n",
      "         ...,\n",
      "         [ 0.1308],\n",
      "         [ 0.1311],\n",
      "         [ 0.1313]],\n",
      "\n",
      "        [[ 0.1148],\n",
      "         [ 0.1193],\n",
      "         [ 0.0343],\n",
      "         ...,\n",
      "         [ 0.1276],\n",
      "         [ 0.1277],\n",
      "         [ 0.1277]],\n",
      "\n",
      "        [[ 0.0688],\n",
      "         [ 0.0867],\n",
      "         [ 0.0977],\n",
      "         ...,\n",
      "         [ 0.0802],\n",
      "         [ 0.0802],\n",
      "         [ 0.0802]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0550],\n",
      "         [-0.1288],\n",
      "         [-0.1846],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0030],\n",
      "         [ 0.0083],\n",
      "         [-0.0185],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0823],\n",
      "         [ 0.1215],\n",
      "         [ 0.1223],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1192],\n",
      "         [ 0.1963],\n",
      "         [ 0.1938],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1148],\n",
      "         [ 0.1193],\n",
      "         [ 0.0343],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0688],\n",
      "         [ 0.0867],\n",
      "         [ 0.0977],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0504],\n",
      "         [-0.0237],\n",
      "         [-0.0809],\n",
      "         ...,\n",
      "         [ 0.0583],\n",
      "         [ 0.0585],\n",
      "         [ 0.0587]],\n",
      "\n",
      "        [[ 0.0394],\n",
      "         [ 0.0442],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [ 0.0499],\n",
      "         [ 0.0499],\n",
      "         [ 0.0499]],\n",
      "\n",
      "        [[ 0.0493],\n",
      "         [ 0.0892],\n",
      "         [ 0.0895],\n",
      "         ...,\n",
      "         [ 0.0616],\n",
      "         [ 0.0617],\n",
      "         [ 0.0617]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2017],\n",
      "         [ 0.2811],\n",
      "         [ 0.2774],\n",
      "         ...,\n",
      "         [ 0.2178],\n",
      "         [ 0.2181],\n",
      "         [ 0.2183]],\n",
      "\n",
      "        [[ 0.1058],\n",
      "         [ 0.1090],\n",
      "         [ 0.0242],\n",
      "         ...,\n",
      "         [ 0.1195],\n",
      "         [ 0.1196],\n",
      "         [ 0.1196]],\n",
      "\n",
      "        [[-0.0029],\n",
      "         [ 0.0139],\n",
      "         [ 0.0257],\n",
      "         ...,\n",
      "         [ 0.0089],\n",
      "         [ 0.0089],\n",
      "         [ 0.0089]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0504],\n",
      "         [-0.0237],\n",
      "         [-0.0809],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0394],\n",
      "         [ 0.0442],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0493],\n",
      "         [ 0.0892],\n",
      "         [ 0.0895],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2017],\n",
      "         [ 0.2811],\n",
      "         [ 0.2774],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1058],\n",
      "         [ 0.1090],\n",
      "         [ 0.0242],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0029],\n",
      "         [ 0.0139],\n",
      "         [ 0.0257],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1049],\n",
      "         [ 0.0303],\n",
      "         [-0.0307],\n",
      "         ...,\n",
      "         [ 0.1186],\n",
      "         [ 0.1189],\n",
      "         [ 0.1190]],\n",
      "\n",
      "        [[ 0.0094],\n",
      "         [ 0.0150],\n",
      "         [-0.0131],\n",
      "         ...,\n",
      "         [ 0.0180],\n",
      "         [ 0.0180],\n",
      "         [ 0.0180]],\n",
      "\n",
      "        [[ 0.1188],\n",
      "         [ 0.1570],\n",
      "         [ 0.1589],\n",
      "         ...,\n",
      "         [ 0.1340],\n",
      "         [ 0.1340],\n",
      "         [ 0.1340]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1154],\n",
      "         [ 0.1926],\n",
      "         [ 0.1895],\n",
      "         ...,\n",
      "         [ 0.1273],\n",
      "         [ 0.1276],\n",
      "         [ 0.1279]],\n",
      "\n",
      "        [[ 0.1042],\n",
      "         [ 0.1071],\n",
      "         [ 0.0216],\n",
      "         ...,\n",
      "         [ 0.1179],\n",
      "         [ 0.1180],\n",
      "         [ 0.1180]],\n",
      "\n",
      "        [[-0.0137],\n",
      "         [ 0.0044],\n",
      "         [ 0.0175],\n",
      "         ...,\n",
      "         [-0.0012],\n",
      "         [-0.0012],\n",
      "         [-0.0012]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1049],\n",
      "         [ 0.0303],\n",
      "         [-0.0307],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0094],\n",
      "         [ 0.0150],\n",
      "         [-0.0131],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1188],\n",
      "         [ 0.1570],\n",
      "         [ 0.1589],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1154],\n",
      "         [ 0.1926],\n",
      "         [ 0.1895],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1042],\n",
      "         [ 0.1071],\n",
      "         [ 0.0216],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0137],\n",
      "         [ 0.0044],\n",
      "         [ 0.0175],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1139],\n",
      "         [ 0.0381],\n",
      "         [-0.0224],\n",
      "         ...,\n",
      "         [ 0.1266],\n",
      "         [ 0.1269],\n",
      "         [ 0.1271]],\n",
      "\n",
      "        [[-0.0049],\n",
      "         [ 0.0019],\n",
      "         [-0.0257],\n",
      "         ...,\n",
      "         [ 0.0024],\n",
      "         [ 0.0024],\n",
      "         [ 0.0024]],\n",
      "\n",
      "        [[ 0.1349],\n",
      "         [ 0.1717],\n",
      "         [ 0.1738],\n",
      "         ...,\n",
      "         [ 0.1506],\n",
      "         [ 0.1506],\n",
      "         [ 0.1507]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0400],\n",
      "         [ 0.1155],\n",
      "         [ 0.1125],\n",
      "         ...,\n",
      "         [ 0.0510],\n",
      "         [ 0.0514],\n",
      "         [ 0.0516]],\n",
      "\n",
      "        [[ 0.1407],\n",
      "         [ 0.1411],\n",
      "         [ 0.0564],\n",
      "         ...,\n",
      "         [ 0.1564],\n",
      "         [ 0.1564],\n",
      "         [ 0.1565]],\n",
      "\n",
      "        [[-0.0395],\n",
      "         [-0.0218],\n",
      "         [-0.0078],\n",
      "         ...,\n",
      "         [-0.0293],\n",
      "         [-0.0293],\n",
      "         [-0.0293]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1139],\n",
      "         [ 0.0381],\n",
      "         [-0.0224],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0049],\n",
      "         [ 0.0019],\n",
      "         [-0.0257],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1349],\n",
      "         [ 0.1717],\n",
      "         [ 0.1738],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0400],\n",
      "         [ 0.1155],\n",
      "         [ 0.1125],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1407],\n",
      "         [ 0.1411],\n",
      "         [ 0.0564],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0395],\n",
      "         [-0.0218],\n",
      "         [-0.0078],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1142],\n",
      "         [ 0.0398],\n",
      "         [-0.0183],\n",
      "         ...,\n",
      "         [ 0.1254],\n",
      "         [ 0.1257],\n",
      "         [ 0.1258]],\n",
      "\n",
      "        [[-0.0122],\n",
      "         [-0.0049],\n",
      "         [-0.0322],\n",
      "         ...,\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0058]],\n",
      "\n",
      "        [[ 0.0456],\n",
      "         [ 0.0833],\n",
      "         [ 0.0833],\n",
      "         ...,\n",
      "         [ 0.0576],\n",
      "         [ 0.0576],\n",
      "         [ 0.0576]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0661],\n",
      "         [ 0.1424],\n",
      "         [ 0.1399],\n",
      "         ...,\n",
      "         [ 0.0765],\n",
      "         [ 0.0768],\n",
      "         [ 0.0770]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [-0.0036],\n",
      "         [-0.0874],\n",
      "         ...,\n",
      "         [ 0.0028],\n",
      "         [ 0.0028],\n",
      "         [ 0.0029]],\n",
      "\n",
      "        [[ 0.0371],\n",
      "         [ 0.0562],\n",
      "         [ 0.0693],\n",
      "         ...,\n",
      "         [ 0.0460],\n",
      "         [ 0.0460],\n",
      "         [ 0.0460]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1142],\n",
      "         [ 0.0398],\n",
      "         [-0.0183],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0122],\n",
      "         [-0.0049],\n",
      "         [-0.0322],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0456],\n",
      "         [ 0.0833],\n",
      "         [ 0.0833],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0661],\n",
      "         [ 0.1424],\n",
      "         [ 0.1399],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [-0.0036],\n",
      "         [-0.0874],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0371],\n",
      "         [ 0.0562],\n",
      "         [ 0.0693],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0429],\n",
      "         [-0.0311],\n",
      "         [-0.0866],\n",
      "         ...,\n",
      "         [ 0.0509],\n",
      "         [ 0.0511],\n",
      "         [ 0.0513]],\n",
      "\n",
      "        [[-0.0163],\n",
      "         [-0.0086],\n",
      "         [-0.0358],\n",
      "         ...,\n",
      "         [-0.0103],\n",
      "         [-0.0103],\n",
      "         [-0.0103]],\n",
      "\n",
      "        [[ 0.0937],\n",
      "         [ 0.1274],\n",
      "         [ 0.1303],\n",
      "         ...,\n",
      "         [ 0.1099],\n",
      "         [ 0.1099],\n",
      "         [ 0.1099]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0167],\n",
      "         [ 0.0910],\n",
      "         [ 0.0888],\n",
      "         ...,\n",
      "         [ 0.0252],\n",
      "         [ 0.0255],\n",
      "         [ 0.0257]],\n",
      "\n",
      "        [[ 0.0669],\n",
      "         [ 0.0742],\n",
      "         [-0.0119],\n",
      "         ...,\n",
      "         [ 0.0767],\n",
      "         [ 0.0768],\n",
      "         [ 0.0768]],\n",
      "\n",
      "        [[ 0.2016],\n",
      "         [ 0.2172],\n",
      "         [ 0.2219],\n",
      "         ...,\n",
      "         [ 0.2180],\n",
      "         [ 0.2180],\n",
      "         [ 0.2180]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0429],\n",
      "         [-0.0311],\n",
      "         [-0.0866],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0163],\n",
      "         [-0.0086],\n",
      "         [-0.0358],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0937],\n",
      "         [ 0.1274],\n",
      "         [ 0.1303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0167],\n",
      "         [ 0.0910],\n",
      "         [ 0.0888],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0669],\n",
      "         [ 0.0742],\n",
      "         [-0.0119],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2016],\n",
      "         [ 0.2172],\n",
      "         [ 0.2219],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0475],\n",
      "         [-0.1185],\n",
      "         [-0.1710],\n",
      "         ...,\n",
      "         [-0.0434],\n",
      "         [-0.0432],\n",
      "         [-0.0430]],\n",
      "\n",
      "        [[-0.0185],\n",
      "         [-0.0106],\n",
      "         [-0.0378],\n",
      "         ...,\n",
      "         [-0.0127],\n",
      "         [-0.0127],\n",
      "         [-0.0127]],\n",
      "\n",
      "        [[-0.0277],\n",
      "         [ 0.0078],\n",
      "         [ 0.0077],\n",
      "         ...,\n",
      "         [-0.0137],\n",
      "         [-0.0137],\n",
      "         [-0.0137]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0026],\n",
      "         [ 0.0780],\n",
      "         [ 0.0765],\n",
      "         ...,\n",
      "         [ 0.0105],\n",
      "         [ 0.0108],\n",
      "         [ 0.0110]],\n",
      "\n",
      "        [[ 0.0580],\n",
      "         [ 0.0656],\n",
      "         [-0.0200],\n",
      "         ...,\n",
      "         [ 0.0663],\n",
      "         [ 0.0664],\n",
      "         [ 0.0664]],\n",
      "\n",
      "        [[ 0.1716],\n",
      "         [ 0.1856],\n",
      "         [ 0.1898],\n",
      "         ...,\n",
      "         [ 0.1876],\n",
      "         [ 0.1876],\n",
      "         [ 0.1876]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0475],\n",
      "         [-0.1185],\n",
      "         [-0.1710],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0185],\n",
      "         [-0.0106],\n",
      "         [-0.0378],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0277],\n",
      "         [ 0.0078],\n",
      "         [ 0.0077],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0026],\n",
      "         [ 0.0780],\n",
      "         [ 0.0765],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0580],\n",
      "         [ 0.0656],\n",
      "         [-0.0200],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1716],\n",
      "         [ 0.1856],\n",
      "         [ 0.1898],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0246],\n",
      "         [-0.0486],\n",
      "         [-0.1085],\n",
      "         ...,\n",
      "         [ 0.0389],\n",
      "         [ 0.0391],\n",
      "         [ 0.0393]],\n",
      "\n",
      "        [[-0.0198],\n",
      "         [-0.0118],\n",
      "         [-0.0389],\n",
      "         ...,\n",
      "         [-0.0141],\n",
      "         [-0.0141],\n",
      "         [-0.0141]],\n",
      "\n",
      "        [[ 0.0277],\n",
      "         [ 0.0682],\n",
      "         [ 0.0670],\n",
      "         ...,\n",
      "         [ 0.0362],\n",
      "         [ 0.0363],\n",
      "         [ 0.0363]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0464],\n",
      "         [ 0.0259],\n",
      "         [ 0.0236],\n",
      "         ...,\n",
      "         [-0.0377],\n",
      "         [-0.0374],\n",
      "         [-0.0372]],\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.0070],\n",
      "         [-0.0912],\n",
      "         ...,\n",
      "         [-0.0037],\n",
      "         [-0.0037],\n",
      "         [-0.0036]],\n",
      "\n",
      "        [[ 0.1146],\n",
      "         [ 0.1300],\n",
      "         [ 0.1368],\n",
      "         ...,\n",
      "         [ 0.1294],\n",
      "         [ 0.1294],\n",
      "         [ 0.1294]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0246],\n",
      "         [-0.0486],\n",
      "         [-0.1085],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0198],\n",
      "         [-0.0118],\n",
      "         [-0.0389],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0277],\n",
      "         [ 0.0682],\n",
      "         [ 0.0670],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0464],\n",
      "         [ 0.0259],\n",
      "         [ 0.0236],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0128],\n",
      "         [-0.0070],\n",
      "         [-0.0912],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1146],\n",
      "         [ 0.1300],\n",
      "         [ 0.1368],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0434],\n",
      "         [-0.0312],\n",
      "         [-0.0907],\n",
      "         ...,\n",
      "         [ 0.0542],\n",
      "         [ 0.0544],\n",
      "         [ 0.0546]],\n",
      "\n",
      "        [[-0.0205],\n",
      "         [-0.0125],\n",
      "         [-0.0396],\n",
      "         ...,\n",
      "         [-0.0148],\n",
      "         [-0.0148],\n",
      "         [-0.0148]],\n",
      "\n",
      "        [[ 0.0784],\n",
      "         [ 0.1189],\n",
      "         [ 0.1189],\n",
      "         ...,\n",
      "         [ 0.0895],\n",
      "         [ 0.0895],\n",
      "         [ 0.0895]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1084],\n",
      "         [ 0.1877],\n",
      "         [ 0.1847],\n",
      "         ...,\n",
      "         [ 0.1209],\n",
      "         [ 0.1212],\n",
      "         [ 0.1214]],\n",
      "\n",
      "        [[ 0.0822],\n",
      "         [ 0.0862],\n",
      "         [ 0.0013],\n",
      "         ...,\n",
      "         [ 0.0940],\n",
      "         [ 0.0941],\n",
      "         [ 0.0941]],\n",
      "\n",
      "        [[ 0.0535],\n",
      "         [ 0.0696],\n",
      "         [ 0.0794],\n",
      "         ...,\n",
      "         [ 0.0657],\n",
      "         [ 0.0657],\n",
      "         [ 0.0657]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0434],\n",
      "         [-0.0312],\n",
      "         [-0.0907],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0205],\n",
      "         [-0.0125],\n",
      "         [-0.0396],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0784],\n",
      "         [ 0.1189],\n",
      "         [ 0.1189],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1084],\n",
      "         [ 0.1877],\n",
      "         [ 0.1847],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0822],\n",
      "         [ 0.0862],\n",
      "         [ 0.0013],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0535],\n",
      "         [ 0.0696],\n",
      "         [ 0.0794],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1506],\n",
      "         [ 0.0772],\n",
      "         [ 0.0172],\n",
      "         ...,\n",
      "         [ 0.1628],\n",
      "         [ 0.1631],\n",
      "         [ 0.1633]],\n",
      "\n",
      "        [[-0.0208],\n",
      "         [-0.0128],\n",
      "         [-0.0400],\n",
      "         ...,\n",
      "         [-0.0152],\n",
      "         [-0.0152],\n",
      "         [-0.0152]],\n",
      "\n",
      "        [[ 0.0507],\n",
      "         [ 0.0911],\n",
      "         [ 0.0910],\n",
      "         ...,\n",
      "         [ 0.0624],\n",
      "         [ 0.0624],\n",
      "         [ 0.0624]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1256],\n",
      "         [ 0.2041],\n",
      "         [ 0.2015],\n",
      "         ...,\n",
      "         [ 0.1376],\n",
      "         [ 0.1379],\n",
      "         [ 0.1382]],\n",
      "\n",
      "        [[ 0.0543],\n",
      "         [ 0.0609],\n",
      "         [-0.0255],\n",
      "         ...,\n",
      "         [ 0.0655],\n",
      "         [ 0.0655],\n",
      "         [ 0.0656]],\n",
      "\n",
      "        [[ 0.0158],\n",
      "         [ 0.0334],\n",
      "         [ 0.0460],\n",
      "         ...,\n",
      "         [ 0.0252],\n",
      "         [ 0.0252],\n",
      "         [ 0.0252]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1506],\n",
      "         [ 0.0772],\n",
      "         [ 0.0172],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0208],\n",
      "         [-0.0128],\n",
      "         [-0.0400],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0507],\n",
      "         [ 0.0911],\n",
      "         [ 0.0910],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1256],\n",
      "         [ 0.2041],\n",
      "         [ 0.2015],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0543],\n",
      "         [ 0.0609],\n",
      "         [-0.0255],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0158],\n",
      "         [ 0.0334],\n",
      "         [ 0.0460],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1588],\n",
      "         [ 0.0834],\n",
      "         [ 0.0229],\n",
      "         ...,\n",
      "         [ 0.1726],\n",
      "         [ 0.1729],\n",
      "         [ 0.1731]],\n",
      "\n",
      "        [[-0.0210],\n",
      "         [-0.0130],\n",
      "         [-0.0402],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[ 0.0451],\n",
      "         [ 0.0853],\n",
      "         [ 0.0842],\n",
      "         ...,\n",
      "         [ 0.0544],\n",
      "         [ 0.0545],\n",
      "         [ 0.0545]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0149],\n",
      "         [ 0.0896],\n",
      "         [ 0.0871],\n",
      "         ...,\n",
      "         [ 0.0239],\n",
      "         [ 0.0242],\n",
      "         [ 0.0244]],\n",
      "\n",
      "        [[ 0.0505],\n",
      "         [ 0.0619],\n",
      "         [-0.0223],\n",
      "         ...,\n",
      "         [ 0.0542],\n",
      "         [ 0.0543],\n",
      "         [ 0.0543]],\n",
      "\n",
      "        [[-0.0065],\n",
      "         [ 0.0121],\n",
      "         [ 0.0266],\n",
      "         ...,\n",
      "         [ 0.0010],\n",
      "         [ 0.0010],\n",
      "         [ 0.0010]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1588],\n",
      "         [ 0.0834],\n",
      "         [ 0.0229],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0210],\n",
      "         [-0.0130],\n",
      "         [-0.0402],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0451],\n",
      "         [ 0.0853],\n",
      "         [ 0.0842],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0149],\n",
      "         [ 0.0896],\n",
      "         [ 0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0505],\n",
      "         [ 0.0619],\n",
      "         [-0.0223],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0065],\n",
      "         [ 0.0121],\n",
      "         [ 0.0266],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 1.3459e-01],\n",
      "         [ 6.0009e-02],\n",
      "         [ 1.6047e-03],\n",
      "         ...,\n",
      "         [ 1.4683e-01],\n",
      "         [ 1.4708e-01],\n",
      "         [ 1.4725e-01]],\n",
      "\n",
      "        [[-2.1118e-02],\n",
      "         [-1.3098e-02],\n",
      "         [-4.0258e-02],\n",
      "         ...,\n",
      "         [-1.5481e-02],\n",
      "         [-1.5481e-02],\n",
      "         [-1.5481e-02]],\n",
      "\n",
      "        [[-1.9244e-02],\n",
      "         [ 2.0856e-02],\n",
      "         [ 1.8054e-02],\n",
      "         ...,\n",
      "         [-1.3201e-02],\n",
      "         [-1.3179e-02],\n",
      "         [-1.3163e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.6585e-01],\n",
      "         [ 2.4580e-01],\n",
      "         [ 2.4236e-01],\n",
      "         ...,\n",
      "         [ 1.8179e-01],\n",
      "         [ 1.8212e-01],\n",
      "         [ 1.8235e-01]],\n",
      "\n",
      "        [[ 5.7571e-02],\n",
      "         [ 6.1169e-02],\n",
      "         [-2.1461e-02],\n",
      "         ...,\n",
      "         [ 6.9791e-02],\n",
      "         [ 6.9850e-02],\n",
      "         [ 6.9890e-02]],\n",
      "\n",
      "        [[-1.9420e-02],\n",
      "         [-1.8647e-04],\n",
      "         [ 1.5364e-02],\n",
      "         ...,\n",
      "         [-1.3112e-02],\n",
      "         [-1.3112e-02],\n",
      "         [-1.3112e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 1.3459e-01],\n",
      "         [ 6.0009e-02],\n",
      "         [ 1.6047e-03],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.1118e-02],\n",
      "         [-1.3098e-02],\n",
      "         [-4.0258e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.9244e-02],\n",
      "         [ 2.0856e-02],\n",
      "         [ 1.8054e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.6585e-01],\n",
      "         [ 2.4580e-01],\n",
      "         [ 2.4236e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 5.7571e-02],\n",
      "         [ 6.1169e-02],\n",
      "         [-2.1461e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.9420e-02],\n",
      "         [-1.8647e-04],\n",
      "         [ 1.5364e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1190],\n",
      "         [ 0.0422],\n",
      "         [-0.0191],\n",
      "         ...,\n",
      "         [ 0.1321],\n",
      "         [ 0.1324],\n",
      "         [ 0.1326]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0131],\n",
      "         [-0.0403],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[-0.0550],\n",
      "         [-0.0156],\n",
      "         [-0.0193],\n",
      "         ...,\n",
      "         [-0.0510],\n",
      "         [-0.0510],\n",
      "         [-0.0510]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1996],\n",
      "         [ 0.2800],\n",
      "         [ 0.2766],\n",
      "         ...,\n",
      "         [ 0.2152],\n",
      "         [ 0.2155],\n",
      "         [ 0.2157]],\n",
      "\n",
      "        [[ 0.0671],\n",
      "         [ 0.0690],\n",
      "         [-0.0142],\n",
      "         ...,\n",
      "         [ 0.0811],\n",
      "         [ 0.0812],\n",
      "         [ 0.0812]],\n",
      "\n",
      "        [[-0.0269],\n",
      "         [-0.0073],\n",
      "         [ 0.0089],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1190],\n",
      "         [ 0.0422],\n",
      "         [-0.0191],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0131],\n",
      "         [-0.0403],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0550],\n",
      "         [-0.0156],\n",
      "         [-0.0193],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1996],\n",
      "         [ 0.2800],\n",
      "         [ 0.2766],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0671],\n",
      "         [ 0.0690],\n",
      "         [-0.0142],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0269],\n",
      "         [-0.0073],\n",
      "         [ 0.0089],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1048],\n",
      "         [ 0.0288],\n",
      "         [-0.0309],\n",
      "         ...,\n",
      "         [ 0.1175],\n",
      "         [ 0.1178],\n",
      "         [ 0.1179]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0403],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[ 0.0302],\n",
      "         [ 0.0684],\n",
      "         [ 0.0682],\n",
      "         ...,\n",
      "         [ 0.0413],\n",
      "         [ 0.0413],\n",
      "         [ 0.0413]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1942],\n",
      "         [ 0.2741],\n",
      "         [ 0.2705],\n",
      "         ...,\n",
      "         [ 0.2104],\n",
      "         [ 0.2108],\n",
      "         [ 0.2110]],\n",
      "\n",
      "        [[ 0.0282],\n",
      "         [ 0.0316],\n",
      "         [-0.0524],\n",
      "         ...,\n",
      "         [ 0.0395],\n",
      "         [ 0.0396],\n",
      "         [ 0.0396]],\n",
      "\n",
      "        [[-0.0311],\n",
      "         [-0.0113],\n",
      "         [ 0.0052],\n",
      "         ...,\n",
      "         [-0.0258],\n",
      "         [-0.0258],\n",
      "         [-0.0258]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1048],\n",
      "         [ 0.0288],\n",
      "         [-0.0309],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0403],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0302],\n",
      "         [ 0.0684],\n",
      "         [ 0.0682],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1942],\n",
      "         [ 0.2741],\n",
      "         [ 0.2705],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0282],\n",
      "         [ 0.0316],\n",
      "         [-0.0524],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0311],\n",
      "         [-0.0113],\n",
      "         [ 0.0052],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1274],\n",
      "         [ 0.0517],\n",
      "         [-0.0067],\n",
      "         ...,\n",
      "         [ 0.1392],\n",
      "         [ 0.1394],\n",
      "         [ 0.1396]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[ 0.0140],\n",
      "         [ 0.0528],\n",
      "         [ 0.0517],\n",
      "         ...,\n",
      "         [ 0.0236],\n",
      "         [ 0.0236],\n",
      "         [ 0.0236]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1163],\n",
      "         [ 0.1949],\n",
      "         [ 0.1914],\n",
      "         ...,\n",
      "         [ 0.1300],\n",
      "         [ 0.1304],\n",
      "         [ 0.1306]],\n",
      "\n",
      "        [[ 0.0051],\n",
      "         [ 0.0104],\n",
      "         [-0.0740],\n",
      "         ...,\n",
      "         [ 0.0140],\n",
      "         [ 0.0140],\n",
      "         [ 0.0141]],\n",
      "\n",
      "        [[-0.0335],\n",
      "         [-0.0136],\n",
      "         [ 0.0031],\n",
      "         ...,\n",
      "         [-0.0284],\n",
      "         [-0.0284],\n",
      "         [-0.0284]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1274],\n",
      "         [ 0.0517],\n",
      "         [-0.0067],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0140],\n",
      "         [ 0.0528],\n",
      "         [ 0.0517],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1163],\n",
      "         [ 0.1949],\n",
      "         [ 0.1914],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0051],\n",
      "         [ 0.0104],\n",
      "         [-0.0740],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0335],\n",
      "         [-0.0136],\n",
      "         [ 0.0031],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1186],\n",
      "         [ 0.0439],\n",
      "         [-0.0126],\n",
      "         ...,\n",
      "         [ 0.1286],\n",
      "         [ 0.1289],\n",
      "         [ 0.1290]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[ 0.0021],\n",
      "         [ 0.0414],\n",
      "         [ 0.0397],\n",
      "         ...,\n",
      "         [ 0.0105],\n",
      "         [ 0.0106],\n",
      "         [ 0.0106]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0360],\n",
      "         [ 0.1111],\n",
      "         [ 0.1076],\n",
      "         ...,\n",
      "         [ 0.0470],\n",
      "         [ 0.0473],\n",
      "         [ 0.0475]],\n",
      "\n",
      "        [[-0.0084],\n",
      "         [-0.0018],\n",
      "         [-0.0866],\n",
      "         ...,\n",
      "         [-0.0010],\n",
      "         [-0.0009],\n",
      "         [-0.0009]],\n",
      "\n",
      "        [[-0.0348],\n",
      "         [-0.0149],\n",
      "         [ 0.0019],\n",
      "         ...,\n",
      "         [-0.0298],\n",
      "         [-0.0298],\n",
      "         [-0.0298]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1186],\n",
      "         [ 0.0439],\n",
      "         [-0.0126],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0021],\n",
      "         [ 0.0414],\n",
      "         [ 0.0397],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0360],\n",
      "         [ 0.1111],\n",
      "         [ 0.1076],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0084],\n",
      "         [-0.0018],\n",
      "         [-0.0866],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0348],\n",
      "         [-0.0149],\n",
      "         [ 0.0019],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0316],\n",
      "         [-0.0415],\n",
      "         [-0.0948],\n",
      "         ...,\n",
      "         [ 0.0377],\n",
      "         [ 0.0380],\n",
      "         [ 0.0381]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[-0.0055],\n",
      "         [ 0.0342],\n",
      "         [ 0.0321],\n",
      "         ...,\n",
      "         [ 0.0022],\n",
      "         [ 0.0022],\n",
      "         [ 0.0022]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0045],\n",
      "         [ 0.0783],\n",
      "         [ 0.0757],\n",
      "         ...,\n",
      "         [ 0.0131],\n",
      "         [ 0.0134],\n",
      "         [ 0.0136]],\n",
      "\n",
      "        [[-0.0162],\n",
      "         [-0.0089],\n",
      "         [-0.0939],\n",
      "         ...,\n",
      "         [-0.0096],\n",
      "         [-0.0095],\n",
      "         [-0.0095]],\n",
      "\n",
      "        [[-0.0356],\n",
      "         [-0.0156],\n",
      "         [ 0.0012],\n",
      "         ...,\n",
      "         [-0.0306],\n",
      "         [-0.0306],\n",
      "         [-0.0306]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0316],\n",
      "         [-0.0415],\n",
      "         [-0.0948],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0055],\n",
      "         [ 0.0342],\n",
      "         [ 0.0321],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0045],\n",
      "         [ 0.0783],\n",
      "         [ 0.0757],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0162],\n",
      "         [-0.0089],\n",
      "         [-0.0939],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0356],\n",
      "         [-0.0156],\n",
      "         [ 0.0012],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0347],\n",
      "         [-0.0387],\n",
      "         [-0.0927],\n",
      "         ...,\n",
      "         [ 0.0410],\n",
      "         [ 0.0413],\n",
      "         [ 0.0414]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[-0.0100],\n",
      "         [ 0.0298],\n",
      "         [ 0.0275],\n",
      "         ...,\n",
      "         [-0.0028],\n",
      "         [-0.0028],\n",
      "         [-0.0028]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0126],\n",
      "         [ 0.0881],\n",
      "         [ 0.0857],\n",
      "         ...,\n",
      "         [ 0.0231],\n",
      "         [ 0.0235],\n",
      "         [ 0.0237]],\n",
      "\n",
      "        [[-0.0206],\n",
      "         [-0.0130],\n",
      "         [-0.0982],\n",
      "         ...,\n",
      "         [-0.0144],\n",
      "         [-0.0144],\n",
      "         [-0.0143]],\n",
      "\n",
      "        [[-0.0360],\n",
      "         [-0.0160],\n",
      "         [ 0.0008],\n",
      "         ...,\n",
      "         [-0.0311],\n",
      "         [-0.0311],\n",
      "         [-0.0311]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0347],\n",
      "         [-0.0387],\n",
      "         [-0.0927],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0100],\n",
      "         [ 0.0298],\n",
      "         [ 0.0275],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0126],\n",
      "         [ 0.0881],\n",
      "         [ 0.0857],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0206],\n",
      "         [-0.0130],\n",
      "         [-0.0982],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0360],\n",
      "         [-0.0160],\n",
      "         [ 0.0008],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0267],\n",
      "         [-0.0480],\n",
      "         [-0.1038],\n",
      "         ...,\n",
      "         [ 0.0353],\n",
      "         [ 0.0355],\n",
      "         [ 0.0357]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[-0.0127],\n",
      "         [ 0.0273],\n",
      "         [ 0.0249],\n",
      "         ...,\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1694],\n",
      "         [ 0.2491],\n",
      "         [ 0.2457],\n",
      "         ...,\n",
      "         [ 0.1853],\n",
      "         [ 0.1856],\n",
      "         [ 0.1858]],\n",
      "\n",
      "        [[-0.0231],\n",
      "         [-0.0153],\n",
      "         [-0.1006],\n",
      "         ...,\n",
      "         [-0.0171],\n",
      "         [-0.0170],\n",
      "         [-0.0170]],\n",
      "\n",
      "        [[-0.0362],\n",
      "         [-0.0163],\n",
      "         [ 0.0006],\n",
      "         ...,\n",
      "         [-0.0314],\n",
      "         [-0.0313],\n",
      "         [-0.0313]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0267],\n",
      "         [-0.0480],\n",
      "         [-0.1038],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0127],\n",
      "         [ 0.0273],\n",
      "         [ 0.0249],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1694],\n",
      "         [ 0.2491],\n",
      "         [ 0.2457],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0231],\n",
      "         [-0.0153],\n",
      "         [-0.1006],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0362],\n",
      "         [-0.0163],\n",
      "         [ 0.0006],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0498],\n",
      "         [-0.0254],\n",
      "         [-0.0834],\n",
      "         ...,\n",
      "         [ 0.0610],\n",
      "         [ 0.0612],\n",
      "         [ 0.0614]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[-0.0142],\n",
      "         [ 0.0259],\n",
      "         [ 0.0234],\n",
      "         ...,\n",
      "         [-0.0073],\n",
      "         [-0.0073],\n",
      "         [-0.0073]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2026],\n",
      "         [ 0.2831],\n",
      "         [ 0.2797],\n",
      "         ...,\n",
      "         [ 0.2182],\n",
      "         [ 0.2185],\n",
      "         [ 0.2187]],\n",
      "\n",
      "        [[-0.0244],\n",
      "         [-0.0166],\n",
      "         [-0.1020],\n",
      "         ...,\n",
      "         [-0.0185],\n",
      "         [-0.0184],\n",
      "         [-0.0184]],\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.0164],\n",
      "         [ 0.0005],\n",
      "         ...,\n",
      "         [-0.0315],\n",
      "         [-0.0315],\n",
      "         [-0.0315]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0498],\n",
      "         [-0.0254],\n",
      "         [-0.0834],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0212],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0142],\n",
      "         [ 0.0259],\n",
      "         [ 0.0234],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2026],\n",
      "         [ 0.2831],\n",
      "         [ 0.2797],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0244],\n",
      "         [-0.0166],\n",
      "         [-0.1020],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.0164],\n",
      "         [ 0.0005],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0147],\n",
      "         [-0.0596],\n",
      "         [-0.1153],\n",
      "         ...,\n",
      "         [ 0.0231],\n",
      "         [ 0.0234],\n",
      "         [ 0.0235]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        [[-0.0150],\n",
      "         [ 0.0251],\n",
      "         [ 0.0226],\n",
      "         ...,\n",
      "         [-0.0082],\n",
      "         [-0.0082],\n",
      "         [-0.0082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1823],\n",
      "         [ 0.2620],\n",
      "         [ 0.2591],\n",
      "         ...,\n",
      "         [ 0.1976],\n",
      "         [ 0.1979],\n",
      "         [ 0.1981]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0173],\n",
      "         [-0.1028],\n",
      "         ...,\n",
      "         [-0.0192],\n",
      "         [-0.0191],\n",
      "         [-0.0191]],\n",
      "\n",
      "        [[-0.0365],\n",
      "         [-0.0165],\n",
      "         [ 0.0004],\n",
      "         ...,\n",
      "         [-0.0316],\n",
      "         [-0.0316],\n",
      "         [-0.0316]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0147],\n",
      "         [-0.0596],\n",
      "         [-0.1153],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0150],\n",
      "         [ 0.0251],\n",
      "         [ 0.0226],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1823],\n",
      "         [ 0.2620],\n",
      "         [ 0.2591],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [-0.0173],\n",
      "         [-0.1028],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0365],\n",
      "         [-0.0165],\n",
      "         [ 0.0004],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0049],\n",
      "         [-0.0786],\n",
      "         [-0.1329],\n",
      "         ...,\n",
      "         [ 0.0015],\n",
      "         [ 0.0018],\n",
      "         [ 0.0019]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0154],\n",
      "         [ 0.0247],\n",
      "         [ 0.0221],\n",
      "         ...,\n",
      "         [-0.0087],\n",
      "         [-0.0086],\n",
      "         [-0.0086]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1968],\n",
      "         [ 0.2759],\n",
      "         [ 0.2729],\n",
      "         ...,\n",
      "         [ 0.2123],\n",
      "         [ 0.2127],\n",
      "         [ 0.2129]],\n",
      "\n",
      "        [[-0.0255],\n",
      "         [-0.0177],\n",
      "         [-0.1032],\n",
      "         ...,\n",
      "         [-0.0195],\n",
      "         [-0.0195],\n",
      "         [-0.0194]],\n",
      "\n",
      "        [[-0.0365],\n",
      "         [-0.0165],\n",
      "         [ 0.0004],\n",
      "         ...,\n",
      "         [-0.0316],\n",
      "         [-0.0316],\n",
      "         [-0.0316]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0049],\n",
      "         [-0.0786],\n",
      "         [-0.1329],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0154],\n",
      "         [ 0.0247],\n",
      "         [ 0.0221],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1968],\n",
      "         [ 0.2759],\n",
      "         [ 0.2729],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0255],\n",
      "         [-0.0177],\n",
      "         [-0.1032],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0365],\n",
      "         [-0.0165],\n",
      "         [ 0.0004],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0159],\n",
      "         [-0.0893],\n",
      "         [-0.1428],\n",
      "         ...,\n",
      "         [-0.0107],\n",
      "         [-0.0105],\n",
      "         [-0.0103]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0157],\n",
      "         [ 0.0244],\n",
      "         [ 0.0219],\n",
      "         ...,\n",
      "         [-0.0089],\n",
      "         [-0.0089],\n",
      "         [-0.0089]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1244],\n",
      "         [ 0.2030],\n",
      "         [ 0.2000],\n",
      "         ...,\n",
      "         [ 0.1380],\n",
      "         [ 0.1383],\n",
      "         [ 0.1385]],\n",
      "\n",
      "        [[-0.0256],\n",
      "         [-0.0179],\n",
      "         [-0.1034],\n",
      "         ...,\n",
      "         [-0.0197],\n",
      "         [-0.0196],\n",
      "         [-0.0196]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0159],\n",
      "         [-0.0893],\n",
      "         [-0.1428],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0157],\n",
      "         [ 0.0244],\n",
      "         [ 0.0219],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1244],\n",
      "         [ 0.2030],\n",
      "         [ 0.2000],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0256],\n",
      "         [-0.0179],\n",
      "         [-0.1034],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0221],\n",
      "         [-0.0954],\n",
      "         [-0.1485],\n",
      "         ...,\n",
      "         [-0.0176],\n",
      "         [-0.0174],\n",
      "         [-0.0172]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0158],\n",
      "         [ 0.0243],\n",
      "         [ 0.0218],\n",
      "         ...,\n",
      "         [-0.0090],\n",
      "         [-0.0090],\n",
      "         [-0.0090]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0561],\n",
      "         [ 0.1321],\n",
      "         [ 0.1294],\n",
      "         ...,\n",
      "         [ 0.0672],\n",
      "         [ 0.0675],\n",
      "         [ 0.0677]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0197],\n",
      "         [-0.0197],\n",
      "         [-0.0196]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0221],\n",
      "         [-0.0954],\n",
      "         [-0.1485],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0158],\n",
      "         [ 0.0243],\n",
      "         [ 0.0218],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0561],\n",
      "         [ 0.1321],\n",
      "         [ 0.1294],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0256],\n",
      "         [-0.0988],\n",
      "         [-0.1518],\n",
      "         ...,\n",
      "         [-0.0216],\n",
      "         [-0.0213],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0243],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [-0.0091],\n",
      "         [-0.0091],\n",
      "         [-0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0212],\n",
      "         [ 0.0956],\n",
      "         [ 0.0934],\n",
      "         ...,\n",
      "         [ 0.0300],\n",
      "         [ 0.0304],\n",
      "         [ 0.0306]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0197],\n",
      "         [-0.0197],\n",
      "         [-0.0196]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0256],\n",
      "         [-0.0988],\n",
      "         [-0.1518],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0243],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0212],\n",
      "         [ 0.0956],\n",
      "         [ 0.0934],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0276],\n",
      "         [-0.1008],\n",
      "         [-0.1536],\n",
      "         ...,\n",
      "         [-0.0238],\n",
      "         [-0.0236],\n",
      "         [-0.0234]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [-0.0091],\n",
      "         [-0.0091],\n",
      "         [-0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0031],\n",
      "         [ 0.0767],\n",
      "         [ 0.0748],\n",
      "         ...,\n",
      "         [ 0.0105],\n",
      "         [ 0.0109],\n",
      "         [ 0.0111]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0197],\n",
      "         [-0.0196],\n",
      "         [-0.0196]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0276],\n",
      "         [-0.1008],\n",
      "         [-0.1536],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0031],\n",
      "         [ 0.0767],\n",
      "         [ 0.0748],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-2.8735e-02],\n",
      "         [-1.0189e-01],\n",
      "         [-1.5471e-01],\n",
      "         ...,\n",
      "         [-2.5060e-02],\n",
      "         [-2.4826e-02],\n",
      "         [-2.4667e-02]],\n",
      "\n",
      "        [[-2.1139e-02],\n",
      "         [-1.3162e-02],\n",
      "         [-4.0352e-02],\n",
      "         ...,\n",
      "         [-1.5441e-02],\n",
      "         [-1.5440e-02],\n",
      "         [-1.5440e-02]],\n",
      "\n",
      "        [[-1.5912e-02],\n",
      "         [ 2.4211e-02],\n",
      "         [ 2.1681e-02],\n",
      "         ...,\n",
      "         [-9.1305e-03],\n",
      "         [-9.1075e-03],\n",
      "         [-9.0916e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.5095e-03],\n",
      "         [ 6.6640e-02],\n",
      "         [ 6.5009e-02],\n",
      "         ...,\n",
      "         [ 1.4018e-04],\n",
      "         [ 4.5469e-04],\n",
      "         [ 6.6833e-04]],\n",
      "\n",
      "        [[-2.5730e-02],\n",
      "         [-1.8042e-02],\n",
      "         [-1.0354e-01],\n",
      "         ...,\n",
      "         [-1.9665e-02],\n",
      "         [-1.9608e-02],\n",
      "         [-1.9569e-02]],\n",
      "\n",
      "        [[-3.6602e-02],\n",
      "         [-1.6622e-02],\n",
      "         [ 2.7301e-04],\n",
      "         ...,\n",
      "         [-3.1715e-02],\n",
      "         [-3.1714e-02],\n",
      "         [-3.1714e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0287],\n",
      "         [-0.1019],\n",
      "         [-0.1547],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0065],\n",
      "         [ 0.0666],\n",
      "         [ 0.0650],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0294],\n",
      "         [-0.1025],\n",
      "         [-0.1553],\n",
      "         ...,\n",
      "         [-0.0258],\n",
      "         [-0.0255],\n",
      "         [-0.0254]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [-0.0091],\n",
      "         [-0.0091],\n",
      "         [-0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0117],\n",
      "         [ 0.0613],\n",
      "         [ 0.0598],\n",
      "         ...,\n",
      "         [-0.0055],\n",
      "         [-0.0051],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0196],\n",
      "         [-0.0196],\n",
      "         [-0.0195]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0294],\n",
      "         [-0.1025],\n",
      "         [-0.1553],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0117],\n",
      "         [ 0.0613],\n",
      "         [ 0.0598],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0297],\n",
      "         [-0.1029],\n",
      "         [-0.1557],\n",
      "         ...,\n",
      "         [-0.0262],\n",
      "         [-0.0259],\n",
      "         [-0.0258]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [-0.0091],\n",
      "         [-0.0091],\n",
      "         [-0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0144],\n",
      "         [ 0.0584],\n",
      "         [ 0.0570],\n",
      "         ...,\n",
      "         [-0.0085],\n",
      "         [-0.0081],\n",
      "         [-0.0079]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0196],\n",
      "         [-0.0196],\n",
      "         [-0.0195]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0297],\n",
      "         [-0.1029],\n",
      "         [-0.1557],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0144],\n",
      "         [ 0.0584],\n",
      "         [ 0.0570],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [-0.1031],\n",
      "         [-0.1559],\n",
      "         ...,\n",
      "         [-0.0264],\n",
      "         [-0.0262],\n",
      "         [-0.0260]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [-0.0091],\n",
      "         [-0.0091],\n",
      "         [-0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0569],\n",
      "         [ 0.0555],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0098],\n",
      "         [-0.0095]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0196],\n",
      "         [-0.0195],\n",
      "         [-0.0195]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [-0.1031],\n",
      "         [-0.1559],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0569],\n",
      "         [ 0.0555],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0301],\n",
      "         [-0.1032],\n",
      "         [-0.1560],\n",
      "         ...,\n",
      "         [-0.0265],\n",
      "         [-0.0263],\n",
      "         [-0.0261]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [-0.0091],\n",
      "         [-0.0091],\n",
      "         [-0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0167],\n",
      "         [ 0.0560],\n",
      "         [ 0.0547],\n",
      "         ...,\n",
      "         [-0.0109],\n",
      "         [-0.0106],\n",
      "         [-0.0104]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0196],\n",
      "         [-0.0195],\n",
      "         [-0.0195]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0301],\n",
      "         [-0.1032],\n",
      "         [-0.1560],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0167],\n",
      "         [ 0.0560],\n",
      "         [ 0.0547],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0301],\n",
      "         [-0.1033],\n",
      "         [-0.1560],\n",
      "         ...,\n",
      "         [-0.0266],\n",
      "         [-0.0264],\n",
      "         [-0.0262]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [-0.0091],\n",
      "         [-0.0091],\n",
      "         [-0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0556],\n",
      "         [ 0.0542],\n",
      "         ...,\n",
      "         [-0.0114],\n",
      "         [-0.0111],\n",
      "         [-0.0108]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0196],\n",
      "         [-0.0195],\n",
      "         [-0.0195]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0301],\n",
      "         [-0.1033],\n",
      "         [-0.1560],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0556],\n",
      "         [ 0.0542],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0302],\n",
      "         [-0.1033],\n",
      "         [-0.1561],\n",
      "         ...,\n",
      "         [-0.0267],\n",
      "         [-0.0264],\n",
      "         [-0.0263]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [-0.0091],\n",
      "         [-0.0091],\n",
      "         [-0.0091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0554],\n",
      "         [ 0.0540],\n",
      "         ...,\n",
      "         [-0.0116],\n",
      "         [-0.0113],\n",
      "         [-0.0111]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [-0.0196],\n",
      "         [-0.0195],\n",
      "         [-0.0195]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [-0.0317],\n",
      "         [-0.0317]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0302],\n",
      "         [-0.1033],\n",
      "         [-0.1561],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0211],\n",
      "         [-0.0132],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0159],\n",
      "         [ 0.0242],\n",
      "         [ 0.0217],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0554],\n",
      "         [ 0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0257],\n",
      "         [-0.0180],\n",
      "         [-0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0366],\n",
      "         [-0.0166],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/25000 [00:01<3:41:25,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот в AttentiveModel сделали mask. Она выглядит так:\n",
      "torch.BoolTensor\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2013],\n",
      "         [0.2512],\n",
      "         [0.1539],\n",
      "         ...,\n",
      "         [0.2100],\n",
      "         [0.2100],\n",
      "         [0.2100]],\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.2987],\n",
      "         [0.2786],\n",
      "         ...,\n",
      "         [0.2100],\n",
      "         [0.2100],\n",
      "         [0.2100]],\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.3054],\n",
      "         [0.1683],\n",
      "         ...,\n",
      "         [0.2099],\n",
      "         [0.2099],\n",
      "         [0.2099]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.1606],\n",
      "         [0.1491],\n",
      "         ...,\n",
      "         [0.1924],\n",
      "         [0.1979],\n",
      "         [0.2016]],\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.0821],\n",
      "         [0.1467],\n",
      "         ...,\n",
      "         [0.2100],\n",
      "         [0.2100],\n",
      "         [0.2100]],\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.1285],\n",
      "         [0.2296],\n",
      "         ...,\n",
      "         [0.1847],\n",
      "         [0.1926],\n",
      "         [0.1981]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.2013],\n",
      "         [0.2512],\n",
      "         [0.1539],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.2987],\n",
      "         [0.2786],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.3054],\n",
      "         [0.1683],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.1606],\n",
      "         [0.1491],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.0821],\n",
      "         [0.1467],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2013],\n",
      "         [0.1285],\n",
      "         [0.2296],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1366],\n",
      "         [0.1855],\n",
      "         [0.0869],\n",
      "         ...,\n",
      "         [0.1465],\n",
      "         [0.1465],\n",
      "         [0.1465]],\n",
      "\n",
      "        [[0.1465],\n",
      "         [0.2438],\n",
      "         [0.2238],\n",
      "         ...,\n",
      "         [0.1561],\n",
      "         [0.1561],\n",
      "         [0.1561]],\n",
      "\n",
      "        [[0.1391],\n",
      "         [0.2426],\n",
      "         [0.1045],\n",
      "         ...,\n",
      "         [0.1489],\n",
      "         [0.1489],\n",
      "         [0.1489]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1449],\n",
      "         [0.1050],\n",
      "         [0.0921],\n",
      "         ...,\n",
      "         [0.1366],\n",
      "         [0.1422],\n",
      "         [0.1460]],\n",
      "\n",
      "        [[0.1283],\n",
      "         [0.0078],\n",
      "         [0.0758],\n",
      "         ...,\n",
      "         [0.1378],\n",
      "         [0.1378],\n",
      "         [0.1378]],\n",
      "\n",
      "        [[0.1393],\n",
      "         [0.0651],\n",
      "         [0.1667],\n",
      "         ...,\n",
      "         [0.1232],\n",
      "         [0.1313],\n",
      "         [0.1369]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1366],\n",
      "         [0.1855],\n",
      "         [0.0869],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1465],\n",
      "         [0.2438],\n",
      "         [0.2238],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1391],\n",
      "         [0.2426],\n",
      "         [0.1045],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1449],\n",
      "         [0.1050],\n",
      "         [0.0921],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1283],\n",
      "         [0.0078],\n",
      "         [0.0758],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1393],\n",
      "         [0.0651],\n",
      "         [0.1667],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.0525],\n",
      "         [0.0997],\n",
      "         [0.0021],\n",
      "         ...,\n",
      "         [0.0613],\n",
      "         [0.0613],\n",
      "         [0.0613]],\n",
      "\n",
      "        [[0.0407],\n",
      "         [0.1363],\n",
      "         [0.1181],\n",
      "         ...,\n",
      "         [0.0508],\n",
      "         [0.0508],\n",
      "         [0.0508]],\n",
      "\n",
      "        [[0.0423],\n",
      "         [0.1449],\n",
      "         [0.0069],\n",
      "         ...,\n",
      "         [0.0520],\n",
      "         [0.0520],\n",
      "         [0.0520]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1678],\n",
      "         [0.1276],\n",
      "         [0.1146],\n",
      "         ...,\n",
      "         [0.1603],\n",
      "         [0.1660],\n",
      "         [0.1700]],\n",
      "\n",
      "        [[0.1441],\n",
      "         [0.0217],\n",
      "         [0.0917],\n",
      "         ...,\n",
      "         [0.1545],\n",
      "         [0.1545],\n",
      "         [0.1545]],\n",
      "\n",
      "        [[0.2556],\n",
      "         [0.1811],\n",
      "         [0.2822],\n",
      "         ...,\n",
      "         [0.2438],\n",
      "         [0.2521],\n",
      "         [0.2579]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.0525],\n",
      "         [0.0997],\n",
      "         [0.0021],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.0407],\n",
      "         [0.1363],\n",
      "         [0.1181],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.0423],\n",
      "         [0.1449],\n",
      "         [0.0069],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1678],\n",
      "         [0.1276],\n",
      "         [0.1146],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1441],\n",
      "         [0.0217],\n",
      "         [0.0917],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.2556],\n",
      "         [0.1811],\n",
      "         [0.2822],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 4.4192e-02],\n",
      "         [ 9.2601e-02],\n",
      "         [-7.3103e-03],\n",
      "         ...,\n",
      "         [ 5.3564e-02],\n",
      "         [ 5.3565e-02],\n",
      "         [ 5.3565e-02]],\n",
      "\n",
      "        [[ 1.0106e-01],\n",
      "         [ 1.9778e-01],\n",
      "         [ 1.7766e-01],\n",
      "         ...,\n",
      "         [ 1.1371e-01],\n",
      "         [ 1.1371e-01],\n",
      "         [ 1.1371e-01]],\n",
      "\n",
      "        [[ 5.3900e-02],\n",
      "         [ 1.5806e-01],\n",
      "         [ 1.8774e-02],\n",
      "         ...,\n",
      "         [ 6.1967e-02],\n",
      "         [ 6.1978e-02],\n",
      "         [ 6.1985e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.3797e-03],\n",
      "         [-3.1522e-02],\n",
      "         [-4.7046e-02],\n",
      "         ...,\n",
      "         [-5.4524e-03],\n",
      "         [ 3.8236e-05],\n",
      "         [ 3.8503e-03]],\n",
      "\n",
      "        [[ 1.3610e-01],\n",
      "         [ 1.3968e-02],\n",
      "         [ 8.5913e-02],\n",
      "         ...,\n",
      "         [ 1.4585e-01],\n",
      "         [ 1.4585e-01],\n",
      "         [ 1.4585e-01]],\n",
      "\n",
      "        [[ 2.1296e-01],\n",
      "         [ 1.3792e-01],\n",
      "         [ 2.3951e-01],\n",
      "         ...,\n",
      "         [ 1.9964e-01],\n",
      "         [ 2.0794e-01],\n",
      "         [ 2.1368e-01]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0442],\n",
      "         [ 0.0926],\n",
      "         [-0.0073],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1011],\n",
      "         [ 0.1978],\n",
      "         [ 0.1777],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0539],\n",
      "         [ 0.1581],\n",
      "         [ 0.0188],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0044],\n",
      "         [-0.0315],\n",
      "         [-0.0470],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1361],\n",
      "         [ 0.0140],\n",
      "         [ 0.0859],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2130],\n",
      "         [ 0.1379],\n",
      "         [ 0.2395],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0131],\n",
      "         [ 0.0597],\n",
      "         [-0.0387],\n",
      "         ...,\n",
      "         [ 0.0214],\n",
      "         [ 0.0214],\n",
      "         [ 0.0214]],\n",
      "\n",
      "        [[ 0.0448],\n",
      "         [ 0.1404],\n",
      "         [ 0.1212],\n",
      "         ...,\n",
      "         [ 0.0562],\n",
      "         [ 0.0562],\n",
      "         [ 0.0562]],\n",
      "\n",
      "        [[ 0.1628],\n",
      "         [ 0.2668],\n",
      "         [ 0.1285],\n",
      "         ...,\n",
      "         [ 0.1737],\n",
      "         [ 0.1737],\n",
      "         [ 0.1737]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0301],\n",
      "         [-0.0084],\n",
      "         [-0.0224],\n",
      "         ...,\n",
      "         [ 0.0221],\n",
      "         [ 0.0276],\n",
      "         [ 0.0315]],\n",
      "\n",
      "        [[ 0.1045],\n",
      "         [-0.0146],\n",
      "         [ 0.0538],\n",
      "         ...,\n",
      "         [ 0.1147],\n",
      "         [ 0.1147],\n",
      "         [ 0.1147]],\n",
      "\n",
      "        [[ 0.1451],\n",
      "         [ 0.0712],\n",
      "         [ 0.1710],\n",
      "         ...,\n",
      "         [ 0.1315],\n",
      "         [ 0.1398],\n",
      "         [ 0.1455]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0131],\n",
      "         [ 0.0597],\n",
      "         [-0.0387],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0448],\n",
      "         [ 0.1404],\n",
      "         [ 0.1212],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1628],\n",
      "         [ 0.2668],\n",
      "         [ 0.1285],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0301],\n",
      "         [-0.0084],\n",
      "         [-0.0224],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1045],\n",
      "         [-0.0146],\n",
      "         [ 0.0538],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1451],\n",
      "         [ 0.0712],\n",
      "         [ 0.1710],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0253],\n",
      "         [ 0.0728],\n",
      "         [-0.0251],\n",
      "         ...,\n",
      "         [ 0.0372],\n",
      "         [ 0.0372],\n",
      "         [ 0.0372]],\n",
      "\n",
      "        [[ 0.0984],\n",
      "         [ 0.1947],\n",
      "         [ 0.1755],\n",
      "         ...,\n",
      "         [ 0.1075],\n",
      "         [ 0.1075],\n",
      "         [ 0.1075]],\n",
      "\n",
      "        [[ 0.1451],\n",
      "         [ 0.2471],\n",
      "         [ 0.1109],\n",
      "         ...,\n",
      "         [ 0.1561],\n",
      "         [ 0.1561],\n",
      "         [ 0.1561]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0789],\n",
      "         [ 0.0399],\n",
      "         [ 0.0259],\n",
      "         ...,\n",
      "         [ 0.0705],\n",
      "         [ 0.0761],\n",
      "         [ 0.0800]],\n",
      "\n",
      "        [[ 0.0202],\n",
      "         [-0.0973],\n",
      "         [-0.0255],\n",
      "         ...,\n",
      "         [ 0.0269],\n",
      "         [ 0.0270],\n",
      "         [ 0.0270]],\n",
      "\n",
      "        [[ 0.1235],\n",
      "         [ 0.0505],\n",
      "         [ 0.1507],\n",
      "         ...,\n",
      "         [ 0.1093],\n",
      "         [ 0.1176],\n",
      "         [ 0.1233]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0253],\n",
      "         [ 0.0728],\n",
      "         [-0.0251],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0984],\n",
      "         [ 0.1947],\n",
      "         [ 0.1755],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1451],\n",
      "         [ 0.2471],\n",
      "         [ 0.1109],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0789],\n",
      "         [ 0.0399],\n",
      "         [ 0.0259],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0202],\n",
      "         [-0.0973],\n",
      "         [-0.0255],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1235],\n",
      "         [ 0.0505],\n",
      "         [ 0.1507],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0621],\n",
      "         [ 0.1111],\n",
      "         [ 0.0154],\n",
      "         ...,\n",
      "         [ 0.0769],\n",
      "         [ 0.0769],\n",
      "         [ 0.0769]],\n",
      "\n",
      "        [[-0.0475],\n",
      "         [ 0.0441],\n",
      "         [ 0.0289],\n",
      "         ...,\n",
      "         [-0.0405],\n",
      "         [-0.0405],\n",
      "         [-0.0405]],\n",
      "\n",
      "        [[ 0.1377],\n",
      "         [ 0.2394],\n",
      "         [ 0.1037],\n",
      "         ...,\n",
      "         [ 0.1487],\n",
      "         [ 0.1487],\n",
      "         [ 0.1487]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1046],\n",
      "         [ 0.0676],\n",
      "         [ 0.0528],\n",
      "         ...,\n",
      "         [ 0.0951],\n",
      "         [ 0.1007],\n",
      "         [ 0.1046]],\n",
      "\n",
      "        [[-0.0439],\n",
      "         [-0.1595],\n",
      "         [-0.0816],\n",
      "         ...,\n",
      "         [-0.0433],\n",
      "         [-0.0433],\n",
      "         [-0.0433]],\n",
      "\n",
      "        [[ 0.1293],\n",
      "         [ 0.0578],\n",
      "         [ 0.1561],\n",
      "         ...,\n",
      "         [ 0.1164],\n",
      "         [ 0.1246],\n",
      "         [ 0.1303]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0621],\n",
      "         [ 0.1111],\n",
      "         [ 0.0154],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0475],\n",
      "         [ 0.0441],\n",
      "         [ 0.0289],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1377],\n",
      "         [ 0.2394],\n",
      "         [ 0.1037],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1046],\n",
      "         [ 0.0676],\n",
      "         [ 0.0528],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0439],\n",
      "         [-0.1595],\n",
      "         [-0.0816],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1293],\n",
      "         [ 0.0578],\n",
      "         [ 0.1561],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1103],\n",
      "         [ 0.1602],\n",
      "         [ 0.0609],\n",
      "         ...,\n",
      "         [ 0.1213],\n",
      "         [ 0.1213],\n",
      "         [ 0.1213]],\n",
      "\n",
      "        [[-0.0408],\n",
      "         [ 0.0515],\n",
      "         [ 0.0354],\n",
      "         ...,\n",
      "         [-0.0327],\n",
      "         [-0.0327],\n",
      "         [-0.0327]],\n",
      "\n",
      "        [[ 0.0299],\n",
      "         [ 0.1320],\n",
      "         [-0.0047],\n",
      "         ...,\n",
      "         [ 0.0380],\n",
      "         [ 0.0380],\n",
      "         [ 0.0380]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0104],\n",
      "         [-0.0244],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0008],\n",
      "         [ 0.0046],\n",
      "         [ 0.0084]],\n",
      "\n",
      "        [[ 0.0407],\n",
      "         [-0.0761],\n",
      "         [-0.0054],\n",
      "         ...,\n",
      "         [ 0.0475],\n",
      "         [ 0.0475],\n",
      "         [ 0.0475]],\n",
      "\n",
      "        [[ 0.0460],\n",
      "         [-0.0261],\n",
      "         [ 0.0716],\n",
      "         ...,\n",
      "         [ 0.0311],\n",
      "         [ 0.0392],\n",
      "         [ 0.0448]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1103],\n",
      "         [ 0.1602],\n",
      "         [ 0.0609],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0408],\n",
      "         [ 0.0515],\n",
      "         [ 0.0354],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0299],\n",
      "         [ 0.1320],\n",
      "         [-0.0047],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0104],\n",
      "         [-0.0244],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0407],\n",
      "         [-0.0761],\n",
      "         [-0.0054],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0460],\n",
      "         [-0.0261],\n",
      "         [ 0.0716],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0837],\n",
      "         [ 0.1334],\n",
      "         [ 0.0350],\n",
      "         ...,\n",
      "         [ 0.0957],\n",
      "         [ 0.0957],\n",
      "         [ 0.0957]],\n",
      "\n",
      "        [[ 0.0912],\n",
      "         [ 0.1875],\n",
      "         [ 0.1696],\n",
      "         ...,\n",
      "         [ 0.0981],\n",
      "         [ 0.0981],\n",
      "         [ 0.0981]],\n",
      "\n",
      "        [[ 0.0475],\n",
      "         [ 0.1476],\n",
      "         [ 0.0131],\n",
      "         ...,\n",
      "         [ 0.0575],\n",
      "         [ 0.0575],\n",
      "         [ 0.0575]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0473],\n",
      "         [-0.0790],\n",
      "         [-0.0962],\n",
      "         ...,\n",
      "         [-0.0607],\n",
      "         [-0.0555],\n",
      "         [-0.0519]],\n",
      "\n",
      "        [[ 0.0871],\n",
      "         [-0.0330],\n",
      "         [ 0.0426],\n",
      "         ...,\n",
      "         [ 0.0935],\n",
      "         [ 0.0935],\n",
      "         [ 0.0935]],\n",
      "\n",
      "        [[ 0.1070],\n",
      "         [ 0.0341],\n",
      "         [ 0.1336],\n",
      "         ...,\n",
      "         [ 0.0922],\n",
      "         [ 0.1004],\n",
      "         [ 0.1061]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0837],\n",
      "         [ 0.1334],\n",
      "         [ 0.0350],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0912],\n",
      "         [ 0.1875],\n",
      "         [ 0.1696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0475],\n",
      "         [ 0.1476],\n",
      "         [ 0.0131],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0473],\n",
      "         [-0.0790],\n",
      "         [-0.0962],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0871],\n",
      "         [-0.0330],\n",
      "         [ 0.0426],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1070],\n",
      "         [ 0.0341],\n",
      "         [ 0.1336],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0328],\n",
      "         [ 0.0801],\n",
      "         [-0.0180],\n",
      "         ...,\n",
      "         [ 0.0427],\n",
      "         [ 0.0427],\n",
      "         [ 0.0427]],\n",
      "\n",
      "        [[ 0.0837],\n",
      "         [ 0.1803],\n",
      "         [ 0.1611],\n",
      "         ...,\n",
      "         [ 0.0932],\n",
      "         [ 0.0932],\n",
      "         [ 0.0932]],\n",
      "\n",
      "        [[ 0.1032],\n",
      "         [ 0.2067],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [ 0.1140],\n",
      "         [ 0.1140],\n",
      "         [ 0.1140]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0156],\n",
      "         [-0.0476],\n",
      "         [-0.0650],\n",
      "         ...,\n",
      "         [-0.0295],\n",
      "         [-0.0242],\n",
      "         [-0.0206]],\n",
      "\n",
      "        [[-0.0147],\n",
      "         [-0.1336],\n",
      "         [-0.0569],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        [[ 0.0897],\n",
      "         [ 0.0171],\n",
      "         [ 0.1159],\n",
      "         ...,\n",
      "         [ 0.0754],\n",
      "         [ 0.0835],\n",
      "         [ 0.0892]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0328],\n",
      "         [ 0.0801],\n",
      "         [-0.0180],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0837],\n",
      "         [ 0.1803],\n",
      "         [ 0.1611],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1032],\n",
      "         [ 0.2067],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0156],\n",
      "         [-0.0476],\n",
      "         [-0.0650],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0147],\n",
      "         [-0.1336],\n",
      "         [-0.0569],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0897],\n",
      "         [ 0.0171],\n",
      "         [ 0.1159],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0063],\n",
      "         [ 0.0521],\n",
      "         [-0.0458],\n",
      "         ...,\n",
      "         [ 0.0141],\n",
      "         [ 0.0141],\n",
      "         [ 0.0141]],\n",
      "\n",
      "        [[ 0.0404],\n",
      "         [ 0.1352],\n",
      "         [ 0.1170],\n",
      "         ...,\n",
      "         [ 0.0483],\n",
      "         [ 0.0483],\n",
      "         [ 0.0483]],\n",
      "\n",
      "        [[ 0.0470],\n",
      "         [ 0.1497],\n",
      "         [ 0.0124],\n",
      "         ...,\n",
      "         [ 0.0553],\n",
      "         [ 0.0553],\n",
      "         [ 0.0553]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0633],\n",
      "         [ 0.0261],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [ 0.0535],\n",
      "         [ 0.0590],\n",
      "         [ 0.0628]],\n",
      "\n",
      "        [[ 0.1449],\n",
      "         [ 0.0234],\n",
      "         [ 0.0883],\n",
      "         ...,\n",
      "         [ 0.1580],\n",
      "         [ 0.1580],\n",
      "         [ 0.1580]],\n",
      "\n",
      "        [[ 0.0239],\n",
      "         [-0.0463],\n",
      "         [ 0.0497],\n",
      "         ...,\n",
      "         [ 0.0076],\n",
      "         [ 0.0154],\n",
      "         [ 0.0209]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0063],\n",
      "         [ 0.0521],\n",
      "         [-0.0458],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0404],\n",
      "         [ 0.1352],\n",
      "         [ 0.1170],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0470],\n",
      "         [ 0.1497],\n",
      "         [ 0.0124],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0633],\n",
      "         [ 0.0261],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1449],\n",
      "         [ 0.0234],\n",
      "         [ 0.0883],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0239],\n",
      "         [-0.0463],\n",
      "         [ 0.0497],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0084],\n",
      "         [ 0.0367],\n",
      "         [-0.0613],\n",
      "         ...,\n",
      "         [-0.0019],\n",
      "         [-0.0019],\n",
      "         [-0.0019]],\n",
      "\n",
      "        [[ 0.0178],\n",
      "         [ 0.1117],\n",
      "         [ 0.0945],\n",
      "         ...,\n",
      "         [ 0.0240],\n",
      "         [ 0.0240],\n",
      "         [ 0.0240]],\n",
      "\n",
      "        [[ 0.0940],\n",
      "         [ 0.1974],\n",
      "         [ 0.0597],\n",
      "         ...,\n",
      "         [ 0.1019],\n",
      "         [ 0.1019],\n",
      "         [ 0.1020]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1112],\n",
      "         [ 0.0708],\n",
      "         [ 0.0590],\n",
      "         ...,\n",
      "         [ 0.1041],\n",
      "         [ 0.1096],\n",
      "         [ 0.1134]],\n",
      "\n",
      "        [[ 0.1774],\n",
      "         [ 0.0565],\n",
      "         [ 0.1249],\n",
      "         ...,\n",
      "         [ 0.1895],\n",
      "         [ 0.1895],\n",
      "         [ 0.1895]],\n",
      "\n",
      "        [[ 0.1706],\n",
      "         [ 0.0970],\n",
      "         [ 0.1973],\n",
      "         ...,\n",
      "         [ 0.1577],\n",
      "         [ 0.1660],\n",
      "         [ 0.1717]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0084],\n",
      "         [ 0.0367],\n",
      "         [-0.0613],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0178],\n",
      "         [ 0.1117],\n",
      "         [ 0.0945],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0940],\n",
      "         [ 0.1974],\n",
      "         [ 0.0597],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1112],\n",
      "         [ 0.0708],\n",
      "         [ 0.0590],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1774],\n",
      "         [ 0.0565],\n",
      "         [ 0.1249],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1706],\n",
      "         [ 0.0970],\n",
      "         [ 0.1973],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0168],\n",
      "         [ 0.0279],\n",
      "         [-0.0701],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0055],\n",
      "         [ 0.0991],\n",
      "         [ 0.0826],\n",
      "         ...,\n",
      "         [ 0.0108],\n",
      "         [ 0.0108],\n",
      "         [ 0.0108]],\n",
      "\n",
      "        [[ 0.0515],\n",
      "         [ 0.1565],\n",
      "         [ 0.0169],\n",
      "         ...,\n",
      "         [ 0.0585],\n",
      "         [ 0.0585],\n",
      "         [ 0.0585]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0200],\n",
      "         [-0.0555],\n",
      "         [-0.0697],\n",
      "         ...,\n",
      "         [-0.0282],\n",
      "         [-0.0229],\n",
      "         [-0.0192]],\n",
      "\n",
      "        [[ 0.1558],\n",
      "         [ 0.0343],\n",
      "         [ 0.1045],\n",
      "         ...,\n",
      "         [ 0.1675],\n",
      "         [ 0.1675],\n",
      "         [ 0.1675]],\n",
      "\n",
      "        [[ 0.2022],\n",
      "         [ 0.1309],\n",
      "         [ 0.2307],\n",
      "         ...,\n",
      "         [ 0.1885],\n",
      "         [ 0.1968],\n",
      "         [ 0.2026]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0168],\n",
      "         [ 0.0279],\n",
      "         [-0.0701],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0055],\n",
      "         [ 0.0991],\n",
      "         [ 0.0826],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0515],\n",
      "         [ 0.1565],\n",
      "         [ 0.0169],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0200],\n",
      "         [-0.0555],\n",
      "         [-0.0697],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1558],\n",
      "         [ 0.0343],\n",
      "         [ 0.1045],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2022],\n",
      "         [ 0.1309],\n",
      "         [ 0.2307],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0216],\n",
      "         [ 0.0228],\n",
      "         [-0.0752],\n",
      "         ...,\n",
      "         [-0.0163],\n",
      "         [-0.0163],\n",
      "         [-0.0163]],\n",
      "\n",
      "        [[-0.0012],\n",
      "         [ 0.0922],\n",
      "         [ 0.0761],\n",
      "         ...,\n",
      "         [ 0.0035],\n",
      "         [ 0.0035],\n",
      "         [ 0.0035]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [ 0.0933],\n",
      "         [-0.0445],\n",
      "         ...,\n",
      "         [-0.0003],\n",
      "         [-0.0002],\n",
      "         [-0.0002]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1092],\n",
      "         [ 0.0718],\n",
      "         [ 0.0586],\n",
      "         ...,\n",
      "         [ 0.1006],\n",
      "         [ 0.1061],\n",
      "         [ 0.1100]],\n",
      "\n",
      "        [[ 0.1708],\n",
      "         [ 0.0497],\n",
      "         [ 0.1187],\n",
      "         ...,\n",
      "         [ 0.1829],\n",
      "         [ 0.1829],\n",
      "         [ 0.1829]],\n",
      "\n",
      "        [[ 0.0906],\n",
      "         [ 0.0191],\n",
      "         [ 0.1180],\n",
      "         ...,\n",
      "         [ 0.0744],\n",
      "         [ 0.0827],\n",
      "         [ 0.0884]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0216],\n",
      "         [ 0.0228],\n",
      "         [-0.0752],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0012],\n",
      "         [ 0.0922],\n",
      "         [ 0.0761],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [ 0.0933],\n",
      "         [-0.0445],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1092],\n",
      "         [ 0.0718],\n",
      "         [ 0.0586],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1708],\n",
      "         [ 0.0497],\n",
      "         [ 0.1187],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0906],\n",
      "         [ 0.0191],\n",
      "         [ 0.1180],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0244],\n",
      "         [ 0.0198],\n",
      "         [-0.0782],\n",
      "         ...,\n",
      "         [-0.0194],\n",
      "         [-0.0194],\n",
      "         [-0.0194]],\n",
      "\n",
      "        [[-0.0049],\n",
      "         [ 0.0883],\n",
      "         [ 0.0725],\n",
      "         ...,\n",
      "         [-0.0005],\n",
      "         [-0.0005],\n",
      "         [-0.0005]],\n",
      "\n",
      "        [[-0.0554],\n",
      "         [ 0.0482],\n",
      "         [-0.0919],\n",
      "         ...,\n",
      "         [-0.0445],\n",
      "         [-0.0445],\n",
      "         [-0.0445]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1044],\n",
      "         [ 0.0671],\n",
      "         [ 0.0533],\n",
      "         ...,\n",
      "         [ 0.0957],\n",
      "         [ 0.1013],\n",
      "         [ 0.1051]],\n",
      "\n",
      "        [[ 0.0982],\n",
      "         [-0.0216],\n",
      "         [ 0.0489],\n",
      "         ...,\n",
      "         [ 0.1078],\n",
      "         [ 0.1078],\n",
      "         [ 0.1078]],\n",
      "\n",
      "        [[ 0.2295],\n",
      "         [ 0.1562],\n",
      "         [ 0.2558],\n",
      "         ...,\n",
      "         [ 0.2189],\n",
      "         [ 0.2273],\n",
      "         [ 0.2332]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0244],\n",
      "         [ 0.0198],\n",
      "         [-0.0782],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0049],\n",
      "         [ 0.0883],\n",
      "         [ 0.0725],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0554],\n",
      "         [ 0.0482],\n",
      "         [-0.0919],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1044],\n",
      "         [ 0.0671],\n",
      "         [ 0.0533],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0982],\n",
      "         [-0.0216],\n",
      "         [ 0.0489],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2295],\n",
      "         [ 0.1562],\n",
      "         [ 0.2558],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0260],\n",
      "         [ 0.0181],\n",
      "         [-0.0799],\n",
      "         ...,\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0070],\n",
      "         [ 0.0863],\n",
      "         [ 0.0706],\n",
      "         ...,\n",
      "         [-0.0027],\n",
      "         [-0.0027],\n",
      "         [-0.0027]],\n",
      "\n",
      "        [[-0.0050],\n",
      "         [ 0.0999],\n",
      "         [-0.0402],\n",
      "         ...,\n",
      "         [-0.0002],\n",
      "         [-0.0002],\n",
      "         [-0.0002]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1527],\n",
      "         [ 0.1137],\n",
      "         [ 0.1004],\n",
      "         ...,\n",
      "         [ 0.1451],\n",
      "         [ 0.1508],\n",
      "         [ 0.1548]],\n",
      "\n",
      "        [[ 0.0313],\n",
      "         [-0.0871],\n",
      "         [-0.0139],\n",
      "         ...,\n",
      "         [ 0.0379],\n",
      "         [ 0.0379],\n",
      "         [ 0.0379]],\n",
      "\n",
      "        [[ 0.1163],\n",
      "         [ 0.0434],\n",
      "         [ 0.1415],\n",
      "         ...,\n",
      "         [ 0.1030],\n",
      "         [ 0.1112],\n",
      "         [ 0.1169]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0260],\n",
      "         [ 0.0181],\n",
      "         [-0.0799],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0070],\n",
      "         [ 0.0863],\n",
      "         [ 0.0706],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0050],\n",
      "         [ 0.0999],\n",
      "         [-0.0402],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1527],\n",
      "         [ 0.1137],\n",
      "         [ 0.1004],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0313],\n",
      "         [-0.0871],\n",
      "         [-0.0139],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1163],\n",
      "         [ 0.0434],\n",
      "         [ 0.1415],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0270],\n",
      "         [ 0.0171],\n",
      "         [-0.0809],\n",
      "         ...,\n",
      "         [-0.0222],\n",
      "         [-0.0222],\n",
      "         [-0.0222]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0852],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0039],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[ 0.0993],\n",
      "         [ 0.2013],\n",
      "         [ 0.0649],\n",
      "         ...,\n",
      "         [ 0.1106],\n",
      "         [ 0.1106],\n",
      "         [ 0.1106]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1523],\n",
      "         [ 0.1169],\n",
      "         [ 0.1026],\n",
      "         ...,\n",
      "         [ 0.1427],\n",
      "         [ 0.1483],\n",
      "         [ 0.1522]],\n",
      "\n",
      "        [[-0.0026],\n",
      "         [-0.1207],\n",
      "         [-0.0448],\n",
      "         ...,\n",
      "         [ 0.0014],\n",
      "         [ 0.0014],\n",
      "         [ 0.0014]],\n",
      "\n",
      "        [[ 0.1355],\n",
      "         [ 0.0630],\n",
      "         [ 0.1625],\n",
      "         ...,\n",
      "         [ 0.1208],\n",
      "         [ 0.1290],\n",
      "         [ 0.1347]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0270],\n",
      "         [ 0.0171],\n",
      "         [-0.0809],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0852],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0993],\n",
      "         [ 0.2013],\n",
      "         [ 0.0649],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1523],\n",
      "         [ 0.1169],\n",
      "         [ 0.1026],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0026],\n",
      "         [-0.1207],\n",
      "         [-0.0448],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1355],\n",
      "         [ 0.0630],\n",
      "         [ 0.1625],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0276],\n",
      "         [ 0.0165],\n",
      "         [-0.0815],\n",
      "         ...,\n",
      "         [-0.0228],\n",
      "         [-0.0228],\n",
      "         [-0.0228]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0846],\n",
      "         [ 0.0690],\n",
      "         ...,\n",
      "         [-0.0045],\n",
      "         [-0.0045],\n",
      "         [-0.0045]],\n",
      "\n",
      "        [[ 0.0902],\n",
      "         [ 0.1922],\n",
      "         [ 0.0559],\n",
      "         ...,\n",
      "         [ 0.1004],\n",
      "         [ 0.1004],\n",
      "         [ 0.1004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1402],\n",
      "         [ 0.1050],\n",
      "         [ 0.0901],\n",
      "         ...,\n",
      "         [ 0.1309],\n",
      "         [ 0.1366],\n",
      "         [ 0.1405]],\n",
      "\n",
      "        [[-0.0203],\n",
      "         [-0.1384],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [-0.0177],\n",
      "         [-0.0177],\n",
      "         [-0.0177]],\n",
      "\n",
      "        [[ 0.0576],\n",
      "         [-0.0152],\n",
      "         [ 0.0831],\n",
      "         ...,\n",
      "         [ 0.0417],\n",
      "         [ 0.0498],\n",
      "         [ 0.0554]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0276],\n",
      "         [ 0.0165],\n",
      "         [-0.0815],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0087],\n",
      "         [ 0.0846],\n",
      "         [ 0.0690],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0902],\n",
      "         [ 0.1922],\n",
      "         [ 0.0559],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1402],\n",
      "         [ 0.1050],\n",
      "         [ 0.0901],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0203],\n",
      "         [-0.1384],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0576],\n",
      "         [-0.0152],\n",
      "         [ 0.0831],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0279],\n",
      "         [ 0.0162],\n",
      "         [-0.0818],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [ 0.0843],\n",
      "         [ 0.0687],\n",
      "         ...,\n",
      "         [-0.0048],\n",
      "         [-0.0048],\n",
      "         [-0.0048]],\n",
      "\n",
      "        [[ 0.1390],\n",
      "         [ 0.2422],\n",
      "         [ 0.1047],\n",
      "         ...,\n",
      "         [ 0.1505],\n",
      "         [ 0.1505],\n",
      "         [ 0.1505]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0583],\n",
      "         [ 0.0213],\n",
      "         [ 0.0068],\n",
      "         ...,\n",
      "         [ 0.0493],\n",
      "         [ 0.0549],\n",
      "         [ 0.0588]],\n",
      "\n",
      "        [[-0.0297],\n",
      "         [-0.1478],\n",
      "         [-0.0693],\n",
      "         ...,\n",
      "         [-0.0279],\n",
      "         [-0.0279],\n",
      "         [-0.0279]],\n",
      "\n",
      "        [[ 0.0728],\n",
      "         [-0.0005],\n",
      "         [ 0.1008],\n",
      "         ...,\n",
      "         [ 0.0546],\n",
      "         [ 0.0628],\n",
      "         [ 0.0684]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0279],\n",
      "         [ 0.0162],\n",
      "         [-0.0818],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [ 0.0843],\n",
      "         [ 0.0687],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1390],\n",
      "         [ 0.2422],\n",
      "         [ 0.1047],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0583],\n",
      "         [ 0.0213],\n",
      "         [ 0.0068],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0297],\n",
      "         [-0.1478],\n",
      "         [-0.0693],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0728],\n",
      "         [-0.0005],\n",
      "         [ 0.1008],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0281],\n",
      "         [ 0.0160],\n",
      "         [-0.0820],\n",
      "         ...,\n",
      "         [-0.0233],\n",
      "         [-0.0233],\n",
      "         [-0.0233]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[ 0.1084],\n",
      "         [ 0.2128],\n",
      "         [ 0.0744],\n",
      "         ...,\n",
      "         [ 0.1177],\n",
      "         [ 0.1177],\n",
      "         [ 0.1177]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0670],\n",
      "         [ 0.0301],\n",
      "         [ 0.0155],\n",
      "         ...,\n",
      "         [ 0.0579],\n",
      "         [ 0.0635],\n",
      "         [ 0.0673]],\n",
      "\n",
      "        [[-0.0348],\n",
      "         [-0.1530],\n",
      "         [-0.0739],\n",
      "         ...,\n",
      "         [-0.0334],\n",
      "         [-0.0334],\n",
      "         [-0.0334]],\n",
      "\n",
      "        [[ 0.0975],\n",
      "         [ 0.0244],\n",
      "         [ 0.1251],\n",
      "         ...,\n",
      "         [ 0.0801],\n",
      "         [ 0.0882],\n",
      "         [ 0.0938]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0281],\n",
      "         [ 0.0160],\n",
      "         [-0.0820],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1084],\n",
      "         [ 0.2128],\n",
      "         [ 0.0744],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0670],\n",
      "         [ 0.0301],\n",
      "         [ 0.0155],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0348],\n",
      "         [-0.1530],\n",
      "         [-0.0739],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0975],\n",
      "         [ 0.0244],\n",
      "         [ 0.1251],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0282],\n",
      "         [ 0.0159],\n",
      "         [-0.0821],\n",
      "         ...,\n",
      "         [-0.0234],\n",
      "         [-0.0234],\n",
      "         [-0.0234]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[ 0.0643],\n",
      "         [ 0.1653],\n",
      "         [ 0.0302],\n",
      "         ...,\n",
      "         [ 0.0736],\n",
      "         [ 0.0736],\n",
      "         [ 0.0737]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1019],\n",
      "         [ 0.0661],\n",
      "         [ 0.0510],\n",
      "         ...,\n",
      "         [ 0.0919],\n",
      "         [ 0.0975],\n",
      "         [ 0.1013]],\n",
      "\n",
      "        [[-0.0375],\n",
      "         [-0.1557],\n",
      "         [-0.0764],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[ 0.1183],\n",
      "         [ 0.0455],\n",
      "         [ 0.1469],\n",
      "         ...,\n",
      "         [ 0.1006],\n",
      "         [ 0.1088],\n",
      "         [ 0.1145]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0282],\n",
      "         [ 0.0159],\n",
      "         [-0.0821],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0643],\n",
      "         [ 0.1653],\n",
      "         [ 0.0302],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1019],\n",
      "         [ 0.0661],\n",
      "         [ 0.0510],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0375],\n",
      "         [-0.1557],\n",
      "         [-0.0764],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1183],\n",
      "         [ 0.0455],\n",
      "         [ 0.1469],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-2.8277e-02],\n",
      "         [ 1.5784e-02],\n",
      "         [-8.2206e-02],\n",
      "         ...,\n",
      "         [-2.3518e-02],\n",
      "         [-2.3518e-02],\n",
      "         [-2.3517e-02]],\n",
      "\n",
      "        [[-9.2496e-03],\n",
      "         [ 8.4105e-02],\n",
      "         [ 6.8509e-02],\n",
      "         ...,\n",
      "         [-5.0372e-03],\n",
      "         [-5.0359e-03],\n",
      "         [-5.0350e-03]],\n",
      "\n",
      "        [[ 7.0197e-02],\n",
      "         [ 1.7179e-01],\n",
      "         [ 3.5894e-02],\n",
      "         ...,\n",
      "         [ 8.0767e-02],\n",
      "         [ 8.0778e-02],\n",
      "         [ 8.0785e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.9976e-02],\n",
      "         [ 5.2659e-02],\n",
      "         [ 3.8414e-02],\n",
      "         ...,\n",
      "         [ 8.1137e-02],\n",
      "         [ 8.6737e-02],\n",
      "         [ 9.0624e-02]],\n",
      "\n",
      "        [[-3.8944e-02],\n",
      "         [-1.5719e-01],\n",
      "         [-7.7708e-02],\n",
      "         ...,\n",
      "         [-3.7905e-02],\n",
      "         [-3.7904e-02],\n",
      "         [-3.7903e-02]],\n",
      "\n",
      "        [[-2.6152e-02],\n",
      "         [-9.6576e-02],\n",
      "         [ 1.5038e-04],\n",
      "         ...,\n",
      "         [-4.5909e-02],\n",
      "         [-3.8229e-02],\n",
      "         [-3.2888e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-2.8277e-02],\n",
      "         [ 1.5784e-02],\n",
      "         [-8.2206e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-9.2496e-03],\n",
      "         [ 8.4105e-02],\n",
      "         [ 6.8509e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 7.0197e-02],\n",
      "         [ 1.7179e-01],\n",
      "         [ 3.5894e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.9976e-02],\n",
      "         [ 5.2659e-02],\n",
      "         [ 3.8414e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-3.8944e-02],\n",
      "         [-1.5719e-01],\n",
      "         [-7.7708e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.6152e-02],\n",
      "         [-9.6576e-02],\n",
      "         [ 1.5038e-04],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-2.8325e-02],\n",
      "         [ 1.5736e-02],\n",
      "         [-8.2253e-02],\n",
      "         ...,\n",
      "         [-2.3566e-02],\n",
      "         [-2.3565e-02],\n",
      "         [-2.3565e-02]],\n",
      "\n",
      "        [[-9.2581e-03],\n",
      "         [ 8.4106e-02],\n",
      "         [ 6.8505e-02],\n",
      "         ...,\n",
      "         [-5.0334e-03],\n",
      "         [-5.0321e-03],\n",
      "         [-5.0312e-03]],\n",
      "\n",
      "        [[ 3.2221e-02],\n",
      "         [ 1.3412e-01],\n",
      "         [-2.8418e-03],\n",
      "         ...,\n",
      "         [ 4.0228e-02],\n",
      "         [ 4.0239e-02],\n",
      "         [ 4.0247e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.5149e-02],\n",
      "         [ 9.5125e-03],\n",
      "         [-5.9766e-03],\n",
      "         ...,\n",
      "         [ 3.4717e-02],\n",
      "         [ 4.0227e-02],\n",
      "         [ 4.4053e-02]],\n",
      "\n",
      "        [[-3.9702e-02],\n",
      "         [-1.5797e-01],\n",
      "         [-7.8427e-02],\n",
      "         ...,\n",
      "         [-3.8719e-02],\n",
      "         [-3.8718e-02],\n",
      "         [-3.8717e-02]],\n",
      "\n",
      "        [[ 1.7191e-02],\n",
      "         [-5.3884e-02],\n",
      "         [ 4.2719e-02],\n",
      "         ...,\n",
      "         [-1.3045e-04],\n",
      "         [ 7.6387e-03],\n",
      "         [ 1.3038e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0283],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0093],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0322],\n",
      "         [ 0.1341],\n",
      "         [-0.0028],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0451],\n",
      "         [ 0.0095],\n",
      "         [-0.0060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0397],\n",
      "         [-0.1580],\n",
      "         [-0.0784],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0172],\n",
      "         [-0.0539],\n",
      "         [ 0.0427],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0236],\n",
      "         [-0.0236],\n",
      "         [-0.0236]],\n",
      "\n",
      "        [[-0.0093],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[ 0.0101],\n",
      "         [ 0.1126],\n",
      "         [-0.0252],\n",
      "         ...,\n",
      "         [ 0.0161],\n",
      "         [ 0.0161],\n",
      "         [ 0.0161]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0205],\n",
      "         [-0.0136],\n",
      "         [-0.0300],\n",
      "         ...,\n",
      "         [ 0.0086],\n",
      "         [ 0.0140],\n",
      "         [ 0.0178]],\n",
      "\n",
      "        [[-0.0401],\n",
      "         [-0.1584],\n",
      "         [-0.0788],\n",
      "         ...,\n",
      "         [-0.0391],\n",
      "         [-0.0391],\n",
      "         [-0.0391]],\n",
      "\n",
      "        [[ 0.1704],\n",
      "         [ 0.0986],\n",
      "         [ 0.1976],\n",
      "         ...,\n",
      "         [ 0.1564],\n",
      "         [ 0.1645],\n",
      "         [ 0.1702]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0093],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0101],\n",
      "         [ 0.1126],\n",
      "         [-0.0252],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0205],\n",
      "         [-0.0136],\n",
      "         [-0.0300],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0401],\n",
      "         [-0.1584],\n",
      "         [-0.0788],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1704],\n",
      "         [ 0.0986],\n",
      "         [ 0.1976],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0236],\n",
      "         [-0.0236],\n",
      "         [-0.0236]],\n",
      "\n",
      "        [[-0.0093],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[-0.0025],\n",
      "         [ 0.1005],\n",
      "         [-0.0380],\n",
      "         ...,\n",
      "         [ 0.0021],\n",
      "         [ 0.0021],\n",
      "         [ 0.0022]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0069],\n",
      "         [-0.0262],\n",
      "         [-0.0431],\n",
      "         ...,\n",
      "         [-0.0060],\n",
      "         [-0.0006],\n",
      "         [ 0.0032]],\n",
      "\n",
      "        [[-0.0403],\n",
      "         [-0.1586],\n",
      "         [-0.0790],\n",
      "         ...,\n",
      "         [-0.0393],\n",
      "         [-0.0393],\n",
      "         [-0.0393]],\n",
      "\n",
      "        [[ 0.1888],\n",
      "         [ 0.1159],\n",
      "         [ 0.2150],\n",
      "         ...,\n",
      "         [ 0.1758],\n",
      "         [ 0.1839],\n",
      "         [ 0.1895]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0093],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0025],\n",
      "         [ 0.1005],\n",
      "         [-0.0380],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0069],\n",
      "         [-0.0262],\n",
      "         [-0.0431],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0403],\n",
      "         [-0.1586],\n",
      "         [-0.0790],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1888],\n",
      "         [ 0.1159],\n",
      "         [ 0.2150],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0236],\n",
      "         [-0.0236],\n",
      "         [-0.0236]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[-0.0097],\n",
      "         [ 0.0936],\n",
      "         [-0.0453],\n",
      "         ...,\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0058]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0007],\n",
      "         [-0.0331],\n",
      "         [-0.0504],\n",
      "         ...,\n",
      "         [-0.0140],\n",
      "         [-0.0087],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0404],\n",
      "         [-0.1587],\n",
      "         [-0.0791],\n",
      "         ...,\n",
      "         [-0.0394],\n",
      "         [-0.0394],\n",
      "         [-0.0394]],\n",
      "\n",
      "        [[ 0.0919],\n",
      "         [ 0.0187],\n",
      "         [ 0.1175],\n",
      "         ...,\n",
      "         [ 0.0775],\n",
      "         [ 0.0856],\n",
      "         [ 0.0913]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0097],\n",
      "         [ 0.0936],\n",
      "         [-0.0453],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0007],\n",
      "         [-0.0331],\n",
      "         [-0.0504],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0404],\n",
      "         [-0.1587],\n",
      "         [-0.0791],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0919],\n",
      "         [ 0.0187],\n",
      "         [ 0.1175],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0236],\n",
      "         [-0.0236],\n",
      "         [-0.0236]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[-0.0138],\n",
      "         [ 0.0898],\n",
      "         [-0.0494],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0049],\n",
      "         [-0.0370],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0185],\n",
      "         [-0.0132],\n",
      "         [-0.0095]],\n",
      "\n",
      "        [[-0.0404],\n",
      "         [-0.1587],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[ 0.1172],\n",
      "         [ 0.0443],\n",
      "         [ 0.1443],\n",
      "         ...,\n",
      "         [ 0.1014],\n",
      "         [ 0.1096],\n",
      "         [ 0.1153]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0841],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0138],\n",
      "         [ 0.0898],\n",
      "         [-0.0494],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0049],\n",
      "         [-0.0370],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0404],\n",
      "         [-0.1587],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1172],\n",
      "         [ 0.0443],\n",
      "         [ 0.1443],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0236],\n",
      "         [-0.0236],\n",
      "         [-0.0236]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[-0.0160],\n",
      "         [ 0.0876],\n",
      "         [-0.0517],\n",
      "         ...,\n",
      "         [-0.0127],\n",
      "         [-0.0127],\n",
      "         [-0.0127]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0072],\n",
      "         [-0.0392],\n",
      "         [-0.0568],\n",
      "         ...,\n",
      "         [-0.0210],\n",
      "         [-0.0157],\n",
      "         [-0.0119]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[ 0.1952],\n",
      "         [ 0.1210],\n",
      "         [ 0.2225],\n",
      "         ...,\n",
      "         [ 0.1819],\n",
      "         [ 0.1902],\n",
      "         [ 0.1960]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0160],\n",
      "         [ 0.0876],\n",
      "         [-0.0517],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0072],\n",
      "         [-0.0392],\n",
      "         [-0.0568],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1952],\n",
      "         [ 0.1210],\n",
      "         [ 0.2225],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0236]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0864],\n",
      "         [-0.0530],\n",
      "         ...,\n",
      "         [-0.0140],\n",
      "         [-0.0140],\n",
      "         [-0.0140]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0085],\n",
      "         [-0.0404],\n",
      "         [-0.0580],\n",
      "         ...,\n",
      "         [-0.0224],\n",
      "         [-0.0170],\n",
      "         [-0.0133]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[ 0.2388],\n",
      "         [ 0.1651],\n",
      "         [ 0.2648],\n",
      "         ...,\n",
      "         [ 0.2269],\n",
      "         [ 0.2352],\n",
      "         [ 0.2410]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0157],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0864],\n",
      "         [-0.0530],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0085],\n",
      "         [-0.0404],\n",
      "         [-0.0580],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.2388],\n",
      "         [ 0.1651],\n",
      "         [ 0.2648],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [ 0.0858],\n",
      "         [-0.0537],\n",
      "         ...,\n",
      "         [-0.0148],\n",
      "         [-0.0148],\n",
      "         [-0.0148]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0092],\n",
      "         [-0.0411],\n",
      "         [-0.0587],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0178],\n",
      "         [-0.0141]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[ 0.1521],\n",
      "         [ 0.0792],\n",
      "         [ 0.1785],\n",
      "         ...,\n",
      "         [ 0.1387],\n",
      "         [ 0.1470],\n",
      "         [ 0.1527]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0180],\n",
      "         [ 0.0858],\n",
      "         [-0.0537],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0092],\n",
      "         [-0.0411],\n",
      "         [-0.0587],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1521],\n",
      "         [ 0.0792],\n",
      "         [ 0.1785],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[-0.0183],\n",
      "         [ 0.0854],\n",
      "         [-0.0541],\n",
      "         ...,\n",
      "         [-0.0152],\n",
      "         [-0.0152],\n",
      "         [-0.0152]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0096],\n",
      "         [-0.0414],\n",
      "         [-0.0591],\n",
      "         ...,\n",
      "         [-0.0235],\n",
      "         [-0.0182],\n",
      "         [-0.0145]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[ 0.0770],\n",
      "         [ 0.0042],\n",
      "         [ 0.1028],\n",
      "         ...,\n",
      "         [ 0.0617],\n",
      "         [ 0.0699],\n",
      "         [ 0.0755]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0183],\n",
      "         [ 0.0854],\n",
      "         [-0.0541],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0096],\n",
      "         [-0.0414],\n",
      "         [-0.0591],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0770],\n",
      "         [ 0.0042],\n",
      "         [ 0.1028],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        [[-0.0185],\n",
      "         [ 0.0853],\n",
      "         [-0.0543],\n",
      "         ...,\n",
      "         [-0.0154],\n",
      "         [-0.0154],\n",
      "         [-0.0154]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0098],\n",
      "         [-0.0417],\n",
      "         [-0.0593],\n",
      "         ...,\n",
      "         [-0.0238],\n",
      "         [-0.0184],\n",
      "         [-0.0147]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[ 0.0348],\n",
      "         [-0.0375],\n",
      "         [ 0.0610],\n",
      "         ...,\n",
      "         [ 0.0174],\n",
      "         [ 0.0254],\n",
      "         [ 0.0310]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0185],\n",
      "         [ 0.0853],\n",
      "         [-0.0543],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0098],\n",
      "         [-0.0417],\n",
      "         [-0.0593],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0348],\n",
      "         [-0.0375],\n",
      "         [ 0.0610],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0186],\n",
      "         [ 0.0852],\n",
      "         [-0.0544],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0099],\n",
      "         [-0.0418],\n",
      "         [-0.0594],\n",
      "         ...,\n",
      "         [-0.0239],\n",
      "         [-0.0185],\n",
      "         [-0.0148]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[ 0.0115],\n",
      "         [-0.0605],\n",
      "         [ 0.0380],\n",
      "         ...,\n",
      "         [-0.0075],\n",
      "         [ 0.0004],\n",
      "         [ 0.0059]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0186],\n",
      "         [ 0.0852],\n",
      "         [-0.0544],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0099],\n",
      "         [-0.0418],\n",
      "         [-0.0594],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0115],\n",
      "         [-0.0605],\n",
      "         [ 0.0380],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0187],\n",
      "         [ 0.0851],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0155],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0100],\n",
      "         [-0.0419],\n",
      "         [-0.0595],\n",
      "         ...,\n",
      "         [-0.0240],\n",
      "         [-0.0186],\n",
      "         [-0.0149]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[-0.0016],\n",
      "         [-0.0735],\n",
      "         [ 0.0252],\n",
      "         ...,\n",
      "         [-0.0214],\n",
      "         [-0.0136],\n",
      "         [-0.0082]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0187],\n",
      "         [ 0.0851],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0100],\n",
      "         [-0.0419],\n",
      "         [-0.0595],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0016],\n",
      "         [-0.0735],\n",
      "         [ 0.0252],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0187],\n",
      "         [ 0.0851],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0156],\n",
      "         [-0.0155],\n",
      "         [-0.0155]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0100],\n",
      "         [-0.0419],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [-0.0240],\n",
      "         [-0.0187],\n",
      "         [-0.0149]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[-0.0089],\n",
      "         [-0.0807],\n",
      "         [ 0.0181],\n",
      "         ...,\n",
      "         [-0.0293],\n",
      "         [-0.0215],\n",
      "         [-0.0161]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0187],\n",
      "         [ 0.0851],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0100],\n",
      "         [-0.0419],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0089],\n",
      "         [-0.0807],\n",
      "         [ 0.0181],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0851],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0156],\n",
      "         [-0.0156],\n",
      "         [-0.0156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0419],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [-0.0240],\n",
      "         [-0.0187],\n",
      "         [-0.0150]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[-0.0130],\n",
      "         [-0.0849],\n",
      "         [ 0.0140],\n",
      "         ...,\n",
      "         [-0.0338],\n",
      "         [-0.0260],\n",
      "         [-0.0206]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0851],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0419],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0130],\n",
      "         [-0.0849],\n",
      "         [ 0.0140],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0156],\n",
      "         [-0.0156],\n",
      "         [-0.0156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0419],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [-0.0240],\n",
      "         [-0.0187],\n",
      "         [-0.0150]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[-0.0154],\n",
      "         [-0.0872],\n",
      "         [ 0.0117],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0285],\n",
      "         [-0.0231]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0419],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0154],\n",
      "         [-0.0872],\n",
      "         [ 0.0117],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0156],\n",
      "         [-0.0156],\n",
      "         [-0.0156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0420],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [-0.0240],\n",
      "         [-0.0187],\n",
      "         [-0.0150]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[-0.0167],\n",
      "         [-0.0885],\n",
      "         [ 0.0104],\n",
      "         ...,\n",
      "         [-0.0377],\n",
      "         [-0.0300],\n",
      "         [-0.0246]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0420],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0167],\n",
      "         [-0.0885],\n",
      "         [ 0.0104],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0156],\n",
      "         [-0.0156],\n",
      "         [-0.0156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0420],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [-0.0240],\n",
      "         [-0.0187],\n",
      "         [-0.0150]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[-0.0175],\n",
      "         [-0.0893],\n",
      "         [ 0.0097],\n",
      "         ...,\n",
      "         [-0.0385],\n",
      "         [-0.0308],\n",
      "         [-0.0254]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0420],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0175],\n",
      "         [-0.0893],\n",
      "         [ 0.0097],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0156],\n",
      "         [-0.0156],\n",
      "         [-0.0156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0420],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [-0.0240],\n",
      "         [-0.0187],\n",
      "         [-0.0150]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[-0.0179],\n",
      "         [-0.0897],\n",
      "         [ 0.0092],\n",
      "         ...,\n",
      "         [-0.0390],\n",
      "         [-0.0313],\n",
      "         [-0.0259]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0420],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0179],\n",
      "         [-0.0897],\n",
      "         [ 0.0092],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [-0.0237],\n",
      "         [-0.0237],\n",
      "         [-0.0237]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [-0.0049],\n",
      "         [-0.0049],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [-0.0156],\n",
      "         [-0.0156],\n",
      "         [-0.0156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0420],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [-0.0240],\n",
      "         [-0.0187],\n",
      "         [-0.0150]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [-0.0395],\n",
      "         [-0.0395],\n",
      "         [-0.0395]],\n",
      "\n",
      "        [[-0.0182],\n",
      "         [-0.0900],\n",
      "         [ 0.0090],\n",
      "         ...,\n",
      "         [-0.0393],\n",
      "         [-0.0316],\n",
      "         [-0.0262]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0284],\n",
      "         [ 0.0156],\n",
      "         [-0.0823],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [ 0.0842],\n",
      "         [ 0.0686],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [ 0.0850],\n",
      "         [-0.0545],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0420],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1588],\n",
      "         [-0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0182],\n",
      "         [-0.0900],\n",
      "         [ 0.0090],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/25000 [00:02<3:31:35,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот в AttentiveModel сделали mask. Она выглядит так:\n",
      "torch.BoolTensor\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1997],\n",
      "         [0.1707],\n",
      "         [0.1902],\n",
      "         ...,\n",
      "         [0.2061],\n",
      "         [0.2061],\n",
      "         [0.2061]],\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.0831],\n",
      "         [0.1753],\n",
      "         ...,\n",
      "         [0.2060],\n",
      "         [0.2060],\n",
      "         [0.2061]],\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.2592],\n",
      "         [0.2840],\n",
      "         ...,\n",
      "         [0.2061],\n",
      "         [0.2061],\n",
      "         [0.2061]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.2069],\n",
      "         [0.1823],\n",
      "         ...,\n",
      "         [0.2061],\n",
      "         [0.2061],\n",
      "         [0.2061]],\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.1606],\n",
      "         [0.2060],\n",
      "         ...,\n",
      "         [0.2061],\n",
      "         [0.2061],\n",
      "         [0.2061]],\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.2053],\n",
      "         [0.1411],\n",
      "         ...,\n",
      "         [0.2061],\n",
      "         [0.2061],\n",
      "         [0.2061]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1997],\n",
      "         [0.1707],\n",
      "         [0.1902],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.0831],\n",
      "         [0.1753],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.2592],\n",
      "         [0.2840],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.2069],\n",
      "         [0.1823],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.1606],\n",
      "         [0.2060],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1997],\n",
      "         [0.2053],\n",
      "         [0.1411],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1403],\n",
      "         [0.1111],\n",
      "         [0.1310],\n",
      "         ...,\n",
      "         [0.1477],\n",
      "         [0.1477],\n",
      "         [0.1477]],\n",
      "\n",
      "        [[0.1340],\n",
      "         [0.0158],\n",
      "         [0.1109],\n",
      "         ...,\n",
      "         [0.1413],\n",
      "         [0.1413],\n",
      "         [0.1413]],\n",
      "\n",
      "        [[0.1428],\n",
      "         [0.2014],\n",
      "         [0.2259],\n",
      "         ...,\n",
      "         [0.1504],\n",
      "         [0.1504],\n",
      "         [0.1504]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1286],\n",
      "         [0.1354],\n",
      "         [0.1098],\n",
      "         ...,\n",
      "         [0.1360],\n",
      "         [0.1360],\n",
      "         [0.1360]],\n",
      "\n",
      "        [[0.1259],\n",
      "         [0.0861],\n",
      "         [0.1312],\n",
      "         ...,\n",
      "         [0.1329],\n",
      "         [0.1329],\n",
      "         [0.1329]],\n",
      "\n",
      "        [[0.1405],\n",
      "         [0.1448],\n",
      "         [0.0819],\n",
      "         ...,\n",
      "         [0.1480],\n",
      "         [0.1480],\n",
      "         [0.1480]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1403],\n",
      "         [0.1111],\n",
      "         [0.1310],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1340],\n",
      "         [0.0158],\n",
      "         [0.1109],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1428],\n",
      "         [0.2014],\n",
      "         [0.2259],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1286],\n",
      "         [0.1354],\n",
      "         [0.1098],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1259],\n",
      "         [0.0861],\n",
      "         [0.1312],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1405],\n",
      "         [0.1448],\n",
      "         [0.0819],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1149],\n",
      "         [ 0.0841],\n",
      "         [ 0.1035],\n",
      "         ...,\n",
      "         [ 0.1238],\n",
      "         [ 0.1238],\n",
      "         [ 0.1238]],\n",
      "\n",
      "        [[ 0.0430],\n",
      "         [-0.0729],\n",
      "         [ 0.0272],\n",
      "         ...,\n",
      "         [ 0.0474],\n",
      "         [ 0.0474],\n",
      "         [ 0.0474]],\n",
      "\n",
      "        [[ 0.1683],\n",
      "         [ 0.2276],\n",
      "         [ 0.2519],\n",
      "         ...,\n",
      "         [ 0.1772],\n",
      "         [ 0.1772],\n",
      "         [ 0.1772]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0513],\n",
      "         [ 0.0597],\n",
      "         [ 0.0333],\n",
      "         ...,\n",
      "         [ 0.0567],\n",
      "         [ 0.0567],\n",
      "         [ 0.0567]],\n",
      "\n",
      "        [[ 0.1388],\n",
      "         [ 0.0998],\n",
      "         [ 0.1449],\n",
      "         ...,\n",
      "         [ 0.1468],\n",
      "         [ 0.1468],\n",
      "         [ 0.1468]],\n",
      "\n",
      "        [[ 0.0260],\n",
      "         [ 0.0300],\n",
      "         [-0.0275],\n",
      "         ...,\n",
      "         [ 0.0308],\n",
      "         [ 0.0308],\n",
      "         [ 0.0308]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1149],\n",
      "         [ 0.0841],\n",
      "         [ 0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0430],\n",
      "         [-0.0729],\n",
      "         [ 0.0272],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1683],\n",
      "         [ 0.2276],\n",
      "         [ 0.2519],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0513],\n",
      "         [ 0.0597],\n",
      "         [ 0.0333],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1388],\n",
      "         [ 0.0998],\n",
      "         [ 0.1449],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0260],\n",
      "         [ 0.0300],\n",
      "         [-0.0275],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 2.9376e-02],\n",
      "         [-4.5076e-06],\n",
      "         [ 1.9783e-02],\n",
      "         ...,\n",
      "         [ 3.7745e-02],\n",
      "         [ 3.7747e-02],\n",
      "         [ 3.7748e-02]],\n",
      "\n",
      "        [[-3.2207e-02],\n",
      "         [-1.4542e-01],\n",
      "         [-4.7839e-02],\n",
      "         ...,\n",
      "         [-2.8276e-02],\n",
      "         [-2.8269e-02],\n",
      "         [-2.8264e-02]],\n",
      "\n",
      "        [[ 1.5312e-01],\n",
      "         [ 2.1152e-01],\n",
      "         [ 2.3588e-01],\n",
      "         ...,\n",
      "         [ 1.6205e-01],\n",
      "         [ 1.6205e-01],\n",
      "         [ 1.6205e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6819e-03],\n",
      "         [ 1.4557e-03],\n",
      "         [-2.5354e-02],\n",
      "         ...,\n",
      "         [-1.7753e-03],\n",
      "         [-1.7753e-03],\n",
      "         [-1.7753e-03]],\n",
      "\n",
      "        [[ 1.9596e-02],\n",
      "         [-1.8517e-02],\n",
      "         [ 2.4168e-02],\n",
      "         ...,\n",
      "         [ 2.4063e-02],\n",
      "         [ 2.4063e-02],\n",
      "         [ 2.4063e-02]],\n",
      "\n",
      "        [[ 9.6947e-03],\n",
      "         [ 1.6049e-02],\n",
      "         [-3.8013e-02],\n",
      "         ...,\n",
      "         [ 1.1397e-02],\n",
      "         [ 1.1400e-02],\n",
      "         [ 1.1402e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 2.9376e-02],\n",
      "         [-4.5076e-06],\n",
      "         [ 1.9783e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-3.2207e-02],\n",
      "         [-1.4542e-01],\n",
      "         [-4.7839e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 1.5312e-01],\n",
      "         [ 2.1152e-01],\n",
      "         [ 2.3588e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6819e-03],\n",
      "         [ 1.4557e-03],\n",
      "         [-2.5354e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 1.9596e-02],\n",
      "         [-1.8517e-02],\n",
      "         [ 2.4168e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 9.6947e-03],\n",
      "         [ 1.6049e-02],\n",
      "         [-3.8013e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0124],\n",
      "         [-0.0393],\n",
      "         [-0.0183],\n",
      "         ...,\n",
      "         [-0.0061],\n",
      "         [-0.0061],\n",
      "         [-0.0061]],\n",
      "\n",
      "        [[ 0.0204],\n",
      "         [-0.0963],\n",
      "         [ 0.0080],\n",
      "         ...,\n",
      "         [ 0.0209],\n",
      "         [ 0.0209],\n",
      "         [ 0.0209]],\n",
      "\n",
      "        [[ 0.1377],\n",
      "         [ 0.1959],\n",
      "         [ 0.2199],\n",
      "         ...,\n",
      "         [ 0.1464],\n",
      "         [ 0.1464],\n",
      "         [ 0.1464]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0191],\n",
      "         [-0.0116],\n",
      "         [-0.0379],\n",
      "         ...,\n",
      "         [-0.0137],\n",
      "         [-0.0137],\n",
      "         [-0.0137]],\n",
      "\n",
      "        [[ 0.0980],\n",
      "         [ 0.0605],\n",
      "         [ 0.1050],\n",
      "         ...,\n",
      "         [ 0.1021],\n",
      "         [ 0.1021],\n",
      "         [ 0.1021]],\n",
      "\n",
      "        [[-0.0580],\n",
      "         [-0.0519],\n",
      "         [-0.1037],\n",
      "         ...,\n",
      "         [-0.0570],\n",
      "         [-0.0570],\n",
      "         [-0.0570]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0124],\n",
      "         [-0.0393],\n",
      "         [-0.0183],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0204],\n",
      "         [-0.0963],\n",
      "         [ 0.0080],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1377],\n",
      "         [ 0.1959],\n",
      "         [ 0.2199],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0191],\n",
      "         [-0.0116],\n",
      "         [-0.0379],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0980],\n",
      "         [ 0.0605],\n",
      "         [ 0.1050],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0580],\n",
      "         [-0.0519],\n",
      "         [-0.1037],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0225],\n",
      "         [-0.0046],\n",
      "         [ 0.0165],\n",
      "         ...,\n",
      "         [ 0.0303],\n",
      "         [ 0.0303],\n",
      "         [ 0.0303]],\n",
      "\n",
      "        [[ 0.0648],\n",
      "         [-0.0513],\n",
      "         [ 0.0428],\n",
      "         ...,\n",
      "         [ 0.0725],\n",
      "         [ 0.0725],\n",
      "         [ 0.0725]],\n",
      "\n",
      "        [[ 0.0335],\n",
      "         [ 0.0902],\n",
      "         [ 0.1143],\n",
      "         ...,\n",
      "         [ 0.0400],\n",
      "         [ 0.0400],\n",
      "         [ 0.0400]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0326],\n",
      "         [ 0.0450],\n",
      "         [ 0.0165],\n",
      "         ...,\n",
      "         [ 0.0345],\n",
      "         [ 0.0345],\n",
      "         [ 0.0345]],\n",
      "\n",
      "        [[ 0.0672],\n",
      "         [ 0.0298],\n",
      "         [ 0.0732],\n",
      "         ...,\n",
      "         [ 0.0701],\n",
      "         [ 0.0701],\n",
      "         [ 0.0701]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [-0.0073],\n",
      "         [-0.0673],\n",
      "         ...,\n",
      "         [-0.0006],\n",
      "         [-0.0006],\n",
      "         [-0.0006]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0225],\n",
      "         [-0.0046],\n",
      "         [ 0.0165],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0648],\n",
      "         [-0.0513],\n",
      "         [ 0.0428],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0335],\n",
      "         [ 0.0902],\n",
      "         [ 0.1143],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0326],\n",
      "         [ 0.0450],\n",
      "         [ 0.0165],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0672],\n",
      "         [ 0.0298],\n",
      "         [ 0.0732],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0092],\n",
      "         [-0.0073],\n",
      "         [-0.0673],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0022],\n",
      "         [-0.0331],\n",
      "         [-0.0137],\n",
      "         ...,\n",
      "         [ 0.0087],\n",
      "         [ 0.0087],\n",
      "         [ 0.0087]],\n",
      "\n",
      "        [[ 0.0440],\n",
      "         [-0.0719],\n",
      "         [ 0.0240],\n",
      "         ...,\n",
      "         [ 0.0502],\n",
      "         [ 0.0502],\n",
      "         [ 0.0502]],\n",
      "\n",
      "        [[-0.0814],\n",
      "         [-0.0291],\n",
      "         [-0.0062],\n",
      "         ...,\n",
      "         [-0.0780],\n",
      "         [-0.0780],\n",
      "         [-0.0780]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0117],\n",
      "         [-0.0389],\n",
      "         ...,\n",
      "         [-0.0172],\n",
      "         [-0.0172],\n",
      "         [-0.0172]],\n",
      "\n",
      "        [[ 0.0077],\n",
      "         [-0.0298],\n",
      "         [ 0.0128],\n",
      "         ...,\n",
      "         [ 0.0079],\n",
      "         [ 0.0079],\n",
      "         [ 0.0079]],\n",
      "\n",
      "        [[ 0.0838],\n",
      "         [ 0.0893],\n",
      "         [ 0.0300],\n",
      "         ...,\n",
      "         [ 0.0900],\n",
      "         [ 0.0900],\n",
      "         [ 0.0900]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0022],\n",
      "         [-0.0331],\n",
      "         [-0.0137],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0440],\n",
      "         [-0.0719],\n",
      "         [ 0.0240],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0814],\n",
      "         [-0.0291],\n",
      "         [-0.0062],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0216],\n",
      "         [-0.0117],\n",
      "         [-0.0389],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0077],\n",
      "         [-0.0298],\n",
      "         [ 0.0128],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0838],\n",
      "         [ 0.0893],\n",
      "         [ 0.0300],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0028],\n",
      "         [-0.0261],\n",
      "         [-0.0060],\n",
      "         ...,\n",
      "         [ 0.0107],\n",
      "         [ 0.0107],\n",
      "         [ 0.0107]],\n",
      "\n",
      "        [[ 0.1308],\n",
      "         [ 0.0117],\n",
      "         [ 0.1087],\n",
      "         ...,\n",
      "         [ 0.1388],\n",
      "         [ 0.1388],\n",
      "         [ 0.1388]],\n",
      "\n",
      "        [[ 0.0014],\n",
      "         [ 0.0563],\n",
      "         [ 0.0799],\n",
      "         ...,\n",
      "         [ 0.0030],\n",
      "         [ 0.0030],\n",
      "         [ 0.0030]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0703],\n",
      "         [ 0.0797],\n",
      "         [ 0.0540],\n",
      "         ...,\n",
      "         [ 0.0764],\n",
      "         [ 0.0764],\n",
      "         [ 0.0764]],\n",
      "\n",
      "        [[-0.0184],\n",
      "         [-0.0548],\n",
      "         [-0.0120],\n",
      "         ...,\n",
      "         [-0.0199],\n",
      "         [-0.0199],\n",
      "         [-0.0199]],\n",
      "\n",
      "        [[-0.0516],\n",
      "         [-0.0470],\n",
      "         [-0.1007],\n",
      "         ...,\n",
      "         [-0.0491],\n",
      "         [-0.0491],\n",
      "         [-0.0491]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0028],\n",
      "         [-0.0261],\n",
      "         [-0.0060],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1308],\n",
      "         [ 0.0117],\n",
      "         [ 0.1087],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0014],\n",
      "         [ 0.0563],\n",
      "         [ 0.0799],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0703],\n",
      "         [ 0.0797],\n",
      "         [ 0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0184],\n",
      "         [-0.0548],\n",
      "         [-0.0120],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0516],\n",
      "         [-0.0470],\n",
      "         [-0.1007],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0077],\n",
      "         [-0.0193],\n",
      "         [ 0.0013],\n",
      "         ...,\n",
      "         [ 0.0137],\n",
      "         [ 0.0137],\n",
      "         [ 0.0137]],\n",
      "\n",
      "        [[ 0.1136],\n",
      "         [-0.0057],\n",
      "         [ 0.0916],\n",
      "         ...,\n",
      "         [ 0.1214],\n",
      "         [ 0.1214],\n",
      "         [ 0.1214]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [ 0.0291],\n",
      "         [ 0.0527],\n",
      "         ...,\n",
      "         [-0.0202],\n",
      "         [-0.0202],\n",
      "         [-0.0202]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0461],\n",
      "         [ 0.0575],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [ 0.0520],\n",
      "         [ 0.0520],\n",
      "         [ 0.0520]],\n",
      "\n",
      "        [[-0.0689],\n",
      "         [-0.1057],\n",
      "         [-0.0642],\n",
      "         ...,\n",
      "         [-0.0694],\n",
      "         [-0.0694],\n",
      "         [-0.0694]],\n",
      "\n",
      "        [[-0.0192],\n",
      "         [-0.0118],\n",
      "         [-0.0634],\n",
      "         ...,\n",
      "         [-0.0200],\n",
      "         [-0.0200],\n",
      "         [-0.0200]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0077],\n",
      "         [-0.0193],\n",
      "         [ 0.0013],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1136],\n",
      "         [-0.0057],\n",
      "         [ 0.0916],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0251],\n",
      "         [ 0.0291],\n",
      "         [ 0.0527],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0461],\n",
      "         [ 0.0575],\n",
      "         [ 0.0303],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0689],\n",
      "         [-0.1057],\n",
      "         [-0.0642],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0192],\n",
      "         [-0.0118],\n",
      "         [-0.0634],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0872],\n",
      "         [ 0.0627],\n",
      "         [ 0.0840],\n",
      "         ...,\n",
      "         [ 0.0922],\n",
      "         [ 0.0922],\n",
      "         [ 0.0922]],\n",
      "\n",
      "        [[ 0.0078],\n",
      "         [-0.1084],\n",
      "         [-0.0091],\n",
      "         ...,\n",
      "         [ 0.0119],\n",
      "         [ 0.0119],\n",
      "         [ 0.0119]],\n",
      "\n",
      "        [[ 0.0580],\n",
      "         [ 0.1158],\n",
      "         [ 0.1408],\n",
      "         ...,\n",
      "         [ 0.0662],\n",
      "         [ 0.0662],\n",
      "         [ 0.0662]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0387],\n",
      "         [ 0.0512],\n",
      "         [ 0.0234],\n",
      "         ...,\n",
      "         [ 0.0418],\n",
      "         [ 0.0418],\n",
      "         [ 0.0418]],\n",
      "\n",
      "        [[ 0.0125],\n",
      "         [-0.0253],\n",
      "         [ 0.0177],\n",
      "         ...,\n",
      "         [ 0.0182],\n",
      "         [ 0.0182],\n",
      "         [ 0.0182]],\n",
      "\n",
      "        [[ 0.0520],\n",
      "         [ 0.0543],\n",
      "         [-0.0064],\n",
      "         ...,\n",
      "         [ 0.0600],\n",
      "         [ 0.0600],\n",
      "         [ 0.0600]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0872],\n",
      "         [ 0.0627],\n",
      "         [ 0.0840],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0078],\n",
      "         [-0.1084],\n",
      "         [-0.0091],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0580],\n",
      "         [ 0.1158],\n",
      "         [ 0.1408],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0387],\n",
      "         [ 0.0512],\n",
      "         [ 0.0234],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0125],\n",
      "         [-0.0253],\n",
      "         [ 0.0177],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0520],\n",
      "         [ 0.0543],\n",
      "         [-0.0064],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0122],\n",
      "         [-0.0152],\n",
      "         [ 0.0055],\n",
      "         ...,\n",
      "         [ 0.0182],\n",
      "         [ 0.0182],\n",
      "         [ 0.0182]],\n",
      "\n",
      "        [[ 0.0354],\n",
      "         [-0.0813],\n",
      "         [ 0.0179],\n",
      "         ...,\n",
      "         [ 0.0397],\n",
      "         [ 0.0397],\n",
      "         [ 0.0397]],\n",
      "\n",
      "        [[ 0.0197],\n",
      "         [ 0.0757],\n",
      "         [ 0.1000],\n",
      "         ...,\n",
      "         [ 0.0265],\n",
      "         [ 0.0265],\n",
      "         [ 0.0265]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0745],\n",
      "         [-0.0608],\n",
      "         [-0.0896],\n",
      "         ...,\n",
      "         [-0.0738],\n",
      "         [-0.0738],\n",
      "         [-0.0738]],\n",
      "\n",
      "        [[ 0.0569],\n",
      "         [ 0.0194],\n",
      "         [ 0.0625],\n",
      "         ...,\n",
      "         [ 0.0650],\n",
      "         [ 0.0650],\n",
      "         [ 0.0650]],\n",
      "\n",
      "        [[ 0.0168],\n",
      "         [ 0.0202],\n",
      "         [-0.0378],\n",
      "         ...,\n",
      "         [ 0.0227],\n",
      "         [ 0.0227],\n",
      "         [ 0.0227]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0122],\n",
      "         [-0.0152],\n",
      "         [ 0.0055],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0354],\n",
      "         [-0.0813],\n",
      "         [ 0.0179],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0197],\n",
      "         [ 0.0757],\n",
      "         [ 0.1000],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0745],\n",
      "         [-0.0608],\n",
      "         [-0.0896],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0569],\n",
      "         [ 0.0194],\n",
      "         [ 0.0625],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0168],\n",
      "         [ 0.0202],\n",
      "         [-0.0378],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0647],\n",
      "         [ 0.0366],\n",
      "         [ 0.0571],\n",
      "         ...,\n",
      "         [ 0.0727],\n",
      "         [ 0.0727],\n",
      "         [ 0.0727]],\n",
      "\n",
      "        [[ 0.0871],\n",
      "         [-0.0315],\n",
      "         [ 0.0704],\n",
      "         ...,\n",
      "         [ 0.0914],\n",
      "         [ 0.0914],\n",
      "         [ 0.0914]],\n",
      "\n",
      "        [[ 0.0089],\n",
      "         [ 0.0656],\n",
      "         [ 0.0903],\n",
      "         ...,\n",
      "         [ 0.0145],\n",
      "         [ 0.0145],\n",
      "         [ 0.0145]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0130],\n",
      "         [-0.0021],\n",
      "         [-0.0295],\n",
      "         ...,\n",
      "         [-0.0088],\n",
      "         [-0.0088],\n",
      "         [-0.0088]],\n",
      "\n",
      "        [[ 0.0641],\n",
      "         [ 0.0259],\n",
      "         [ 0.0699],\n",
      "         ...,\n",
      "         [ 0.0723],\n",
      "         [ 0.0723],\n",
      "         [ 0.0723]],\n",
      "\n",
      "        [[ 0.0055],\n",
      "         [ 0.0116],\n",
      "         [-0.0438],\n",
      "         ...,\n",
      "         [ 0.0101],\n",
      "         [ 0.0101],\n",
      "         [ 0.0101]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0647],\n",
      "         [ 0.0366],\n",
      "         [ 0.0571],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0871],\n",
      "         [-0.0315],\n",
      "         [ 0.0704],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0089],\n",
      "         [ 0.0656],\n",
      "         [ 0.0903],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0130],\n",
      "         [-0.0021],\n",
      "         [-0.0295],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0641],\n",
      "         [ 0.0259],\n",
      "         [ 0.0699],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0055],\n",
      "         [ 0.0116],\n",
      "         [-0.0438],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0692],\n",
      "         [-0.0950],\n",
      "         [-0.0735],\n",
      "         ...,\n",
      "         [-0.0611],\n",
      "         [-0.0611],\n",
      "         [-0.0611]],\n",
      "\n",
      "        [[-0.0407],\n",
      "         [-0.1554],\n",
      "         [-0.0525],\n",
      "         ...,\n",
      "         [-0.0409],\n",
      "         [-0.0409],\n",
      "         [-0.0409]],\n",
      "\n",
      "        [[-0.0391],\n",
      "         [ 0.0147],\n",
      "         [ 0.0384],\n",
      "         ...,\n",
      "         [-0.0328],\n",
      "         [-0.0328],\n",
      "         [-0.0328]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0172],\n",
      "         [ 0.0305],\n",
      "         [ 0.0020],\n",
      "         ...,\n",
      "         [ 0.0187],\n",
      "         [ 0.0187],\n",
      "         [ 0.0187]],\n",
      "\n",
      "        [[ 0.0313],\n",
      "         [-0.0073],\n",
      "         [ 0.0361],\n",
      "         ...,\n",
      "         [ 0.0382],\n",
      "         [ 0.0382],\n",
      "         [ 0.0382]],\n",
      "\n",
      "        [[-0.0423],\n",
      "         [-0.0388],\n",
      "         [-0.0941],\n",
      "         ...,\n",
      "         [-0.0371],\n",
      "         [-0.0371],\n",
      "         [-0.0371]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0692],\n",
      "         [-0.0950],\n",
      "         [-0.0735],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0407],\n",
      "         [-0.1554],\n",
      "         [-0.0525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0391],\n",
      "         [ 0.0147],\n",
      "         [ 0.0384],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0172],\n",
      "         [ 0.0305],\n",
      "         [ 0.0020],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0313],\n",
      "         [-0.0073],\n",
      "         [ 0.0361],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0423],\n",
      "         [-0.0388],\n",
      "         [-0.0941],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 8.1496e-02],\n",
      "         [ 5.2936e-02],\n",
      "         [ 7.3532e-02],\n",
      "         ...,\n",
      "         [ 9.0411e-02],\n",
      "         [ 9.0413e-02],\n",
      "         [ 9.0415e-02]],\n",
      "\n",
      "        [[ 8.0690e-02],\n",
      "         [-3.7084e-02],\n",
      "         [ 6.2431e-02],\n",
      "         ...,\n",
      "         [ 8.5873e-02],\n",
      "         [ 8.5880e-02],\n",
      "         [ 8.5886e-02]],\n",
      "\n",
      "        [[ 8.1023e-02],\n",
      "         [ 1.3884e-01],\n",
      "         [ 1.6355e-01],\n",
      "         ...,\n",
      "         [ 9.0655e-02],\n",
      "         [ 9.0655e-02],\n",
      "         [ 9.0655e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.6067e-01],\n",
      "         [ 1.6991e-01],\n",
      "         [ 1.4377e-01],\n",
      "         ...,\n",
      "         [ 1.6870e-01],\n",
      "         [ 1.6870e-01],\n",
      "         [ 1.6870e-01]],\n",
      "\n",
      "        [[-3.6794e-03],\n",
      "         [-4.2017e-02],\n",
      "         [ 1.0117e-03],\n",
      "         ...,\n",
      "         [-3.9428e-05],\n",
      "         [-3.9071e-05],\n",
      "         [-3.8832e-05]],\n",
      "\n",
      "        [[ 9.6832e-02],\n",
      "         [ 1.0133e-01],\n",
      "         [ 3.9876e-02],\n",
      "         ...,\n",
      "         [ 1.0485e-01],\n",
      "         [ 1.0485e-01],\n",
      "         [ 1.0486e-01]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0815],\n",
      "         [ 0.0529],\n",
      "         [ 0.0735],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0807],\n",
      "         [-0.0371],\n",
      "         [ 0.0624],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0810],\n",
      "         [ 0.1388],\n",
      "         [ 0.1636],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1607],\n",
      "         [ 0.1699],\n",
      "         [ 0.1438],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0037],\n",
      "         [-0.0420],\n",
      "         [ 0.0010],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0968],\n",
      "         [ 0.1013],\n",
      "         [ 0.0399],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1040],\n",
      "         [ 0.0762],\n",
      "         [ 0.0969],\n",
      "         ...,\n",
      "         [ 0.1135],\n",
      "         [ 0.1135],\n",
      "         [ 0.1135]],\n",
      "\n",
      "        [[ 0.0139],\n",
      "         [-0.1021],\n",
      "         [-0.0014],\n",
      "         ...,\n",
      "         [ 0.0164],\n",
      "         [ 0.0164],\n",
      "         [ 0.0164]],\n",
      "\n",
      "        [[ 0.0437],\n",
      "         [ 0.1001],\n",
      "         [ 0.1243],\n",
      "         ...,\n",
      "         [ 0.0551],\n",
      "         [ 0.0551],\n",
      "         [ 0.0551]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0909],\n",
      "         [ 0.1004],\n",
      "         [ 0.0748],\n",
      "         ...,\n",
      "         [ 0.0976],\n",
      "         [ 0.0976],\n",
      "         [ 0.0976]],\n",
      "\n",
      "        [[ 0.0447],\n",
      "         [ 0.0054],\n",
      "         [ 0.0499],\n",
      "         ...,\n",
      "         [ 0.0502],\n",
      "         [ 0.0502],\n",
      "         [ 0.0502]],\n",
      "\n",
      "        [[ 0.1103],\n",
      "         [ 0.1128],\n",
      "         [ 0.0502],\n",
      "         ...,\n",
      "         [ 0.1207],\n",
      "         [ 0.1207],\n",
      "         [ 0.1207]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1040],\n",
      "         [ 0.0762],\n",
      "         [ 0.0969],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0139],\n",
      "         [-0.1021],\n",
      "         [-0.0014],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0437],\n",
      "         [ 0.1001],\n",
      "         [ 0.1243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0909],\n",
      "         [ 0.1004],\n",
      "         [ 0.0748],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0447],\n",
      "         [ 0.0054],\n",
      "         [ 0.0499],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1103],\n",
      "         [ 0.1128],\n",
      "         [ 0.0502],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1114],\n",
      "         [ 0.0802],\n",
      "         [ 0.0999],\n",
      "         ...,\n",
      "         [ 0.1225],\n",
      "         [ 0.1225],\n",
      "         [ 0.1225]],\n",
      "\n",
      "        [[-0.0419],\n",
      "         [-0.1555],\n",
      "         [-0.0562],\n",
      "         ...,\n",
      "         [-0.0404],\n",
      "         [-0.0403],\n",
      "         [-0.0403]],\n",
      "\n",
      "        [[ 0.1094],\n",
      "         [ 0.1682],\n",
      "         [ 0.1932],\n",
      "         ...,\n",
      "         [ 0.1183],\n",
      "         [ 0.1183],\n",
      "         [ 0.1183]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0265],\n",
      "         [ 0.0369],\n",
      "         [ 0.0104],\n",
      "         ...,\n",
      "         [ 0.0306],\n",
      "         [ 0.0306],\n",
      "         [ 0.0306]],\n",
      "\n",
      "        [[ 0.0291],\n",
      "         [-0.0098],\n",
      "         [ 0.0339],\n",
      "         ...,\n",
      "         [ 0.0348],\n",
      "         [ 0.0348],\n",
      "         [ 0.0348]],\n",
      "\n",
      "        [[ 0.0937],\n",
      "         [ 0.0967],\n",
      "         [ 0.0361],\n",
      "         ...,\n",
      "         [ 0.1028],\n",
      "         [ 0.1028],\n",
      "         [ 0.1028]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1114],\n",
      "         [ 0.0802],\n",
      "         [ 0.0999],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0419],\n",
      "         [-0.1555],\n",
      "         [-0.0562],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1094],\n",
      "         [ 0.1682],\n",
      "         [ 0.1932],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0265],\n",
      "         [ 0.0369],\n",
      "         [ 0.0104],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0291],\n",
      "         [-0.0098],\n",
      "         [ 0.0339],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0937],\n",
      "         [ 0.0967],\n",
      "         [ 0.0361],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0883],\n",
      "         [ 0.0560],\n",
      "         [ 0.0752],\n",
      "         ...,\n",
      "         [ 0.0999],\n",
      "         [ 0.0999],\n",
      "         [ 0.0999]],\n",
      "\n",
      "        [[ 0.0531],\n",
      "         [-0.0619],\n",
      "         [ 0.0397],\n",
      "         ...,\n",
      "         [ 0.0541],\n",
      "         [ 0.0541],\n",
      "         [ 0.0541]],\n",
      "\n",
      "        [[ 0.0933],\n",
      "         [ 0.1508],\n",
      "         [ 0.1746],\n",
      "         ...,\n",
      "         [ 0.0991],\n",
      "         [ 0.0991],\n",
      "         [ 0.0991]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0045],\n",
      "         [ 0.0073],\n",
      "         [-0.0202],\n",
      "         ...,\n",
      "         [-0.0025],\n",
      "         [-0.0025],\n",
      "         [-0.0025]],\n",
      "\n",
      "        [[-0.0772],\n",
      "         [-0.1152],\n",
      "         [-0.0737],\n",
      "         ...,\n",
      "         [-0.0759],\n",
      "         [-0.0759],\n",
      "         [-0.0759]],\n",
      "\n",
      "        [[ 0.0917],\n",
      "         [ 0.0939],\n",
      "         [ 0.0328],\n",
      "         ...,\n",
      "         [ 0.1012],\n",
      "         [ 0.1012],\n",
      "         [ 0.1012]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0883],\n",
      "         [ 0.0560],\n",
      "         [ 0.0752],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0531],\n",
      "         [-0.0619],\n",
      "         [ 0.0397],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0933],\n",
      "         [ 0.1508],\n",
      "         [ 0.1746],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0045],\n",
      "         [ 0.0073],\n",
      "         [-0.0202],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0772],\n",
      "         [-0.1152],\n",
      "         [-0.0737],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0917],\n",
      "         [ 0.0939],\n",
      "         [ 0.0328],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0155],\n",
      "         [-0.0152],\n",
      "         [ 0.0041],\n",
      "         ...,\n",
      "         [ 0.0248],\n",
      "         [ 0.0248],\n",
      "         [ 0.0248]],\n",
      "\n",
      "        [[ 0.0636],\n",
      "         [-0.0518],\n",
      "         [ 0.0507],\n",
      "         ...,\n",
      "         [ 0.0643],\n",
      "         [ 0.0643],\n",
      "         [ 0.0643]],\n",
      "\n",
      "        [[-0.0010],\n",
      "         [ 0.0553],\n",
      "         [ 0.0792],\n",
      "         ...,\n",
      "         [ 0.0044],\n",
      "         [ 0.0044],\n",
      "         [ 0.0044]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0203],\n",
      "         [-0.0077],\n",
      "         [-0.0359],\n",
      "         ...,\n",
      "         [-0.0195],\n",
      "         [-0.0195],\n",
      "         [-0.0195]],\n",
      "\n",
      "        [[-0.0302],\n",
      "         [-0.0685],\n",
      "         [-0.0255],\n",
      "         ...,\n",
      "         [-0.0301],\n",
      "         [-0.0301],\n",
      "         [-0.0301]],\n",
      "\n",
      "        [[ 0.1607],\n",
      "         [ 0.1635],\n",
      "         [ 0.1005],\n",
      "         ...,\n",
      "         [ 0.1716],\n",
      "         [ 0.1716],\n",
      "         [ 0.1716]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0155],\n",
      "         [-0.0152],\n",
      "         [ 0.0041],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0636],\n",
      "         [-0.0518],\n",
      "         [ 0.0507],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0010],\n",
      "         [ 0.0553],\n",
      "         [ 0.0792],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0203],\n",
      "         [-0.0077],\n",
      "         [-0.0359],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0302],\n",
      "         [-0.0685],\n",
      "         [-0.0255],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1607],\n",
      "         [ 0.1635],\n",
      "         [ 0.1005],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0505],\n",
      "         [ 0.0250],\n",
      "         [ 0.0461],\n",
      "         ...,\n",
      "         [ 0.0555],\n",
      "         [ 0.0555],\n",
      "         [ 0.0555]],\n",
      "\n",
      "        [[ 0.0668],\n",
      "         [-0.0493],\n",
      "         [ 0.0485],\n",
      "         ...,\n",
      "         [ 0.0712],\n",
      "         [ 0.0712],\n",
      "         [ 0.0712]],\n",
      "\n",
      "        [[-0.0150],\n",
      "         [ 0.0400],\n",
      "         [ 0.0638],\n",
      "         ...,\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0287],\n",
      "         [-0.0157],\n",
      "         [-0.0443],\n",
      "         ...,\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285]],\n",
      "\n",
      "        [[ 0.1178],\n",
      "         [ 0.0798],\n",
      "         [ 0.1254],\n",
      "         ...,\n",
      "         [ 0.1232],\n",
      "         [ 0.1232],\n",
      "         [ 0.1232]],\n",
      "\n",
      "        [[ 0.1546],\n",
      "         [ 0.1589],\n",
      "         [ 0.0984],\n",
      "         ...,\n",
      "         [ 0.1639],\n",
      "         [ 0.1639],\n",
      "         [ 0.1639]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0505],\n",
      "         [ 0.0250],\n",
      "         [ 0.0461],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0668],\n",
      "         [-0.0493],\n",
      "         [ 0.0485],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0150],\n",
      "         [ 0.0400],\n",
      "         [ 0.0638],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0287],\n",
      "         [-0.0157],\n",
      "         [-0.0443],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1178],\n",
      "         [ 0.0798],\n",
      "         [ 0.1254],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1546],\n",
      "         [ 0.1589],\n",
      "         [ 0.0984],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1079],\n",
      "         [ 0.0800],\n",
      "         [ 0.1004],\n",
      "         ...,\n",
      "         [ 0.1151],\n",
      "         [ 0.1151],\n",
      "         [ 0.1151]],\n",
      "\n",
      "        [[ 0.0802],\n",
      "         [-0.0378],\n",
      "         [ 0.0610],\n",
      "         ...,\n",
      "         [ 0.0861],\n",
      "         [ 0.0861],\n",
      "         [ 0.0861]],\n",
      "\n",
      "        [[-0.0150],\n",
      "         [ 0.0414],\n",
      "         [ 0.0655],\n",
      "         ...,\n",
      "         [-0.0072],\n",
      "         [-0.0072],\n",
      "         [-0.0072]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0333],\n",
      "         [-0.0200],\n",
      "         [-0.0489],\n",
      "         ...,\n",
      "         [-0.0333],\n",
      "         [-0.0333],\n",
      "         [-0.0333]],\n",
      "\n",
      "        [[ 0.1353],\n",
      "         [ 0.0959],\n",
      "         [ 0.1417],\n",
      "         ...,\n",
      "         [ 0.1428],\n",
      "         [ 0.1428],\n",
      "         [ 0.1428]],\n",
      "\n",
      "        [[ 0.1643],\n",
      "         [ 0.1690],\n",
      "         [ 0.1078],\n",
      "         ...,\n",
      "         [ 0.1741],\n",
      "         [ 0.1741],\n",
      "         [ 0.1741]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1079],\n",
      "         [ 0.0800],\n",
      "         [ 0.1004],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0802],\n",
      "         [-0.0378],\n",
      "         [ 0.0610],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0150],\n",
      "         [ 0.0414],\n",
      "         [ 0.0655],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0333],\n",
      "         [-0.0200],\n",
      "         [-0.0489],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1353],\n",
      "         [ 0.0959],\n",
      "         [ 0.1417],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1643],\n",
      "         [ 0.1690],\n",
      "         [ 0.1078],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0375],\n",
      "         [-0.0625],\n",
      "         [-0.0411],\n",
      "         ...,\n",
      "         [-0.0329],\n",
      "         [-0.0329],\n",
      "         [-0.0329]],\n",
      "\n",
      "        [[-0.0012],\n",
      "         [-0.1186],\n",
      "         [-0.0163],\n",
      "         ...,\n",
      "         [ 0.0020],\n",
      "         [ 0.0020],\n",
      "         [ 0.0020]],\n",
      "\n",
      "        [[-0.0002],\n",
      "         [ 0.0559],\n",
      "         [ 0.0798],\n",
      "         ...,\n",
      "         [ 0.0062],\n",
      "         [ 0.0062],\n",
      "         [ 0.0062]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0357],\n",
      "         [-0.0224],\n",
      "         [-0.0514],\n",
      "         ...,\n",
      "         [-0.0359],\n",
      "         [-0.0359],\n",
      "         [-0.0359]],\n",
      "\n",
      "        [[ 0.0920],\n",
      "         [ 0.0530],\n",
      "         [ 0.0976],\n",
      "         ...,\n",
      "         [ 0.0998],\n",
      "         [ 0.0998],\n",
      "         [ 0.0998]],\n",
      "\n",
      "        [[ 0.1495],\n",
      "         [ 0.1527],\n",
      "         [ 0.0922],\n",
      "         ...,\n",
      "         [ 0.1592],\n",
      "         [ 0.1592],\n",
      "         [ 0.1593]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0375],\n",
      "         [-0.0625],\n",
      "         [-0.0411],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0012],\n",
      "         [-0.1186],\n",
      "         [-0.0163],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0002],\n",
      "         [ 0.0559],\n",
      "         [ 0.0798],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0357],\n",
      "         [-0.0224],\n",
      "         [-0.0514],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0920],\n",
      "         [ 0.0530],\n",
      "         [ 0.0976],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1495],\n",
      "         [ 0.1527],\n",
      "         [ 0.0922],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0269],\n",
      "         [-0.0009],\n",
      "         [ 0.0196],\n",
      "         ...,\n",
      "         [ 0.0335],\n",
      "         [ 0.0335],\n",
      "         [ 0.0335]],\n",
      "\n",
      "        [[ 0.0042],\n",
      "         [-0.1137],\n",
      "         [-0.0129],\n",
      "         ...,\n",
      "         [ 0.0087],\n",
      "         [ 0.0087],\n",
      "         [ 0.0088]],\n",
      "\n",
      "        [[ 0.1514],\n",
      "         [ 0.2113],\n",
      "         [ 0.2364],\n",
      "         ...,\n",
      "         [ 0.1599],\n",
      "         [ 0.1599],\n",
      "         [ 0.1599]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0369],\n",
      "         [-0.0236],\n",
      "         [-0.0527],\n",
      "         ...,\n",
      "         [-0.0372],\n",
      "         [-0.0372],\n",
      "         [-0.0372]],\n",
      "\n",
      "        [[ 0.0902],\n",
      "         [ 0.0517],\n",
      "         [ 0.0954],\n",
      "         ...,\n",
      "         [ 0.0988],\n",
      "         [ 0.0988],\n",
      "         [ 0.0988]],\n",
      "\n",
      "        [[ 0.0597],\n",
      "         [ 0.0636],\n",
      "         [ 0.0068],\n",
      "         ...,\n",
      "         [ 0.0656],\n",
      "         [ 0.0656],\n",
      "         [ 0.0656]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0269],\n",
      "         [-0.0009],\n",
      "         [ 0.0196],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0042],\n",
      "         [-0.1137],\n",
      "         [-0.0129],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1514],\n",
      "         [ 0.2113],\n",
      "         [ 0.2364],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0369],\n",
      "         [-0.0236],\n",
      "         [-0.0527],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0902],\n",
      "         [ 0.0517],\n",
      "         [ 0.0954],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0597],\n",
      "         [ 0.0636],\n",
      "         [ 0.0068],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0925],\n",
      "         [ 0.0670],\n",
      "         [ 0.0881],\n",
      "         ...,\n",
      "         [ 0.0982],\n",
      "         [ 0.0982],\n",
      "         [ 0.0982]],\n",
      "\n",
      "        [[ 0.0146],\n",
      "         [-0.1041],\n",
      "         [-0.0034],\n",
      "         ...,\n",
      "         [ 0.0204],\n",
      "         [ 0.0204],\n",
      "         [ 0.0204]],\n",
      "\n",
      "        [[ 0.1681],\n",
      "         [ 0.2279],\n",
      "         [ 0.2524],\n",
      "         ...,\n",
      "         [ 0.1779],\n",
      "         [ 0.1779],\n",
      "         [ 0.1779]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0376],\n",
      "         [-0.0243],\n",
      "         [-0.0534],\n",
      "         ...,\n",
      "         [-0.0378],\n",
      "         [-0.0378],\n",
      "         [-0.0378]],\n",
      "\n",
      "        [[ 0.1145],\n",
      "         [ 0.0763],\n",
      "         [ 0.1205],\n",
      "         ...,\n",
      "         [ 0.1221],\n",
      "         [ 0.1221],\n",
      "         [ 0.1221]],\n",
      "\n",
      "        [[ 0.0769],\n",
      "         [ 0.0824],\n",
      "         [ 0.0269],\n",
      "         ...,\n",
      "         [ 0.0811],\n",
      "         [ 0.0811],\n",
      "         [ 0.0811]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0925],\n",
      "         [ 0.0670],\n",
      "         [ 0.0881],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0146],\n",
      "         [-0.1041],\n",
      "         [-0.0034],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1681],\n",
      "         [ 0.2279],\n",
      "         [ 0.2524],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0376],\n",
      "         [-0.0243],\n",
      "         [-0.0534],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1145],\n",
      "         [ 0.0763],\n",
      "         [ 0.1205],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0769],\n",
      "         [ 0.0824],\n",
      "         [ 0.0269],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0765],\n",
      "         [ 0.0462],\n",
      "         [ 0.0658],\n",
      "         ...,\n",
      "         [ 0.0855],\n",
      "         [ 0.0855],\n",
      "         [ 0.0855]],\n",
      "\n",
      "        [[-0.0318],\n",
      "         [-0.1469],\n",
      "         [-0.0468],\n",
      "         ...,\n",
      "         [-0.0279],\n",
      "         [-0.0279],\n",
      "         [-0.0279]],\n",
      "\n",
      "        [[ 0.1512],\n",
      "         [ 0.2098],\n",
      "         [ 0.2346],\n",
      "         ...,\n",
      "         [ 0.1611],\n",
      "         [ 0.1611],\n",
      "         [ 0.1611]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0379],\n",
      "         [-0.0246],\n",
      "         [-0.0538],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[ 0.0846],\n",
      "         [ 0.0462],\n",
      "         [ 0.0905],\n",
      "         ...,\n",
      "         [ 0.0914],\n",
      "         [ 0.0914],\n",
      "         [ 0.0914]],\n",
      "\n",
      "        [[ 0.0234],\n",
      "         [ 0.0286],\n",
      "         [-0.0256],\n",
      "         ...,\n",
      "         [ 0.0258],\n",
      "         [ 0.0258],\n",
      "         [ 0.0258]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0765],\n",
      "         [ 0.0462],\n",
      "         [ 0.0658],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0318],\n",
      "         [-0.1469],\n",
      "         [-0.0468],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1512],\n",
      "         [ 0.2098],\n",
      "         [ 0.2346],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0379],\n",
      "         [-0.0246],\n",
      "         [-0.0538],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0846],\n",
      "         [ 0.0462],\n",
      "         [ 0.0905],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0234],\n",
      "         [ 0.0286],\n",
      "         [-0.0256],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0659],\n",
      "         [ 0.0384],\n",
      "         [ 0.0592],\n",
      "         ...,\n",
      "         [ 0.0741],\n",
      "         [ 0.0742],\n",
      "         [ 0.0742]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [-0.1312],\n",
      "         [-0.0280],\n",
      "         ...,\n",
      "         [-0.0162],\n",
      "         [-0.0162],\n",
      "         [-0.0162]],\n",
      "\n",
      "        [[ 0.1106],\n",
      "         [ 0.1688],\n",
      "         [ 0.1938],\n",
      "         ...,\n",
      "         [ 0.1199],\n",
      "         [ 0.1199],\n",
      "         [ 0.1199]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0539],\n",
      "         ...,\n",
      "         [-0.0382],\n",
      "         [-0.0382],\n",
      "         [-0.0382]],\n",
      "\n",
      "        [[ 0.0348],\n",
      "         [-0.0038],\n",
      "         [ 0.0397],\n",
      "         ...,\n",
      "         [ 0.0387],\n",
      "         [ 0.0388],\n",
      "         [ 0.0388]],\n",
      "\n",
      "        [[ 0.0687],\n",
      "         [ 0.0741],\n",
      "         [ 0.0161],\n",
      "         ...,\n",
      "         [ 0.0736],\n",
      "         [ 0.0736],\n",
      "         [ 0.0736]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0659],\n",
      "         [ 0.0384],\n",
      "         [ 0.0592],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [-0.1312],\n",
      "         [-0.0280],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1106],\n",
      "         [ 0.1688],\n",
      "         [ 0.1938],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0539],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0348],\n",
      "         [-0.0038],\n",
      "         [ 0.0397],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0687],\n",
      "         [ 0.0741],\n",
      "         [ 0.0161],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1039],\n",
      "         [ 0.0719],\n",
      "         [ 0.0911],\n",
      "         ...,\n",
      "         [ 0.1151],\n",
      "         [ 0.1151],\n",
      "         [ 0.1151]],\n",
      "\n",
      "        [[-0.0769],\n",
      "         [-0.1924],\n",
      "         [-0.0873],\n",
      "         ...,\n",
      "         [-0.0767],\n",
      "         [-0.0767],\n",
      "         [-0.0767]],\n",
      "\n",
      "        [[ 0.0571],\n",
      "         [ 0.1136],\n",
      "         [ 0.1378],\n",
      "         ...,\n",
      "         [ 0.0643],\n",
      "         [ 0.0643],\n",
      "         [ 0.0643]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0382],\n",
      "         [-0.0382],\n",
      "         [-0.0382]],\n",
      "\n",
      "        [[ 0.0026],\n",
      "         [-0.0356],\n",
      "         [ 0.0073],\n",
      "         ...,\n",
      "         [ 0.0039],\n",
      "         [ 0.0039],\n",
      "         [ 0.0039]],\n",
      "\n",
      "        [[ 0.0413],\n",
      "         [ 0.0454],\n",
      "         [-0.0126],\n",
      "         ...,\n",
      "         [ 0.0462],\n",
      "         [ 0.0462],\n",
      "         [ 0.0462]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1039],\n",
      "         [ 0.0719],\n",
      "         [ 0.0911],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0769],\n",
      "         [-0.1924],\n",
      "         [-0.0873],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0571],\n",
      "         [ 0.1136],\n",
      "         [ 0.1378],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0026],\n",
      "         [-0.0356],\n",
      "         [ 0.0073],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0413],\n",
      "         [ 0.0454],\n",
      "         [-0.0126],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 5.2672e-02],\n",
      "         [ 2.2557e-02],\n",
      "         [ 4.2413e-02],\n",
      "         ...,\n",
      "         [ 6.2558e-02],\n",
      "         [ 6.2560e-02],\n",
      "         [ 6.2562e-02]],\n",
      "\n",
      "        [[-1.3279e-01],\n",
      "         [-2.4540e-01],\n",
      "         [-1.4210e-01],\n",
      "         ...,\n",
      "         [-1.3344e-01],\n",
      "         [-1.3343e-01],\n",
      "         [-1.3343e-01]],\n",
      "\n",
      "        [[ 2.7737e-02],\n",
      "         [ 8.3269e-02],\n",
      "         [ 1.0703e-01],\n",
      "         ...,\n",
      "         [ 3.2907e-02],\n",
      "         [ 3.2907e-02],\n",
      "         [ 3.2907e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.8097e-02],\n",
      "         [-2.4850e-02],\n",
      "         [-5.4040e-02],\n",
      "         ...,\n",
      "         [-3.8227e-02],\n",
      "         [-3.8227e-02],\n",
      "         [-3.8227e-02]],\n",
      "\n",
      "        [[-1.6805e-02],\n",
      "         [-5.4706e-02],\n",
      "         [-1.2072e-02],\n",
      "         ...,\n",
      "         [-1.7267e-02],\n",
      "         [-1.7267e-02],\n",
      "         [-1.7266e-02]],\n",
      "\n",
      "        [[ 5.7313e-02],\n",
      "         [ 6.0072e-02],\n",
      "         [ 5.4866e-05],\n",
      "         ...,\n",
      "         [ 6.4885e-02],\n",
      "         [ 6.4887e-02],\n",
      "         [ 6.4889e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 5.2672e-02],\n",
      "         [ 2.2557e-02],\n",
      "         [ 4.2413e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.3279e-01],\n",
      "         [-2.4540e-01],\n",
      "         [-1.4210e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 2.7737e-02],\n",
      "         [ 8.3269e-02],\n",
      "         [ 1.0703e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.8097e-02],\n",
      "         [-2.4850e-02],\n",
      "         [-5.4040e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.6805e-02],\n",
      "         [-5.4706e-02],\n",
      "         [-1.2072e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 5.7313e-02],\n",
      "         [ 6.0072e-02],\n",
      "         [ 5.4866e-05],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0699],\n",
      "         [ 0.0391],\n",
      "         [ 0.0587],\n",
      "         ...,\n",
      "         [ 0.0803],\n",
      "         [ 0.0803],\n",
      "         [ 0.0803]],\n",
      "\n",
      "        [[ 0.0030],\n",
      "         [-0.1115],\n",
      "         [-0.0168],\n",
      "         ...,\n",
      "         [ 0.0093],\n",
      "         [ 0.0093],\n",
      "         [ 0.0093]],\n",
      "\n",
      "        [[ 0.0116],\n",
      "         [ 0.0666],\n",
      "         [ 0.0901],\n",
      "         ...,\n",
      "         [ 0.0154],\n",
      "         [ 0.0154],\n",
      "         [ 0.0154]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0249],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0382],\n",
      "         [-0.0382],\n",
      "         [-0.0382]],\n",
      "\n",
      "        [[-0.0281],\n",
      "         [-0.0659],\n",
      "         [-0.0234],\n",
      "         ...,\n",
      "         [-0.0296],\n",
      "         [-0.0296],\n",
      "         [-0.0296]],\n",
      "\n",
      "        [[ 0.1820],\n",
      "         [ 0.1841],\n",
      "         [ 0.1192],\n",
      "         ...,\n",
      "         [ 0.1927],\n",
      "         [ 0.1927],\n",
      "         [ 0.1927]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0699],\n",
      "         [ 0.0391],\n",
      "         [ 0.0587],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0030],\n",
      "         [-0.1115],\n",
      "         [-0.0168],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0116],\n",
      "         [ 0.0666],\n",
      "         [ 0.0901],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0249],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0281],\n",
      "         [-0.0659],\n",
      "         [-0.0234],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1820],\n",
      "         [ 0.1841],\n",
      "         [ 0.1192],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0349],\n",
      "         [ 0.0066],\n",
      "         [ 0.0271],\n",
      "         ...,\n",
      "         [ 0.0423],\n",
      "         [ 0.0423],\n",
      "         [ 0.0423]],\n",
      "\n",
      "        [[-0.0203],\n",
      "         [-0.1352],\n",
      "         [-0.0378],\n",
      "         ...,\n",
      "         [-0.0160],\n",
      "         [-0.0160],\n",
      "         [-0.0160]],\n",
      "\n",
      "        [[ 0.0027],\n",
      "         [ 0.0575],\n",
      "         [ 0.0808],\n",
      "         ...,\n",
      "         [ 0.0057],\n",
      "         [ 0.0057],\n",
      "         [ 0.0057]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0249],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0382],\n",
      "         [-0.0382],\n",
      "         [-0.0382]],\n",
      "\n",
      "        [[-0.0346],\n",
      "         [-0.0723],\n",
      "         [-0.0299],\n",
      "         ...,\n",
      "         [-0.0366],\n",
      "         [-0.0366],\n",
      "         [-0.0366]],\n",
      "\n",
      "        [[ 0.1321],\n",
      "         [ 0.1347],\n",
      "         [ 0.0716],\n",
      "         ...,\n",
      "         [ 0.1423],\n",
      "         [ 0.1423],\n",
      "         [ 0.1423]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0349],\n",
      "         [ 0.0066],\n",
      "         [ 0.0271],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0203],\n",
      "         [-0.1352],\n",
      "         [-0.0378],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0027],\n",
      "         [ 0.0575],\n",
      "         [ 0.0808],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0249],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0346],\n",
      "         [-0.0723],\n",
      "         [-0.0299],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1321],\n",
      "         [ 0.1347],\n",
      "         [ 0.0716],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0145],\n",
      "         [-0.0117],\n",
      "         [ 0.0093],\n",
      "         ...,\n",
      "         [ 0.0194],\n",
      "         [ 0.0194],\n",
      "         [ 0.0194]],\n",
      "\n",
      "        [[-0.0487],\n",
      "         [-0.1641],\n",
      "         [-0.0579],\n",
      "         ...,\n",
      "         [-0.0505],\n",
      "         [-0.0505],\n",
      "         [-0.0505]],\n",
      "\n",
      "        [[-0.0022],\n",
      "         [ 0.0525],\n",
      "         [ 0.0757],\n",
      "         ...,\n",
      "         [ 0.0004],\n",
      "         [ 0.0004],\n",
      "         [ 0.0004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0249],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0382],\n",
      "         [-0.0382],\n",
      "         [-0.0382]],\n",
      "\n",
      "        [[-0.0383],\n",
      "         [-0.0759],\n",
      "         [-0.0335],\n",
      "         ...,\n",
      "         [-0.0406],\n",
      "         [-0.0406],\n",
      "         [-0.0406]],\n",
      "\n",
      "        [[ 0.0732],\n",
      "         [ 0.0762],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [ 0.0814],\n",
      "         [ 0.0814],\n",
      "         [ 0.0814]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0145],\n",
      "         [-0.0117],\n",
      "         [ 0.0093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0487],\n",
      "         [-0.1641],\n",
      "         [-0.0579],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0022],\n",
      "         [ 0.0525],\n",
      "         [ 0.0757],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0249],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0383],\n",
      "         [-0.0759],\n",
      "         [-0.0335],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0732],\n",
      "         [ 0.0762],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0024],\n",
      "         [-0.0224],\n",
      "         [-0.0010],\n",
      "         ...,\n",
      "         [ 0.0058],\n",
      "         [ 0.0058],\n",
      "         [ 0.0058]],\n",
      "\n",
      "        [[-0.0485],\n",
      "         [-0.1635],\n",
      "         [-0.0562],\n",
      "         ...,\n",
      "         [-0.0519],\n",
      "         [-0.0519],\n",
      "         [-0.0519]],\n",
      "\n",
      "        [[-0.0049],\n",
      "         [ 0.0497],\n",
      "         [ 0.0729],\n",
      "         ...,\n",
      "         [-0.0025],\n",
      "         [-0.0025],\n",
      "         [-0.0025]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0382],\n",
      "         [-0.0382],\n",
      "         [-0.0382]],\n",
      "\n",
      "        [[-0.0403],\n",
      "         [-0.0779],\n",
      "         [-0.0356],\n",
      "         ...,\n",
      "         [-0.0428],\n",
      "         [-0.0428],\n",
      "         [-0.0428]],\n",
      "\n",
      "        [[ 0.0373],\n",
      "         [ 0.0412],\n",
      "         [-0.0168],\n",
      "         ...,\n",
      "         [ 0.0431],\n",
      "         [ 0.0431],\n",
      "         [ 0.0431]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0024],\n",
      "         [-0.0224],\n",
      "         [-0.0010],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0485],\n",
      "         [-0.1635],\n",
      "         [-0.0562],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0049],\n",
      "         [ 0.0497],\n",
      "         [ 0.0729],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0403],\n",
      "         [-0.0779],\n",
      "         [-0.0356],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0373],\n",
      "         [ 0.0412],\n",
      "         [-0.0168],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0048],\n",
      "         [-0.0288],\n",
      "         [-0.0071],\n",
      "         ...,\n",
      "         [-0.0023],\n",
      "         [-0.0023],\n",
      "         [-0.0023]],\n",
      "\n",
      "        [[ 0.0991],\n",
      "         [-0.0149],\n",
      "         [ 0.0748],\n",
      "         ...,\n",
      "         [ 0.1083],\n",
      "         [ 0.1083],\n",
      "         [ 0.1083]],\n",
      "\n",
      "        [[-0.0064],\n",
      "         [ 0.0482],\n",
      "         [ 0.0714],\n",
      "         ...,\n",
      "         [-0.0041],\n",
      "         [-0.0041],\n",
      "         [-0.0041]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0415],\n",
      "         [-0.0791],\n",
      "         [-0.0367],\n",
      "         ...,\n",
      "         [-0.0440],\n",
      "         [-0.0440],\n",
      "         [-0.0440]],\n",
      "\n",
      "        [[ 0.0163],\n",
      "         [ 0.0209],\n",
      "         [-0.0355],\n",
      "         ...,\n",
      "         [ 0.0204],\n",
      "         [ 0.0204],\n",
      "         [ 0.0204]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0048],\n",
      "         [-0.0288],\n",
      "         [-0.0071],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0991],\n",
      "         [-0.0149],\n",
      "         [ 0.0748],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0064],\n",
      "         [ 0.0482],\n",
      "         [ 0.0714],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0415],\n",
      "         [-0.0791],\n",
      "         [-0.0367],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0163],\n",
      "         [ 0.0209],\n",
      "         [-0.0355],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0091],\n",
      "         [-0.0326],\n",
      "         [-0.0108],\n",
      "         ...,\n",
      "         [-0.0073],\n",
      "         [-0.0072],\n",
      "         [-0.0072]],\n",
      "\n",
      "        [[ 0.1086],\n",
      "         [-0.0053],\n",
      "         [ 0.0820],\n",
      "         ...,\n",
      "         [ 0.1193],\n",
      "         [ 0.1194],\n",
      "         [ 0.1194]],\n",
      "\n",
      "        [[-0.0072],\n",
      "         [ 0.0474],\n",
      "         [ 0.0705],\n",
      "         ...,\n",
      "         [-0.0050],\n",
      "         [-0.0050],\n",
      "         [-0.0050]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0421],\n",
      "         [-0.0797],\n",
      "         [-0.0374],\n",
      "         ...,\n",
      "         [-0.0447],\n",
      "         [-0.0447],\n",
      "         [-0.0447]],\n",
      "\n",
      "        [[ 0.0042],\n",
      "         [ 0.0093],\n",
      "         [-0.0462],\n",
      "         ...,\n",
      "         [ 0.0073],\n",
      "         [ 0.0073],\n",
      "         [ 0.0073]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0091],\n",
      "         [-0.0326],\n",
      "         [-0.0108],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1086],\n",
      "         [-0.0053],\n",
      "         [ 0.0820],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0072],\n",
      "         [ 0.0474],\n",
      "         [ 0.0705],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0381],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0421],\n",
      "         [-0.0797],\n",
      "         [-0.0374],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0042],\n",
      "         [ 0.0093],\n",
      "         [-0.0462],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0117],\n",
      "         [-0.0349],\n",
      "         [-0.0130],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]],\n",
      "\n",
      "        [[ 0.0860],\n",
      "         [-0.0285],\n",
      "         [ 0.0612],\n",
      "         ...,\n",
      "         [ 0.0959],\n",
      "         [ 0.0959],\n",
      "         [ 0.0959]],\n",
      "\n",
      "        [[-0.0076],\n",
      "         [ 0.0470],\n",
      "         [ 0.0701],\n",
      "         ...,\n",
      "         [-0.0054],\n",
      "         [-0.0054],\n",
      "         [-0.0054]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0425],\n",
      "         [-0.0801],\n",
      "         [-0.0377],\n",
      "         ...,\n",
      "         [-0.0451],\n",
      "         [-0.0451],\n",
      "         [-0.0451]],\n",
      "\n",
      "        [[-0.0027],\n",
      "         [ 0.0027],\n",
      "         [-0.0523],\n",
      "         ...,\n",
      "         [-0.0003],\n",
      "         [-0.0002],\n",
      "         [-0.0002]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0117],\n",
      "         [-0.0349],\n",
      "         [-0.0130],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0860],\n",
      "         [-0.0285],\n",
      "         [ 0.0612],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0076],\n",
      "         [ 0.0470],\n",
      "         [ 0.0701],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0425],\n",
      "         [-0.0801],\n",
      "         [-0.0377],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0027],\n",
      "         [ 0.0027],\n",
      "         [-0.0523],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0133],\n",
      "         [-0.0363],\n",
      "         [-0.0144],\n",
      "         ...,\n",
      "         [-0.0120],\n",
      "         [-0.0120],\n",
      "         [-0.0120]],\n",
      "\n",
      "        [[ 0.0392],\n",
      "         [-0.0763],\n",
      "         [ 0.0187],\n",
      "         ...,\n",
      "         [ 0.0457],\n",
      "         [ 0.0457],\n",
      "         [ 0.0457]],\n",
      "\n",
      "        [[-0.0079],\n",
      "         [ 0.0467],\n",
      "         [ 0.0699],\n",
      "         ...,\n",
      "         [-0.0057],\n",
      "         [-0.0057],\n",
      "         [-0.0057]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0427],\n",
      "         [-0.0803],\n",
      "         [-0.0379],\n",
      "         ...,\n",
      "         [-0.0453],\n",
      "         [-0.0453],\n",
      "         [-0.0453]],\n",
      "\n",
      "        [[-0.0066],\n",
      "         [-0.0011],\n",
      "         [-0.0558],\n",
      "         ...,\n",
      "         [-0.0045],\n",
      "         [-0.0045],\n",
      "         [-0.0045]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0133],\n",
      "         [-0.0363],\n",
      "         [-0.0144],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0392],\n",
      "         [-0.0763],\n",
      "         [ 0.0187],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0079],\n",
      "         [ 0.0467],\n",
      "         [ 0.0699],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0427],\n",
      "         [-0.0803],\n",
      "         [-0.0379],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0066],\n",
      "         [-0.0011],\n",
      "         [-0.0558],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0142],\n",
      "         [-0.0372],\n",
      "         [-0.0152],\n",
      "         ...,\n",
      "         [-0.0131],\n",
      "         [-0.0131],\n",
      "         [-0.0131]],\n",
      "\n",
      "        [[ 0.0109],\n",
      "         [-0.1050],\n",
      "         [-0.0058],\n",
      "         ...,\n",
      "         [ 0.0145],\n",
      "         [ 0.0145],\n",
      "         [ 0.0145]],\n",
      "\n",
      "        [[-0.0080],\n",
      "         [ 0.0466],\n",
      "         [ 0.0697],\n",
      "         ...,\n",
      "         [-0.0058],\n",
      "         [-0.0058],\n",
      "         [-0.0058]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0428],\n",
      "         [-0.0804],\n",
      "         [-0.0381],\n",
      "         ...,\n",
      "         [-0.0454],\n",
      "         [-0.0454],\n",
      "         [-0.0454]],\n",
      "\n",
      "        [[-0.0088],\n",
      "         [-0.0032],\n",
      "         [-0.0578],\n",
      "         ...,\n",
      "         [-0.0070],\n",
      "         [-0.0070],\n",
      "         [-0.0070]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0142],\n",
      "         [-0.0372],\n",
      "         [-0.0152],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0109],\n",
      "         [-0.1050],\n",
      "         [-0.0058],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0080],\n",
      "         [ 0.0466],\n",
      "         [ 0.0697],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0428],\n",
      "         [-0.0804],\n",
      "         [-0.0381],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0088],\n",
      "         [-0.0032],\n",
      "         [-0.0578],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0148],\n",
      "         [-0.0377],\n",
      "         [-0.0158],\n",
      "         ...,\n",
      "         [-0.0138],\n",
      "         [-0.0138],\n",
      "         [-0.0138]],\n",
      "\n",
      "        [[-0.0057],\n",
      "         [-0.1218],\n",
      "         [-0.0200],\n",
      "         ...,\n",
      "         [-0.0040],\n",
      "         [-0.0039],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0465],\n",
      "         [ 0.0697],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0429],\n",
      "         [-0.0805],\n",
      "         [-0.0381],\n",
      "         ...,\n",
      "         [-0.0455],\n",
      "         [-0.0455],\n",
      "         [-0.0455]],\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0045],\n",
      "         [-0.0589],\n",
      "         ...,\n",
      "         [-0.0084],\n",
      "         [-0.0084],\n",
      "         [-0.0084]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0148],\n",
      "         [-0.0377],\n",
      "         [-0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0057],\n",
      "         [-0.1218],\n",
      "         [-0.0200],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0465],\n",
      "         [ 0.0697],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0429],\n",
      "         [-0.0805],\n",
      "         [-0.0381],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0101],\n",
      "         [-0.0045],\n",
      "         [-0.0589],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0152],\n",
      "         [-0.0381],\n",
      "         [-0.0161],\n",
      "         ...,\n",
      "         [-0.0142],\n",
      "         [-0.0142],\n",
      "         [-0.0142]],\n",
      "\n",
      "        [[-0.0153],\n",
      "         [-0.1316],\n",
      "         [-0.0283],\n",
      "         ...,\n",
      "         [-0.0147],\n",
      "         [-0.0147],\n",
      "         [-0.0147]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0429],\n",
      "         [-0.0805],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0455],\n",
      "         [-0.0455],\n",
      "         [-0.0455]],\n",
      "\n",
      "        [[-0.0109],\n",
      "         [-0.0052],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [-0.0092],\n",
      "         [-0.0092],\n",
      "         [-0.0092]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0152],\n",
      "         [-0.0381],\n",
      "         [-0.0161],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0153],\n",
      "         [-0.1316],\n",
      "         [-0.0283],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0429],\n",
      "         [-0.0805],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0109],\n",
      "         [-0.0052],\n",
      "         [-0.0596],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0154],\n",
      "         [-0.0383],\n",
      "         [-0.0163],\n",
      "         ...,\n",
      "         [-0.0144],\n",
      "         [-0.0144],\n",
      "         [-0.0144]],\n",
      "\n",
      "        [[-0.0209],\n",
      "         [-0.1372],\n",
      "         [-0.0332],\n",
      "         ...,\n",
      "         [-0.0209],\n",
      "         [-0.0209],\n",
      "         [-0.0209]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0429],\n",
      "         [-0.0805],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0455],\n",
      "         [-0.0455],\n",
      "         [-0.0455]],\n",
      "\n",
      "        [[-0.0113],\n",
      "         [-0.0057],\n",
      "         [-0.0600],\n",
      "         ...,\n",
      "         [-0.0097],\n",
      "         [-0.0097],\n",
      "         [-0.0097]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0154],\n",
      "         [-0.0383],\n",
      "         [-0.0163],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0209],\n",
      "         [-0.1372],\n",
      "         [-0.0332],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0429],\n",
      "         [-0.0805],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0113],\n",
      "         [-0.0057],\n",
      "         [-0.0600],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0156],\n",
      "         [-0.0384],\n",
      "         [-0.0164],\n",
      "         ...,\n",
      "         [-0.0146],\n",
      "         [-0.0146],\n",
      "         [-0.0146]],\n",
      "\n",
      "        [[-0.0241],\n",
      "         [-0.1405],\n",
      "         [-0.0359],\n",
      "         ...,\n",
      "         [-0.0244],\n",
      "         [-0.0244],\n",
      "         [-0.0244]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0805],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0116],\n",
      "         [-0.0059],\n",
      "         [-0.0603],\n",
      "         ...,\n",
      "         [-0.0100],\n",
      "         [-0.0100],\n",
      "         [-0.0100]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0156],\n",
      "         [-0.0384],\n",
      "         [-0.0164],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0241],\n",
      "         [-0.1405],\n",
      "         [-0.0359],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0805],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0116],\n",
      "         [-0.0059],\n",
      "         [-0.0603],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0157],\n",
      "         [-0.0385],\n",
      "         [-0.0165],\n",
      "         ...,\n",
      "         [-0.0147],\n",
      "         [-0.0147],\n",
      "         [-0.0147]],\n",
      "\n",
      "        [[-0.0259],\n",
      "         [-0.1423],\n",
      "         [-0.0375],\n",
      "         ...,\n",
      "         [-0.0264],\n",
      "         [-0.0264],\n",
      "         [-0.0264]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0118],\n",
      "         [-0.0061],\n",
      "         [-0.0605],\n",
      "         ...,\n",
      "         [-0.0102],\n",
      "         [-0.0102],\n",
      "         [-0.0102]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0157],\n",
      "         [-0.0385],\n",
      "         [-0.0165],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0259],\n",
      "         [-0.1423],\n",
      "         [-0.0375],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0118],\n",
      "         [-0.0061],\n",
      "         [-0.0605],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0157],\n",
      "         [-0.0386],\n",
      "         [-0.0166],\n",
      "         ...,\n",
      "         [-0.0148],\n",
      "         [-0.0148],\n",
      "         [-0.0148]],\n",
      "\n",
      "        [[-0.0269],\n",
      "         [-0.1433],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [-0.0275],\n",
      "         [-0.0275],\n",
      "         [-0.0275]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0119],\n",
      "         [-0.0062],\n",
      "         [-0.0606],\n",
      "         ...,\n",
      "         [-0.0103],\n",
      "         [-0.0103],\n",
      "         [-0.0103]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0157],\n",
      "         [-0.0386],\n",
      "         [-0.0166],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0269],\n",
      "         [-0.1433],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0119],\n",
      "         [-0.0062],\n",
      "         [-0.0606],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0158],\n",
      "         [-0.0386],\n",
      "         [-0.0166],\n",
      "         ...,\n",
      "         [-0.0149],\n",
      "         [-0.0149],\n",
      "         [-0.0149]],\n",
      "\n",
      "        [[-0.0275],\n",
      "         [-0.1439],\n",
      "         [-0.0390],\n",
      "         ...,\n",
      "         [-0.0281],\n",
      "         [-0.0281],\n",
      "         [-0.0281]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0120],\n",
      "         [-0.0063],\n",
      "         [-0.0606],\n",
      "         ...,\n",
      "         [-0.0104],\n",
      "         [-0.0104],\n",
      "         [-0.0104]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0158],\n",
      "         [-0.0386],\n",
      "         [-0.0166],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0275],\n",
      "         [-0.1439],\n",
      "         [-0.0390],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0120],\n",
      "         [-0.0063],\n",
      "         [-0.0606],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0158],\n",
      "         [-0.0386],\n",
      "         [-0.0166],\n",
      "         ...,\n",
      "         [-0.0149],\n",
      "         [-0.0149],\n",
      "         [-0.0149]],\n",
      "\n",
      "        [[-0.0278],\n",
      "         [-0.1443],\n",
      "         [-0.0393],\n",
      "         ...,\n",
      "         [-0.0285],\n",
      "         [-0.0285],\n",
      "         [-0.0285]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0120],\n",
      "         [-0.0063],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [-0.0105],\n",
      "         [-0.0105],\n",
      "         [-0.0105]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0158],\n",
      "         [-0.0386],\n",
      "         [-0.0166],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0278],\n",
      "         [-0.1443],\n",
      "         [-0.0393],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0120],\n",
      "         [-0.0063],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0158],\n",
      "         [-0.0387],\n",
      "         [-0.0167],\n",
      "         ...,\n",
      "         [-0.0149],\n",
      "         [-0.0149],\n",
      "         [-0.0149]],\n",
      "\n",
      "        [[-0.0280],\n",
      "         [-0.1445],\n",
      "         [-0.0395],\n",
      "         ...,\n",
      "         [-0.0287],\n",
      "         [-0.0287],\n",
      "         [-0.0287]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0064],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [-0.0105],\n",
      "         [-0.0105],\n",
      "         [-0.0105]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0158],\n",
      "         [-0.0387],\n",
      "         [-0.0167],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0280],\n",
      "         [-0.1445],\n",
      "         [-0.0395],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0064],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0159],\n",
      "         [-0.0387],\n",
      "         [-0.0167],\n",
      "         ...,\n",
      "         [-0.0149],\n",
      "         [-0.0149],\n",
      "         [-0.0149]],\n",
      "\n",
      "        [[-0.0281],\n",
      "         [-0.1446],\n",
      "         [-0.0396],\n",
      "         ...,\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0064],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [-0.0105],\n",
      "         [-0.0105],\n",
      "         [-0.0105]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0159],\n",
      "         [-0.0387],\n",
      "         [-0.0167],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0281],\n",
      "         [-0.1446],\n",
      "         [-0.0396],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0064],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0159],\n",
      "         [-0.0387],\n",
      "         [-0.0167],\n",
      "         ...,\n",
      "         [-0.0149],\n",
      "         [-0.0149],\n",
      "         [-0.0149]],\n",
      "\n",
      "        [[-0.0281],\n",
      "         [-0.1446],\n",
      "         [-0.0396],\n",
      "         ...,\n",
      "         [-0.0288],\n",
      "         [-0.0288],\n",
      "         [-0.0288]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0064],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [-0.0106],\n",
      "         [-0.0105],\n",
      "         [-0.0105]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0159],\n",
      "         [-0.0387],\n",
      "         [-0.0167],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0281],\n",
      "         [-0.1446],\n",
      "         [-0.0396],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0064],\n",
      "         [-0.0607],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0159],\n",
      "         [-0.0387],\n",
      "         [-0.0167],\n",
      "         ...,\n",
      "         [-0.0150],\n",
      "         [-0.0150],\n",
      "         [-0.0150]],\n",
      "\n",
      "        [[-0.0282],\n",
      "         [-0.1447],\n",
      "         [-0.0397],\n",
      "         ...,\n",
      "         [-0.0289],\n",
      "         [-0.0289],\n",
      "         [-0.0289]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [-0.0381],\n",
      "         [-0.0381],\n",
      "         [-0.0381]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0383],\n",
      "         ...,\n",
      "         [-0.0456],\n",
      "         [-0.0456],\n",
      "         [-0.0456]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0064],\n",
      "         [-0.0608],\n",
      "         ...,\n",
      "         [-0.0106],\n",
      "         [-0.0106],\n",
      "         [-0.0106]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0159],\n",
      "         [-0.0387],\n",
      "         [-0.0167],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0282],\n",
      "         [-0.1447],\n",
      "         [-0.0397],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0082],\n",
      "         [ 0.0465],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0380],\n",
      "         [-0.0248],\n",
      "         [-0.0540],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.0806],\n",
      "         [-0.0383],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0121],\n",
      "         [-0.0064],\n",
      "         [-0.0608],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/25000 [00:02<3:33:29,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот в AttentiveModel сделали mask. Она выглядит так:\n",
      "torch.BoolTensor\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1978],\n",
      "         [0.2198],\n",
      "         [0.2129],\n",
      "         ...,\n",
      "         [0.2016],\n",
      "         [0.2016],\n",
      "         [0.2016]],\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.1143],\n",
      "         [0.2168],\n",
      "         ...,\n",
      "         [0.2016],\n",
      "         [0.2016],\n",
      "         [0.2016]],\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.2052],\n",
      "         [0.1737],\n",
      "         ...,\n",
      "         [0.0731],\n",
      "         [0.1281],\n",
      "         [0.1057]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.2379],\n",
      "         [0.1277],\n",
      "         ...,\n",
      "         [0.2016],\n",
      "         [0.2016],\n",
      "         [0.2016]],\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.2198],\n",
      "         [0.2707],\n",
      "         ...,\n",
      "         [0.2016],\n",
      "         [0.2016],\n",
      "         [0.2016]],\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.1473],\n",
      "         [0.1547],\n",
      "         ...,\n",
      "         [0.2016],\n",
      "         [0.2016],\n",
      "         [0.2016]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1978],\n",
      "         [0.2198],\n",
      "         [0.2129],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.1143],\n",
      "         [0.2168],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.2052],\n",
      "         [0.1737],\n",
      "         ...,\n",
      "         [0.0731],\n",
      "         [0.1281],\n",
      "         [0.1057]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.2379],\n",
      "         [0.1277],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.2198],\n",
      "         [0.2707],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1978],\n",
      "         [0.1473],\n",
      "         [0.1547],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1370],\n",
      "         [0.1587],\n",
      "         [0.1514],\n",
      "         ...,\n",
      "         [0.1417],\n",
      "         [0.1417],\n",
      "         [0.1417]],\n",
      "\n",
      "        [[0.1367],\n",
      "         [0.0527],\n",
      "         [0.1573],\n",
      "         ...,\n",
      "         [0.1411],\n",
      "         [0.1411],\n",
      "         [0.1411]],\n",
      "\n",
      "        [[0.1346],\n",
      "         [0.1402],\n",
      "         [0.1086],\n",
      "         ...,\n",
      "         [0.0097],\n",
      "         [0.0650],\n",
      "         [0.0416]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1238],\n",
      "         [0.1654],\n",
      "         [0.0532],\n",
      "         ...,\n",
      "         [0.1282],\n",
      "         [0.1282],\n",
      "         [0.1282]],\n",
      "\n",
      "        [[0.1444],\n",
      "         [0.1666],\n",
      "         [0.2166],\n",
      "         ...,\n",
      "         [0.1490],\n",
      "         [0.1490],\n",
      "         [0.1490]],\n",
      "\n",
      "        [[0.1256],\n",
      "         [0.0739],\n",
      "         [0.0813],\n",
      "         ...,\n",
      "         [0.1302],\n",
      "         [0.1302],\n",
      "         [0.1302]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1370],\n",
      "         [0.1587],\n",
      "         [0.1514],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1367],\n",
      "         [0.0527],\n",
      "         [0.1573],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1346],\n",
      "         [0.1402],\n",
      "         [0.1086],\n",
      "         ...,\n",
      "         [0.0097],\n",
      "         [0.0650],\n",
      "         [0.0416]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1238],\n",
      "         [0.1654],\n",
      "         [0.0532],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1444],\n",
      "         [0.1666],\n",
      "         [0.2166],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1256],\n",
      "         [0.0739],\n",
      "         [0.0813],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0438],\n",
      "         [-0.0204],\n",
      "         [-0.0316],\n",
      "         ...,\n",
      "         [-0.0378],\n",
      "         [-0.0378],\n",
      "         [-0.0378]],\n",
      "\n",
      "        [[ 0.1557],\n",
      "         [ 0.0713],\n",
      "         [ 0.1769],\n",
      "         ...,\n",
      "         [ 0.1612],\n",
      "         [ 0.1612],\n",
      "         [ 0.1612]],\n",
      "\n",
      "        [[-0.0023],\n",
      "         [ 0.0007],\n",
      "         [-0.0304],\n",
      "         ...,\n",
      "         [-0.1202],\n",
      "         [-0.0646],\n",
      "         [-0.0916]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0979],\n",
      "         [ 0.1419],\n",
      "         [ 0.0274],\n",
      "         ...,\n",
      "         [ 0.1012],\n",
      "         [ 0.1012],\n",
      "         [ 0.1012]],\n",
      "\n",
      "        [[ 0.1667],\n",
      "         [ 0.1894],\n",
      "         [ 0.2394],\n",
      "         ...,\n",
      "         [ 0.1722],\n",
      "         [ 0.1722],\n",
      "         [ 0.1722]],\n",
      "\n",
      "        [[ 0.0809],\n",
      "         [ 0.0290],\n",
      "         [ 0.0360],\n",
      "         ...,\n",
      "         [ 0.0841],\n",
      "         [ 0.0841],\n",
      "         [ 0.0841]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0438],\n",
      "         [-0.0204],\n",
      "         [-0.0316],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1557],\n",
      "         [ 0.0713],\n",
      "         [ 0.1769],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0023],\n",
      "         [ 0.0007],\n",
      "         [-0.0304],\n",
      "         ...,\n",
      "         [-0.1202],\n",
      "         [-0.0646],\n",
      "         [-0.0916]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0979],\n",
      "         [ 0.1419],\n",
      "         [ 0.0274],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1667],\n",
      "         [ 0.1894],\n",
      "         [ 0.2394],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0809],\n",
      "         [ 0.0290],\n",
      "         [ 0.0360],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0753],\n",
      "         [ 0.0988],\n",
      "         [ 0.0892],\n",
      "         ...,\n",
      "         [ 0.0806],\n",
      "         [ 0.0806],\n",
      "         [ 0.0806]],\n",
      "\n",
      "        [[ 0.1039],\n",
      "         [ 0.0216],\n",
      "         [ 0.1275],\n",
      "         ...,\n",
      "         [ 0.1083],\n",
      "         [ 0.1083],\n",
      "         [ 0.1083]],\n",
      "\n",
      "        [[-0.0788],\n",
      "         [-0.0772],\n",
      "         [-0.1074],\n",
      "         ...,\n",
      "         [-0.1892],\n",
      "         [-0.1331],\n",
      "         [-0.1627]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0215],\n",
      "         [ 0.0702],\n",
      "         [-0.0469],\n",
      "         ...,\n",
      "         [ 0.0220],\n",
      "         [ 0.0220],\n",
      "         [ 0.0220]],\n",
      "\n",
      "        [[ 0.0478],\n",
      "         [ 0.0707],\n",
      "         [ 0.1206],\n",
      "         ...,\n",
      "         [ 0.0523],\n",
      "         [ 0.0523],\n",
      "         [ 0.0523]],\n",
      "\n",
      "        [[ 0.0681],\n",
      "         [ 0.0186],\n",
      "         [ 0.0259],\n",
      "         ...,\n",
      "         [ 0.0743],\n",
      "         [ 0.0743],\n",
      "         [ 0.0743]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0753],\n",
      "         [ 0.0988],\n",
      "         [ 0.0892],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1039],\n",
      "         [ 0.0216],\n",
      "         [ 0.1275],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0788],\n",
      "         [-0.0772],\n",
      "         [-0.1074],\n",
      "         ...,\n",
      "         [-0.1892],\n",
      "         [-0.1331],\n",
      "         [-0.1627]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0215],\n",
      "         [ 0.0702],\n",
      "         [-0.0469],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0478],\n",
      "         [ 0.0707],\n",
      "         [ 0.1206],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0681],\n",
      "         [ 0.0186],\n",
      "         [ 0.0259],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1006],\n",
      "         [ 0.1216],\n",
      "         [ 0.1161],\n",
      "         ...,\n",
      "         [ 0.1084],\n",
      "         [ 0.1084],\n",
      "         [ 0.1084]],\n",
      "\n",
      "        [[ 0.0848],\n",
      "         [ 0.0035],\n",
      "         [ 0.1095],\n",
      "         ...,\n",
      "         [ 0.0883],\n",
      "         [ 0.0883],\n",
      "         [ 0.0883]],\n",
      "\n",
      "        [[ 0.0464],\n",
      "         [ 0.0506],\n",
      "         [ 0.0178],\n",
      "         ...,\n",
      "         [-0.0710],\n",
      "         [-0.0091],\n",
      "         [-0.0427]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540],\n",
      "         [ 0.1010],\n",
      "         [-0.0162],\n",
      "         ...,\n",
      "         [ 0.0560],\n",
      "         [ 0.0560],\n",
      "         [ 0.0560]],\n",
      "\n",
      "        [[ 0.1163],\n",
      "         [ 0.1391],\n",
      "         [ 0.1894],\n",
      "         ...,\n",
      "         [ 0.1212],\n",
      "         [ 0.1212],\n",
      "         [ 0.1212]],\n",
      "\n",
      "        [[-0.0206],\n",
      "         [-0.0708],\n",
      "         [-0.0638],\n",
      "         ...,\n",
      "         [-0.0167],\n",
      "         [-0.0167],\n",
      "         [-0.0167]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1006],\n",
      "         [ 0.1216],\n",
      "         [ 0.1161],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0848],\n",
      "         [ 0.0035],\n",
      "         [ 0.1095],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0464],\n",
      "         [ 0.0506],\n",
      "         [ 0.0178],\n",
      "         ...,\n",
      "         [-0.0710],\n",
      "         [-0.0091],\n",
      "         [-0.0427]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540],\n",
      "         [ 0.1010],\n",
      "         [-0.0162],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1163],\n",
      "         [ 0.1391],\n",
      "         [ 0.1894],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0206],\n",
      "         [-0.0708],\n",
      "         [-0.0638],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1364],\n",
      "         [ 0.1597],\n",
      "         [ 0.1503],\n",
      "         ...,\n",
      "         [ 0.1412],\n",
      "         [ 0.1412],\n",
      "         [ 0.1412]],\n",
      "\n",
      "        [[ 0.0466],\n",
      "         [-0.0337],\n",
      "         [ 0.0730],\n",
      "         ...,\n",
      "         [ 0.0489],\n",
      "         [ 0.0489],\n",
      "         [ 0.0489]],\n",
      "\n",
      "        [[-0.0650],\n",
      "         [-0.0639],\n",
      "         [-0.0949],\n",
      "         ...,\n",
      "         [-0.1752],\n",
      "         [-0.1174],\n",
      "         [-0.1494]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0576],\n",
      "         [ 0.0995],\n",
      "         [-0.0117],\n",
      "         ...,\n",
      "         [ 0.0619],\n",
      "         [ 0.0619],\n",
      "         [ 0.0619]],\n",
      "\n",
      "        [[ 0.0184],\n",
      "         [ 0.0431],\n",
      "         [ 0.0910],\n",
      "         ...,\n",
      "         [ 0.0186],\n",
      "         [ 0.0186],\n",
      "         [ 0.0186]],\n",
      "\n",
      "        [[ 0.0936],\n",
      "         [ 0.0455],\n",
      "         [ 0.0536],\n",
      "         ...,\n",
      "         [ 0.1028],\n",
      "         [ 0.1028],\n",
      "         [ 0.1028]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1364],\n",
      "         [ 0.1597],\n",
      "         [ 0.1503],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0466],\n",
      "         [-0.0337],\n",
      "         [ 0.0730],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0650],\n",
      "         [-0.0639],\n",
      "         [-0.0949],\n",
      "         ...,\n",
      "         [-0.1752],\n",
      "         [-0.1174],\n",
      "         [-0.1494]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0576],\n",
      "         [ 0.0995],\n",
      "         [-0.0117],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0184],\n",
      "         [ 0.0431],\n",
      "         [ 0.0910],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0936],\n",
      "         [ 0.0455],\n",
      "         [ 0.0536],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1370],\n",
      "         [ 0.1586],\n",
      "         [ 0.1520],\n",
      "         ...,\n",
      "         [ 0.1437],\n",
      "         [ 0.1437],\n",
      "         [ 0.1437]],\n",
      "\n",
      "        [[ 0.1025],\n",
      "         [ 0.0209],\n",
      "         [ 0.1279],\n",
      "         ...,\n",
      "         [ 0.1057],\n",
      "         [ 0.1057],\n",
      "         [ 0.1057]],\n",
      "\n",
      "        [[-0.0786],\n",
      "         [-0.0766],\n",
      "         [-0.1075],\n",
      "         ...,\n",
      "         [-0.1879],\n",
      "         [-0.1294],\n",
      "         [-0.1619]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0053],\n",
      "         [ 0.0517],\n",
      "         [-0.0633],\n",
      "         ...,\n",
      "         [ 0.0071],\n",
      "         [ 0.0071],\n",
      "         [ 0.0071]],\n",
      "\n",
      "        [[ 0.0598],\n",
      "         [ 0.0857],\n",
      "         [ 0.1320],\n",
      "         ...,\n",
      "         [ 0.0586],\n",
      "         [ 0.0586],\n",
      "         [ 0.0586]],\n",
      "\n",
      "        [[ 0.0695],\n",
      "         [ 0.0186],\n",
      "         [ 0.0265],\n",
      "         ...,\n",
      "         [ 0.0781],\n",
      "         [ 0.0781],\n",
      "         [ 0.0781]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1370],\n",
      "         [ 0.1586],\n",
      "         [ 0.1520],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1025],\n",
      "         [ 0.0209],\n",
      "         [ 0.1279],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0786],\n",
      "         [-0.0766],\n",
      "         [-0.1075],\n",
      "         ...,\n",
      "         [-0.1879],\n",
      "         [-0.1294],\n",
      "         [-0.1619]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0053],\n",
      "         [ 0.0517],\n",
      "         [-0.0633],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0598],\n",
      "         [ 0.0857],\n",
      "         [ 0.1320],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0695],\n",
      "         [ 0.0186],\n",
      "         [ 0.0265],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0833],\n",
      "         [ 0.1054],\n",
      "         [ 0.0959],\n",
      "         ...,\n",
      "         [ 0.0876],\n",
      "         [ 0.0876],\n",
      "         [ 0.0876]],\n",
      "\n",
      "        [[-0.0345],\n",
      "         [-0.1126],\n",
      "         [-0.0020],\n",
      "         ...,\n",
      "         [-0.0366],\n",
      "         [-0.0366],\n",
      "         [-0.0366]],\n",
      "\n",
      "        [[ 0.0822],\n",
      "         [ 0.0885],\n",
      "         [ 0.0562],\n",
      "         ...,\n",
      "         [-0.0380],\n",
      "         [ 0.0190],\n",
      "         [-0.0081]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0147],\n",
      "         [ 0.0601],\n",
      "         [-0.0541],\n",
      "         ...,\n",
      "         [ 0.0171],\n",
      "         [ 0.0171],\n",
      "         [ 0.0171]],\n",
      "\n",
      "        [[-0.0536],\n",
      "         [-0.0279],\n",
      "         [ 0.0176],\n",
      "         ...,\n",
      "         [-0.0566],\n",
      "         [-0.0566],\n",
      "         [-0.0566]],\n",
      "\n",
      "        [[ 0.1073],\n",
      "         [ 0.0572],\n",
      "         [ 0.0650],\n",
      "         ...,\n",
      "         [ 0.1157],\n",
      "         [ 0.1157],\n",
      "         [ 0.1157]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0833],\n",
      "         [ 0.1054],\n",
      "         [ 0.0959],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0345],\n",
      "         [-0.1126],\n",
      "         [-0.0020],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0822],\n",
      "         [ 0.0885],\n",
      "         [ 0.0562],\n",
      "         ...,\n",
      "         [-0.0380],\n",
      "         [ 0.0190],\n",
      "         [-0.0081]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0147],\n",
      "         [ 0.0601],\n",
      "         [-0.0541],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0536],\n",
      "         [-0.0279],\n",
      "         [ 0.0176],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1073],\n",
      "         [ 0.0572],\n",
      "         [ 0.0650],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0889],\n",
      "         [ 0.1124],\n",
      "         [ 0.1003],\n",
      "         ...,\n",
      "         [ 0.0914],\n",
      "         [ 0.0914],\n",
      "         [ 0.0914]],\n",
      "\n",
      "        [[ 0.0588],\n",
      "         [-0.0213],\n",
      "         [ 0.0903],\n",
      "         ...,\n",
      "         [ 0.0583],\n",
      "         [ 0.0583],\n",
      "         [ 0.0583]],\n",
      "\n",
      "        [[ 0.0027],\n",
      "         [ 0.0060],\n",
      "         [-0.0255],\n",
      "         ...,\n",
      "         [-0.1132],\n",
      "         [-0.0569],\n",
      "         [-0.0852]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0397],\n",
      "         [ 0.0075],\n",
      "         [-0.1072],\n",
      "         ...,\n",
      "         [-0.0382],\n",
      "         [-0.0382],\n",
      "         [-0.0382]],\n",
      "\n",
      "        [[ 0.0180],\n",
      "         [ 0.0426],\n",
      "         [ 0.0905],\n",
      "         ...,\n",
      "         [ 0.0189],\n",
      "         [ 0.0189],\n",
      "         [ 0.0189]],\n",
      "\n",
      "        [[ 0.0408],\n",
      "         [-0.0103],\n",
      "         [-0.0031],\n",
      "         ...,\n",
      "         [ 0.0460],\n",
      "         [ 0.0460],\n",
      "         [ 0.0460]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0889],\n",
      "         [ 0.1124],\n",
      "         [ 0.1003],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0588],\n",
      "         [-0.0213],\n",
      "         [ 0.0903],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0027],\n",
      "         [ 0.0060],\n",
      "         [-0.0255],\n",
      "         ...,\n",
      "         [-0.1132],\n",
      "         [-0.0569],\n",
      "         [-0.0852]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0397],\n",
      "         [ 0.0075],\n",
      "         [-0.1072],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0180],\n",
      "         [ 0.0426],\n",
      "         [ 0.0905],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0408],\n",
      "         [-0.0103],\n",
      "         [-0.0031],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 1.0287e-01],\n",
      "         [ 1.2625e-01],\n",
      "         [ 1.1498e-01],\n",
      "         ...,\n",
      "         [ 1.0606e-01],\n",
      "         [ 1.0606e-01],\n",
      "         [ 1.0606e-01]],\n",
      "\n",
      "        [[ 5.1281e-02],\n",
      "         [-2.8610e-02],\n",
      "         [ 7.8624e-02],\n",
      "         ...,\n",
      "         [ 5.3287e-02],\n",
      "         [ 5.3287e-02],\n",
      "         [ 5.3287e-02]],\n",
      "\n",
      "        [[ 1.2442e-01],\n",
      "         [ 1.3024e-01],\n",
      "         [ 9.8160e-02],\n",
      "         ...,\n",
      "         [-3.7089e-05],\n",
      "         [ 5.5454e-02],\n",
      "         [ 3.1570e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.4147e-02],\n",
      "         [ 1.3524e-04],\n",
      "         [-1.1181e-01],\n",
      "         ...,\n",
      "         [-3.9998e-02],\n",
      "         [-3.9998e-02],\n",
      "         [-3.9998e-02]],\n",
      "\n",
      "        [[ 7.7312e-02],\n",
      "         [ 1.0215e-01],\n",
      "         [ 1.5083e-01],\n",
      "         ...,\n",
      "         [ 7.9732e-02],\n",
      "         [ 7.9732e-02],\n",
      "         [ 7.9732e-02]],\n",
      "\n",
      "        [[-2.7344e-02],\n",
      "         [-7.8046e-02],\n",
      "         [-7.1142e-02],\n",
      "         ...,\n",
      "         [-2.3817e-02],\n",
      "         [-2.3817e-02],\n",
      "         [-2.3817e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 1.0287e-01],\n",
      "         [ 1.2625e-01],\n",
      "         [ 1.1498e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 5.1281e-02],\n",
      "         [-2.8610e-02],\n",
      "         [ 7.8624e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 1.2442e-01],\n",
      "         [ 1.3024e-01],\n",
      "         [ 9.8160e-02],\n",
      "         ...,\n",
      "         [-3.7089e-05],\n",
      "         [ 5.5454e-02],\n",
      "         [ 3.1570e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.4147e-02],\n",
      "         [ 1.3524e-04],\n",
      "         [-1.1181e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 7.7312e-02],\n",
      "         [ 1.0215e-01],\n",
      "         [ 1.5083e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.7344e-02],\n",
      "         [-7.8046e-02],\n",
      "         [-7.1142e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1045],\n",
      "         [ 0.1273],\n",
      "         [ 0.1172],\n",
      "         ...,\n",
      "         [ 0.1085],\n",
      "         [ 0.1085],\n",
      "         [ 0.1085]],\n",
      "\n",
      "        [[-0.0150],\n",
      "         [-0.0968],\n",
      "         [ 0.0107],\n",
      "         ...,\n",
      "         [-0.0113],\n",
      "         [-0.0113],\n",
      "         [-0.0113]],\n",
      "\n",
      "        [[ 0.0439],\n",
      "         [ 0.0484],\n",
      "         [ 0.0173],\n",
      "         ...,\n",
      "         [-0.0764],\n",
      "         [-0.0234],\n",
      "         [-0.0466]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0393],\n",
      "         [ 0.0808],\n",
      "         [-0.0293],\n",
      "         ...,\n",
      "         [ 0.0446],\n",
      "         [ 0.0446],\n",
      "         [ 0.0446]],\n",
      "\n",
      "        [[ 0.0748],\n",
      "         [ 0.0975],\n",
      "         [ 0.1476],\n",
      "         ...,\n",
      "         [ 0.0795],\n",
      "         [ 0.0795],\n",
      "         [ 0.0795]],\n",
      "\n",
      "        [[ 0.0850],\n",
      "         [ 0.0329],\n",
      "         [ 0.0402],\n",
      "         ...,\n",
      "         [ 0.0899],\n",
      "         [ 0.0899],\n",
      "         [ 0.0899]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1045],\n",
      "         [ 0.1273],\n",
      "         [ 0.1172],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0150],\n",
      "         [-0.0968],\n",
      "         [ 0.0107],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0439],\n",
      "         [ 0.0484],\n",
      "         [ 0.0173],\n",
      "         ...,\n",
      "         [-0.0764],\n",
      "         [-0.0234],\n",
      "         [-0.0466]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0393],\n",
      "         [ 0.0808],\n",
      "         [-0.0293],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0748],\n",
      "         [ 0.0975],\n",
      "         [ 0.1476],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0850],\n",
      "         [ 0.0329],\n",
      "         [ 0.0402],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0342],\n",
      "         [-0.0104],\n",
      "         [-0.0265],\n",
      "         ...,\n",
      "         [-0.0349],\n",
      "         [-0.0349],\n",
      "         [-0.0349]],\n",
      "\n",
      "        [[ 0.1840],\n",
      "         [ 0.1018],\n",
      "         [ 0.1979],\n",
      "         ...,\n",
      "         [ 0.1932],\n",
      "         [ 0.1932],\n",
      "         [ 0.1932]],\n",
      "\n",
      "        [[ 0.1017],\n",
      "         [ 0.1069],\n",
      "         [ 0.0745],\n",
      "         ...,\n",
      "         [-0.0207],\n",
      "         [ 0.0366],\n",
      "         [ 0.0098]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0113],\n",
      "         [ 0.0569],\n",
      "         [-0.0577],\n",
      "         ...,\n",
      "         [ 0.0139],\n",
      "         [ 0.0139],\n",
      "         [ 0.0139]],\n",
      "\n",
      "        [[ 0.0331],\n",
      "         [ 0.0564],\n",
      "         [ 0.1048],\n",
      "         ...,\n",
      "         [ 0.0355],\n",
      "         [ 0.0355],\n",
      "         [ 0.0355]],\n",
      "\n",
      "        [[-0.0417],\n",
      "         [-0.0939],\n",
      "         [-0.0870],\n",
      "         ...,\n",
      "         [-0.0387],\n",
      "         [-0.0387],\n",
      "         [-0.0387]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0342],\n",
      "         [-0.0104],\n",
      "         [-0.0265],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1840],\n",
      "         [ 0.1018],\n",
      "         [ 0.1979],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1017],\n",
      "         [ 0.1069],\n",
      "         [ 0.0745],\n",
      "         ...,\n",
      "         [-0.0207],\n",
      "         [ 0.0366],\n",
      "         [ 0.0098]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0113],\n",
      "         [ 0.0569],\n",
      "         [-0.0577],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0331],\n",
      "         [ 0.0564],\n",
      "         [ 0.1048],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0417],\n",
      "         [-0.0939],\n",
      "         [-0.0870],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1554],\n",
      "         [ 0.1759],\n",
      "         [ 0.1711],\n",
      "         ...,\n",
      "         [ 0.1629],\n",
      "         [ 0.1629],\n",
      "         [ 0.1629]],\n",
      "\n",
      "        [[ 0.1809],\n",
      "         [ 0.0980],\n",
      "         [ 0.1990],\n",
      "         ...,\n",
      "         [ 0.1884],\n",
      "         [ 0.1884],\n",
      "         [ 0.1884]],\n",
      "\n",
      "        [[ 0.0851],\n",
      "         [ 0.0889],\n",
      "         [ 0.0570],\n",
      "         ...,\n",
      "         [-0.0348],\n",
      "         [ 0.0231],\n",
      "         [-0.0052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0086],\n",
      "         [ 0.0403],\n",
      "         [-0.0774],\n",
      "         ...,\n",
      "         [-0.0081],\n",
      "         [-0.0081],\n",
      "         [-0.0081]],\n",
      "\n",
      "        [[ 0.0133],\n",
      "         [ 0.0374],\n",
      "         [ 0.0848],\n",
      "         ...,\n",
      "         [ 0.0139],\n",
      "         [ 0.0139],\n",
      "         [ 0.0139]],\n",
      "\n",
      "        [[ 0.0403],\n",
      "         [-0.0131],\n",
      "         [-0.0064],\n",
      "         ...,\n",
      "         [ 0.0415],\n",
      "         [ 0.0415],\n",
      "         [ 0.0415]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1554],\n",
      "         [ 0.1759],\n",
      "         [ 0.1711],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1809],\n",
      "         [ 0.0980],\n",
      "         [ 0.1990],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0851],\n",
      "         [ 0.0889],\n",
      "         [ 0.0570],\n",
      "         ...,\n",
      "         [-0.0348],\n",
      "         [ 0.0231],\n",
      "         [-0.0052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0086],\n",
      "         [ 0.0403],\n",
      "         [-0.0774],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0133],\n",
      "         [ 0.0374],\n",
      "         [ 0.0848],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0403],\n",
      "         [-0.0131],\n",
      "         [-0.0064],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1688],\n",
      "         [ 0.1906],\n",
      "         [ 0.1836],\n",
      "         ...,\n",
      "         [ 0.1749],\n",
      "         [ 0.1749],\n",
      "         [ 0.1749]],\n",
      "\n",
      "        [[ 0.1536],\n",
      "         [ 0.0701],\n",
      "         [ 0.1705],\n",
      "         ...,\n",
      "         [ 0.1614],\n",
      "         [ 0.1614],\n",
      "         [ 0.1614]],\n",
      "\n",
      "        [[ 0.1414],\n",
      "         [ 0.1468],\n",
      "         [ 0.1150],\n",
      "         ...,\n",
      "         [ 0.0150],\n",
      "         [ 0.0697],\n",
      "         [ 0.0474]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0214],\n",
      "         [ 0.0297],\n",
      "         [-0.0900],\n",
      "         ...,\n",
      "         [-0.0223],\n",
      "         [-0.0223],\n",
      "         [-0.0223]],\n",
      "\n",
      "        [[ 0.0032],\n",
      "         [ 0.0278],\n",
      "         [ 0.0746],\n",
      "         ...,\n",
      "         [ 0.0026],\n",
      "         [ 0.0026],\n",
      "         [ 0.0026]],\n",
      "\n",
      "        [[ 0.0990],\n",
      "         [ 0.0476],\n",
      "         [ 0.0550],\n",
      "         ...,\n",
      "         [ 0.1046],\n",
      "         [ 0.1046],\n",
      "         [ 0.1046]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1688],\n",
      "         [ 0.1906],\n",
      "         [ 0.1836],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1536],\n",
      "         [ 0.0701],\n",
      "         [ 0.1705],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1414],\n",
      "         [ 0.1468],\n",
      "         [ 0.1150],\n",
      "         ...,\n",
      "         [ 0.0150],\n",
      "         [ 0.0697],\n",
      "         [ 0.0474]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0214],\n",
      "         [ 0.0297],\n",
      "         [-0.0900],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0032],\n",
      "         [ 0.0278],\n",
      "         [ 0.0746],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0990],\n",
      "         [ 0.0476],\n",
      "         [ 0.0550],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1554],\n",
      "         [ 0.1783],\n",
      "         [ 0.1692],\n",
      "         ...,\n",
      "         [ 0.1605],\n",
      "         [ 0.1605],\n",
      "         [ 0.1605]],\n",
      "\n",
      "        [[ 0.0843],\n",
      "         [ 0.0017],\n",
      "         [ 0.1072],\n",
      "         ...,\n",
      "         [ 0.0907],\n",
      "         [ 0.0907],\n",
      "         [ 0.0907]],\n",
      "\n",
      "        [[ 0.1407],\n",
      "         [ 0.1464],\n",
      "         [ 0.1147],\n",
      "         ...,\n",
      "         [ 0.0152],\n",
      "         [ 0.0690],\n",
      "         [ 0.0474]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0293],\n",
      "         [ 0.0231],\n",
      "         [-0.0978],\n",
      "         ...,\n",
      "         [-0.0310],\n",
      "         [-0.0310],\n",
      "         [-0.0310]],\n",
      "\n",
      "        [[-0.0023],\n",
      "         [ 0.0227],\n",
      "         [ 0.0691],\n",
      "         ...,\n",
      "         [-0.0035],\n",
      "         [-0.0035],\n",
      "         [-0.0035]],\n",
      "\n",
      "        [[ 0.1105],\n",
      "         [ 0.0594],\n",
      "         [ 0.0663],\n",
      "         ...,\n",
      "         [ 0.1139],\n",
      "         [ 0.1139],\n",
      "         [ 0.1139]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1554],\n",
      "         [ 0.1783],\n",
      "         [ 0.1692],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0843],\n",
      "         [ 0.0017],\n",
      "         [ 0.1072],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1407],\n",
      "         [ 0.1464],\n",
      "         [ 0.1147],\n",
      "         ...,\n",
      "         [ 0.0152],\n",
      "         [ 0.0690],\n",
      "         [ 0.0474]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0293],\n",
      "         [ 0.0231],\n",
      "         [-0.0978],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0023],\n",
      "         [ 0.0227],\n",
      "         [ 0.0691],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1105],\n",
      "         [ 0.0594],\n",
      "         [ 0.0663],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1156],\n",
      "         [ 0.1386],\n",
      "         [ 0.1278],\n",
      "         ...,\n",
      "         [ 0.1193],\n",
      "         [ 0.1193],\n",
      "         [ 0.1193]],\n",
      "\n",
      "        [[-0.0071],\n",
      "         [-0.0871],\n",
      "         [ 0.0165],\n",
      "         ...,\n",
      "         [-0.0028],\n",
      "         [-0.0028],\n",
      "         [-0.0028]],\n",
      "\n",
      "        [[ 0.0980],\n",
      "         [ 0.1018],\n",
      "         [ 0.0702],\n",
      "         ...,\n",
      "         [-0.0220],\n",
      "         [ 0.0347],\n",
      "         [ 0.0079]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0341],\n",
      "         [ 0.0190],\n",
      "         [-0.1024],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0053],\n",
      "         [ 0.0199],\n",
      "         [ 0.0660],\n",
      "         ...,\n",
      "         [-0.0069],\n",
      "         [-0.0069],\n",
      "         [-0.0069]],\n",
      "\n",
      "        [[-0.0423],\n",
      "         [-0.0955],\n",
      "         [-0.0890],\n",
      "         ...,\n",
      "         [-0.0408],\n",
      "         [-0.0408],\n",
      "         [-0.0408]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1156],\n",
      "         [ 0.1386],\n",
      "         [ 0.1278],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0071],\n",
      "         [-0.0871],\n",
      "         [ 0.0165],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0980],\n",
      "         [ 0.1018],\n",
      "         [ 0.0702],\n",
      "         ...,\n",
      "         [-0.0220],\n",
      "         [ 0.0347],\n",
      "         [ 0.0079]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0341],\n",
      "         [ 0.0190],\n",
      "         [-0.1024],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0053],\n",
      "         [ 0.0199],\n",
      "         [ 0.0660],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0423],\n",
      "         [-0.0955],\n",
      "         [-0.0890],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0050],\n",
      "         [ 0.0307],\n",
      "         [ 0.0133],\n",
      "         ...,\n",
      "         [ 0.0043],\n",
      "         [ 0.0043],\n",
      "         [ 0.0043]],\n",
      "\n",
      "        [[ 0.0790],\n",
      "         [-0.0017],\n",
      "         [ 0.1073],\n",
      "         ...,\n",
      "         [ 0.0807],\n",
      "         [ 0.0807],\n",
      "         [ 0.0807]],\n",
      "\n",
      "        [[ 0.0909],\n",
      "         [ 0.0953],\n",
      "         [ 0.0637],\n",
      "         ...,\n",
      "         [-0.0318],\n",
      "         [ 0.0234],\n",
      "         [-0.0011]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0370],\n",
      "         [ 0.0166],\n",
      "         [-0.1052],\n",
      "         ...,\n",
      "         [-0.0394],\n",
      "         [-0.0394],\n",
      "         [-0.0394]],\n",
      "\n",
      "        [[-0.0070],\n",
      "         [ 0.0183],\n",
      "         [ 0.0643],\n",
      "         ...,\n",
      "         [-0.0087],\n",
      "         [-0.0087],\n",
      "         [-0.0087]],\n",
      "\n",
      "        [[ 0.0089],\n",
      "         [-0.0417],\n",
      "         [-0.0342],\n",
      "         ...,\n",
      "         [ 0.0156],\n",
      "         [ 0.0156],\n",
      "         [ 0.0156]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0050],\n",
      "         [ 0.0307],\n",
      "         [ 0.0133],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0790],\n",
      "         [-0.0017],\n",
      "         [ 0.1073],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0909],\n",
      "         [ 0.0953],\n",
      "         [ 0.0637],\n",
      "         ...,\n",
      "         [-0.0318],\n",
      "         [ 0.0234],\n",
      "         [-0.0011]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0370],\n",
      "         [ 0.0166],\n",
      "         [-0.1052],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0070],\n",
      "         [ 0.0183],\n",
      "         [ 0.0643],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0089],\n",
      "         [-0.0417],\n",
      "         [-0.0342],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0140],\n",
      "         [ 0.0394],\n",
      "         [ 0.0245],\n",
      "         ...,\n",
      "         [ 0.0158],\n",
      "         [ 0.0158],\n",
      "         [ 0.0158]],\n",
      "\n",
      "        [[ 0.0154],\n",
      "         [-0.0644],\n",
      "         [ 0.0451],\n",
      "         ...,\n",
      "         [ 0.0157],\n",
      "         [ 0.0157],\n",
      "         [ 0.0157]],\n",
      "\n",
      "        [[ 0.0433],\n",
      "         [ 0.0468],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [-0.0758],\n",
      "         [-0.0195],\n",
      "         [-0.0467]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0387],\n",
      "         [ 0.0151],\n",
      "         [-0.1069],\n",
      "         ...,\n",
      "         [-0.0412],\n",
      "         [-0.0412],\n",
      "         [-0.0412]],\n",
      "\n",
      "        [[-0.0080],\n",
      "         [ 0.0174],\n",
      "         [ 0.0634],\n",
      "         ...,\n",
      "         [-0.0098],\n",
      "         [-0.0098],\n",
      "         [-0.0098]],\n",
      "\n",
      "        [[ 0.0535],\n",
      "         [ 0.0027],\n",
      "         [ 0.0103],\n",
      "         ...,\n",
      "         [ 0.0612],\n",
      "         [ 0.0612],\n",
      "         [ 0.0612]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0140],\n",
      "         [ 0.0394],\n",
      "         [ 0.0245],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0154],\n",
      "         [-0.0644],\n",
      "         [ 0.0451],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0433],\n",
      "         [ 0.0468],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [-0.0758],\n",
      "         [-0.0195],\n",
      "         [-0.0467]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0387],\n",
      "         [ 0.0151],\n",
      "         [-0.1069],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0080],\n",
      "         [ 0.0174],\n",
      "         [ 0.0634],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0535],\n",
      "         [ 0.0027],\n",
      "         [ 0.0103],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0292],\n",
      "         [ 0.0545],\n",
      "         [ 0.0384],\n",
      "         ...,\n",
      "         [ 0.0292],\n",
      "         [ 0.0292],\n",
      "         [ 0.0292]],\n",
      "\n",
      "        [[ 0.0466],\n",
      "         [-0.0329],\n",
      "         [ 0.0787],\n",
      "         ...,\n",
      "         [ 0.0450],\n",
      "         [ 0.0450],\n",
      "         [ 0.0450]],\n",
      "\n",
      "        [[ 0.0668],\n",
      "         [ 0.0710],\n",
      "         [ 0.0395],\n",
      "         ...,\n",
      "         [-0.0545],\n",
      "         [ 0.0003],\n",
      "         [-0.0244]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0397],\n",
      "         [ 0.0142],\n",
      "         [-0.1079],\n",
      "         ...,\n",
      "         [-0.0423],\n",
      "         [-0.0423],\n",
      "         [-0.0423]],\n",
      "\n",
      "        [[-0.0085],\n",
      "         [ 0.0169],\n",
      "         [ 0.0628],\n",
      "         ...,\n",
      "         [-0.0104],\n",
      "         [-0.0104],\n",
      "         [-0.0104]],\n",
      "\n",
      "        [[ 0.1188],\n",
      "         [ 0.0688],\n",
      "         [ 0.0766],\n",
      "         ...,\n",
      "         [ 0.1278],\n",
      "         [ 0.1278],\n",
      "         [ 0.1278]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0292],\n",
      "         [ 0.0545],\n",
      "         [ 0.0384],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0466],\n",
      "         [-0.0329],\n",
      "         [ 0.0787],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0668],\n",
      "         [ 0.0710],\n",
      "         [ 0.0395],\n",
      "         ...,\n",
      "         [-0.0545],\n",
      "         [ 0.0003],\n",
      "         [-0.0244]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0397],\n",
      "         [ 0.0142],\n",
      "         [-0.1079],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0085],\n",
      "         [ 0.0169],\n",
      "         [ 0.0628],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1188],\n",
      "         [ 0.0688],\n",
      "         [ 0.0766],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0879],\n",
      "         [ 0.1116],\n",
      "         [ 0.0998],\n",
      "         ...,\n",
      "         [ 0.0908],\n",
      "         [ 0.0908],\n",
      "         [ 0.0908]],\n",
      "\n",
      "        [[ 0.0274],\n",
      "         [-0.0540],\n",
      "         [ 0.0576],\n",
      "         ...,\n",
      "         [ 0.0272],\n",
      "         [ 0.0272],\n",
      "         [ 0.0272]],\n",
      "\n",
      "        [[ 0.1124],\n",
      "         [ 0.1173],\n",
      "         [ 0.0850],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [ 0.0478],\n",
      "         [ 0.0205]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0402],\n",
      "         [ 0.0137],\n",
      "         [-0.1084],\n",
      "         ...,\n",
      "         [-0.0429],\n",
      "         [-0.0429],\n",
      "         [-0.0429]],\n",
      "\n",
      "        [[-0.0088],\n",
      "         [ 0.0166],\n",
      "         [ 0.0625],\n",
      "         ...,\n",
      "         [-0.0107],\n",
      "         [-0.0107],\n",
      "         [-0.0107]],\n",
      "\n",
      "        [[ 0.1183],\n",
      "         [ 0.0666],\n",
      "         [ 0.0739],\n",
      "         ...,\n",
      "         [ 0.1244],\n",
      "         [ 0.1244],\n",
      "         [ 0.1244]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0879],\n",
      "         [ 0.1116],\n",
      "         [ 0.0998],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0274],\n",
      "         [-0.0540],\n",
      "         [ 0.0576],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1124],\n",
      "         [ 0.1173],\n",
      "         [ 0.0850],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [ 0.0478],\n",
      "         [ 0.0205]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0402],\n",
      "         [ 0.0137],\n",
      "         [-0.1084],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0088],\n",
      "         [ 0.0166],\n",
      "         [ 0.0625],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1183],\n",
      "         [ 0.0666],\n",
      "         [ 0.0739],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0696],\n",
      "         [ 0.0918],\n",
      "         [ 0.0826],\n",
      "         ...,\n",
      "         [ 0.0745],\n",
      "         [ 0.0745],\n",
      "         [ 0.0745]],\n",
      "\n",
      "        [[ 0.0632],\n",
      "         [-0.0197],\n",
      "         [ 0.0906],\n",
      "         ...,\n",
      "         [ 0.0649],\n",
      "         [ 0.0649],\n",
      "         [ 0.0649]],\n",
      "\n",
      "        [[ 0.0768],\n",
      "         [ 0.0820],\n",
      "         [ 0.0500],\n",
      "         ...,\n",
      "         [-0.0443],\n",
      "         [ 0.0112],\n",
      "         [-0.0143]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0406],\n",
      "         [ 0.0134],\n",
      "         [-0.1088],\n",
      "         ...,\n",
      "         [-0.0433],\n",
      "         [-0.0433],\n",
      "         [-0.0433]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [ 0.0164],\n",
      "         [ 0.0624],\n",
      "         ...,\n",
      "         [-0.0109],\n",
      "         [-0.0109],\n",
      "         [-0.0109]],\n",
      "\n",
      "        [[ 0.0118],\n",
      "         [-0.0396],\n",
      "         [-0.0330],\n",
      "         ...,\n",
      "         [ 0.0141],\n",
      "         [ 0.0141],\n",
      "         [ 0.0141]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0696],\n",
      "         [ 0.0918],\n",
      "         [ 0.0826],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0632],\n",
      "         [-0.0197],\n",
      "         [ 0.0906],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0768],\n",
      "         [ 0.0820],\n",
      "         [ 0.0500],\n",
      "         ...,\n",
      "         [-0.0443],\n",
      "         [ 0.0112],\n",
      "         [-0.0143]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0406],\n",
      "         [ 0.0134],\n",
      "         [-0.1088],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [ 0.0164],\n",
      "         [ 0.0624],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0118],\n",
      "         [-0.0396],\n",
      "         [-0.0330],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0253],\n",
      "         [ 0.0478],\n",
      "         [ 0.0362],\n",
      "         ...,\n",
      "         [ 0.0281],\n",
      "         [ 0.0281],\n",
      "         [ 0.0281]],\n",
      "\n",
      "        [[ 0.0322],\n",
      "         [-0.0495],\n",
      "         [ 0.0586],\n",
      "         ...,\n",
      "         [ 0.0338],\n",
      "         [ 0.0338],\n",
      "         [ 0.0338]],\n",
      "\n",
      "        [[ 0.0759],\n",
      "         [ 0.0810],\n",
      "         [ 0.0485],\n",
      "         ...,\n",
      "         [-0.0468],\n",
      "         [ 0.0103],\n",
      "         [-0.0164]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0408],\n",
      "         [ 0.0132],\n",
      "         [-0.1090],\n",
      "         ...,\n",
      "         [-0.0435],\n",
      "         [-0.0435],\n",
      "         [-0.0435]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [ 0.0163],\n",
      "         [ 0.0623],\n",
      "         ...,\n",
      "         [-0.0109],\n",
      "         [-0.0109],\n",
      "         [-0.0109]],\n",
      "\n",
      "        [[ 0.0186],\n",
      "         [-0.0336],\n",
      "         [-0.0270],\n",
      "         ...,\n",
      "         [ 0.0200],\n",
      "         [ 0.0200],\n",
      "         [ 0.0200]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0253],\n",
      "         [ 0.0478],\n",
      "         [ 0.0362],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0322],\n",
      "         [-0.0495],\n",
      "         [ 0.0586],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0759],\n",
      "         [ 0.0810],\n",
      "         [ 0.0485],\n",
      "         ...,\n",
      "         [-0.0468],\n",
      "         [ 0.0103],\n",
      "         [-0.0164]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0408],\n",
      "         [ 0.0132],\n",
      "         [-0.1090],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0090],\n",
      "         [ 0.0163],\n",
      "         [ 0.0623],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0186],\n",
      "         [-0.0336],\n",
      "         [-0.0270],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0041],\n",
      "         [ 0.0274],\n",
      "         [ 0.0136],\n",
      "         ...,\n",
      "         [ 0.0052],\n",
      "         [ 0.0052],\n",
      "         [ 0.0052]],\n",
      "\n",
      "        [[ 0.0456],\n",
      "         [-0.0358],\n",
      "         [ 0.0682],\n",
      "         ...,\n",
      "         [ 0.0496],\n",
      "         [ 0.0496],\n",
      "         [ 0.0496]],\n",
      "\n",
      "        [[ 0.0249],\n",
      "         [ 0.0291],\n",
      "         [-0.0024],\n",
      "         ...,\n",
      "         [-0.0968],\n",
      "         [-0.0424],\n",
      "         [-0.0666]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0409],\n",
      "         [ 0.0130],\n",
      "         [-0.1091],\n",
      "         ...,\n",
      "         [-0.0437],\n",
      "         [-0.0437],\n",
      "         [-0.0437]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0163],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.1501],\n",
      "         [ 0.0995],\n",
      "         [ 0.1071],\n",
      "         ...,\n",
      "         [ 0.1572],\n",
      "         [ 0.1572],\n",
      "         [ 0.1572]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0041],\n",
      "         [ 0.0274],\n",
      "         [ 0.0136],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0456],\n",
      "         [-0.0358],\n",
      "         [ 0.0682],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0249],\n",
      "         [ 0.0291],\n",
      "         [-0.0024],\n",
      "         ...,\n",
      "         [-0.0968],\n",
      "         [-0.0424],\n",
      "         [-0.0666]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0409],\n",
      "         [ 0.0130],\n",
      "         [-0.1091],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0163],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1501],\n",
      "         [ 0.0995],\n",
      "         [ 0.1071],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0067],\n",
      "         [ 0.0172],\n",
      "         [ 0.0021],\n",
      "         ...,\n",
      "         [-0.0065],\n",
      "         [-0.0065],\n",
      "         [-0.0065]],\n",
      "\n",
      "        [[ 0.1699],\n",
      "         [ 0.0866],\n",
      "         [ 0.1848],\n",
      "         ...,\n",
      "         [ 0.1773],\n",
      "         [ 0.1773],\n",
      "         [ 0.1773]],\n",
      "\n",
      "        [[ 0.1586],\n",
      "         [ 0.1649],\n",
      "         [ 0.1345],\n",
      "         ...,\n",
      "         [ 0.0301],\n",
      "         [ 0.0780],\n",
      "         [ 0.0639]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0410],\n",
      "         [ 0.0130],\n",
      "         [-0.1092],\n",
      "         ...,\n",
      "         [-0.0437],\n",
      "         [-0.0437],\n",
      "         [-0.0437]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0163],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0848],\n",
      "         [ 0.0322],\n",
      "         [ 0.0395],\n",
      "         ...,\n",
      "         [ 0.0900],\n",
      "         [ 0.0900],\n",
      "         [ 0.0900]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0067],\n",
      "         [ 0.0172],\n",
      "         [ 0.0021],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1699],\n",
      "         [ 0.0866],\n",
      "         [ 0.1848],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1586],\n",
      "         [ 0.1649],\n",
      "         [ 0.1345],\n",
      "         ...,\n",
      "         [ 0.0301],\n",
      "         [ 0.0780],\n",
      "         [ 0.0639]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0410],\n",
      "         [ 0.0130],\n",
      "         [-0.1092],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0163],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0848],\n",
      "         [ 0.0322],\n",
      "         [ 0.0395],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0124],\n",
      "         [ 0.0118],\n",
      "         [-0.0039],\n",
      "         ...,\n",
      "         [-0.0127],\n",
      "         [-0.0127],\n",
      "         [-0.0127]],\n",
      "\n",
      "        [[ 0.1639],\n",
      "         [ 0.0810],\n",
      "         [ 0.1842],\n",
      "         ...,\n",
      "         [ 0.1699],\n",
      "         [ 0.1699],\n",
      "         [ 0.1699]],\n",
      "\n",
      "        [[ 0.1322],\n",
      "         [ 0.1381],\n",
      "         [ 0.1069],\n",
      "         ...,\n",
      "         [ 0.0050],\n",
      "         [ 0.0561],\n",
      "         [ 0.0379]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0129],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0438],\n",
      "         [-0.0438],\n",
      "         [-0.0438]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0163],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0797],\n",
      "         [ 0.0267],\n",
      "         [ 0.0339],\n",
      "         ...,\n",
      "         [ 0.0847],\n",
      "         [ 0.0847],\n",
      "         [ 0.0847]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0124],\n",
      "         [ 0.0118],\n",
      "         [-0.0039],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1639],\n",
      "         [ 0.0810],\n",
      "         [ 0.1842],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1322],\n",
      "         [ 0.1381],\n",
      "         [ 0.1069],\n",
      "         ...,\n",
      "         [ 0.0050],\n",
      "         [ 0.0561],\n",
      "         [ 0.0379]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0129],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0163],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0797],\n",
      "         [ 0.0267],\n",
      "         [ 0.0339],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0154],\n",
      "         [ 0.0089],\n",
      "         [-0.0070],\n",
      "         ...,\n",
      "         [-0.0159],\n",
      "         [-0.0159],\n",
      "         [-0.0159]],\n",
      "\n",
      "        [[ 0.0917],\n",
      "         [ 0.0099],\n",
      "         [ 0.1187],\n",
      "         ...,\n",
      "         [ 0.0947],\n",
      "         [ 0.0947],\n",
      "         [ 0.0947]],\n",
      "\n",
      "        [[ 0.1136],\n",
      "         [ 0.1186],\n",
      "         [ 0.0868],\n",
      "         ...,\n",
      "         [-0.0106],\n",
      "         [ 0.0444],\n",
      "         [ 0.0208]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0129],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0438],\n",
      "         [-0.0438],\n",
      "         [-0.0438]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0968],\n",
      "         [ 0.0446],\n",
      "         [ 0.0515],\n",
      "         ...,\n",
      "         [ 0.1008],\n",
      "         [ 0.1008],\n",
      "         [ 0.1008]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0154],\n",
      "         [ 0.0089],\n",
      "         [-0.0070],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0917],\n",
      "         [ 0.0099],\n",
      "         [ 0.1187],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1136],\n",
      "         [ 0.1186],\n",
      "         [ 0.0868],\n",
      "         ...,\n",
      "         [-0.0106],\n",
      "         [ 0.0444],\n",
      "         [ 0.0208]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0129],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0968],\n",
      "         [ 0.0446],\n",
      "         [ 0.0515],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0169],\n",
      "         [ 0.0075],\n",
      "         [-0.0086],\n",
      "         ...,\n",
      "         [-0.0175],\n",
      "         [-0.0175],\n",
      "         [-0.0175]],\n",
      "\n",
      "        [[ 0.0497],\n",
      "         [-0.0308],\n",
      "         [ 0.0780],\n",
      "         ...,\n",
      "         [ 0.0513],\n",
      "         [ 0.0513],\n",
      "         [ 0.0513]],\n",
      "\n",
      "        [[-0.0563],\n",
      "         [-0.0542],\n",
      "         [-0.0848],\n",
      "         ...,\n",
      "         [-0.1696],\n",
      "         [-0.1143],\n",
      "         [-0.1424]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0129],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0438],\n",
      "         [-0.0438],\n",
      "         [-0.0438]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0645],\n",
      "         [ 0.0126],\n",
      "         [ 0.0198],\n",
      "         ...,\n",
      "         [ 0.0698],\n",
      "         [ 0.0698],\n",
      "         [ 0.0698]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0169],\n",
      "         [ 0.0075],\n",
      "         [-0.0086],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0497],\n",
      "         [-0.0308],\n",
      "         [ 0.0780],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0563],\n",
      "         [-0.0542],\n",
      "         [-0.0848],\n",
      "         ...,\n",
      "         [-0.1696],\n",
      "         [-0.1143],\n",
      "         [-0.1424]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0129],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0645],\n",
      "         [ 0.0126],\n",
      "         [ 0.0198],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0177],\n",
      "         [ 0.0068],\n",
      "         [-0.0093],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0206],\n",
      "         [-0.1008],\n",
      "         [ 0.0052],\n",
      "         ...,\n",
      "         [-0.0182],\n",
      "         [-0.0182],\n",
      "         [-0.0182]],\n",
      "\n",
      "        [[ 0.0535],\n",
      "         [ 0.0592],\n",
      "         [ 0.0273],\n",
      "         ...,\n",
      "         [-0.0696],\n",
      "         [-0.0142],\n",
      "         [-0.0385]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0438],\n",
      "         [-0.0438],\n",
      "         [-0.0438]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0500],\n",
      "         [-0.0026],\n",
      "         [ 0.0039],\n",
      "         ...,\n",
      "         [ 0.0510],\n",
      "         [ 0.0510],\n",
      "         [ 0.0510]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0177],\n",
      "         [ 0.0068],\n",
      "         [-0.0093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0206],\n",
      "         [-0.1008],\n",
      "         [ 0.0052],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0535],\n",
      "         [ 0.0592],\n",
      "         [ 0.0273],\n",
      "         ...,\n",
      "         [-0.0696],\n",
      "         [-0.0142],\n",
      "         [-0.0385]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0500],\n",
      "         [-0.0026],\n",
      "         [ 0.0039],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0096],\n",
      "         ...,\n",
      "         [-0.0186],\n",
      "         [-0.0186],\n",
      "         [-0.0186]],\n",
      "\n",
      "        [[ 0.0501],\n",
      "         [-0.0321],\n",
      "         [ 0.0689],\n",
      "         ...,\n",
      "         [ 0.0559],\n",
      "         [ 0.0559],\n",
      "         [ 0.0559]],\n",
      "\n",
      "        [[ 0.0462],\n",
      "         [ 0.0511],\n",
      "         [ 0.0191],\n",
      "         ...,\n",
      "         [-0.0762],\n",
      "         [-0.0205],\n",
      "         [-0.0458]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0885],\n",
      "         [ 0.0354],\n",
      "         [ 0.0420],\n",
      "         ...,\n",
      "         [ 0.0900],\n",
      "         [ 0.0900],\n",
      "         [ 0.0900]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0096],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0501],\n",
      "         [-0.0321],\n",
      "         [ 0.0689],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0462],\n",
      "         [ 0.0511],\n",
      "         [ 0.0191],\n",
      "         ...,\n",
      "         [-0.0762],\n",
      "         [-0.0205],\n",
      "         [-0.0458]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0885],\n",
      "         [ 0.0354],\n",
      "         [ 0.0420],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0181],\n",
      "         [ 0.0063],\n",
      "         [-0.0097],\n",
      "         ...,\n",
      "         [-0.0187],\n",
      "         [-0.0187],\n",
      "         [-0.0187]],\n",
      "\n",
      "        [[ 0.1075],\n",
      "         [ 0.0254],\n",
      "         [ 0.1325],\n",
      "         ...,\n",
      "         [ 0.1109],\n",
      "         [ 0.1109],\n",
      "         [ 0.1109]],\n",
      "\n",
      "        [[-0.0778],\n",
      "         [-0.0760],\n",
      "         [-0.1064],\n",
      "         ...,\n",
      "         [-0.1908],\n",
      "         [-0.1359],\n",
      "         [-0.1636]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0331],\n",
      "         [-0.0205],\n",
      "         [-0.0139],\n",
      "         ...,\n",
      "         [ 0.0341],\n",
      "         [ 0.0341],\n",
      "         [ 0.0341]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0181],\n",
      "         [ 0.0063],\n",
      "         [-0.0097],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1075],\n",
      "         [ 0.0254],\n",
      "         [ 0.1325],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0778],\n",
      "         [-0.0760],\n",
      "         [-0.1064],\n",
      "         ...,\n",
      "         [-0.1908],\n",
      "         [-0.1359],\n",
      "         [-0.1636]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0411],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0331],\n",
      "         [-0.0205],\n",
      "         [-0.0139],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0182],\n",
      "         [ 0.0063],\n",
      "         [-0.0097],\n",
      "         ...,\n",
      "         [-0.0187],\n",
      "         [-0.0187],\n",
      "         [-0.0187]],\n",
      "\n",
      "        [[-0.0445],\n",
      "         [-0.1232],\n",
      "         [-0.0128],\n",
      "         ...,\n",
      "         [-0.0445],\n",
      "         [-0.0445],\n",
      "         [-0.0445]],\n",
      "\n",
      "        [[ 0.0400],\n",
      "         [ 0.0450],\n",
      "         [ 0.0136],\n",
      "         ...,\n",
      "         [-0.0829],\n",
      "         [-0.0295],\n",
      "         [-0.0520]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0331],\n",
      "         [-0.0204],\n",
      "         [-0.0142],\n",
      "         ...,\n",
      "         [ 0.0323],\n",
      "         [ 0.0323],\n",
      "         [ 0.0323]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0182],\n",
      "         [ 0.0063],\n",
      "         [-0.0097],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0445],\n",
      "         [-0.1232],\n",
      "         [-0.0128],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0400],\n",
      "         [ 0.0450],\n",
      "         [ 0.0136],\n",
      "         ...,\n",
      "         [-0.0829],\n",
      "         [-0.0295],\n",
      "         [-0.0520]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0331],\n",
      "         [-0.0204],\n",
      "         [-0.0142],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0181],\n",
      "         [ 0.0063],\n",
      "         [-0.0097],\n",
      "         ...,\n",
      "         [-0.0186],\n",
      "         [-0.0186],\n",
      "         [-0.0186]],\n",
      "\n",
      "        [[ 0.0771],\n",
      "         [-0.0043],\n",
      "         [ 0.0920],\n",
      "         ...,\n",
      "         [ 0.0849],\n",
      "         [ 0.0849],\n",
      "         [ 0.0849]],\n",
      "\n",
      "        [[ 0.1410],\n",
      "         [ 0.1476],\n",
      "         [ 0.1163],\n",
      "         ...,\n",
      "         [ 0.0137],\n",
      "         [ 0.0649],\n",
      "         [ 0.0468]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0273],\n",
      "         [-0.0258],\n",
      "         [-0.0193],\n",
      "         ...,\n",
      "         [ 0.0282],\n",
      "         [ 0.0282],\n",
      "         [ 0.0282]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0181],\n",
      "         [ 0.0063],\n",
      "         [-0.0097],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0771],\n",
      "         [-0.0043],\n",
      "         [ 0.0920],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1410],\n",
      "         [ 0.1476],\n",
      "         [ 0.1163],\n",
      "         ...,\n",
      "         [ 0.0137],\n",
      "         [ 0.0649],\n",
      "         [ 0.0468]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0273],\n",
      "         [-0.0258],\n",
      "         [-0.0193],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0181],\n",
      "         [ 0.0063],\n",
      "         [-0.0096],\n",
      "         ...,\n",
      "         [-0.0186],\n",
      "         [-0.0186],\n",
      "         [-0.0186]],\n",
      "\n",
      "        [[ 0.0514],\n",
      "         [-0.0301],\n",
      "         [ 0.0688],\n",
      "         ...,\n",
      "         [ 0.0584],\n",
      "         [ 0.0584],\n",
      "         [ 0.0584]],\n",
      "\n",
      "        [[ 0.1195],\n",
      "         [ 0.1255],\n",
      "         [ 0.0941],\n",
      "         ...,\n",
      "         [-0.0047],\n",
      "         [ 0.0474],\n",
      "         [ 0.0270]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0133],\n",
      "         [-0.0391],\n",
      "         [-0.0324],\n",
      "         ...,\n",
      "         [ 0.0156],\n",
      "         [ 0.0156],\n",
      "         [ 0.0156]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0181],\n",
      "         [ 0.0063],\n",
      "         [-0.0096],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0514],\n",
      "         [-0.0301],\n",
      "         [ 0.0688],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1195],\n",
      "         [ 0.1255],\n",
      "         [ 0.0941],\n",
      "         ...,\n",
      "         [-0.0047],\n",
      "         [ 0.0474],\n",
      "         [ 0.0270]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0133],\n",
      "         [-0.0391],\n",
      "         [-0.0324],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0181],\n",
      "         [ 0.0063],\n",
      "         [-0.0096],\n",
      "         ...,\n",
      "         [-0.0185],\n",
      "         [-0.0185],\n",
      "         [-0.0185]],\n",
      "\n",
      "        [[ 0.0672],\n",
      "         [-0.0146],\n",
      "         [ 0.0810],\n",
      "         ...,\n",
      "         [ 0.0754],\n",
      "         [ 0.0754],\n",
      "         [ 0.0754]],\n",
      "\n",
      "        [[ 0.1378],\n",
      "         [ 0.1435],\n",
      "         [ 0.1112],\n",
      "         ...,\n",
      "         [ 0.0133],\n",
      "         [ 0.0694],\n",
      "         [ 0.0449]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.1356],\n",
      "         [ 0.0838],\n",
      "         [ 0.0910],\n",
      "         ...,\n",
      "         [ 0.1405],\n",
      "         [ 0.1405],\n",
      "         [ 0.1405]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0181],\n",
      "         [ 0.0063],\n",
      "         [-0.0096],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0672],\n",
      "         [-0.0146],\n",
      "         [ 0.0810],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1378],\n",
      "         [ 0.1435],\n",
      "         [ 0.1112],\n",
      "         ...,\n",
      "         [ 0.0133],\n",
      "         [ 0.0694],\n",
      "         [ 0.0449]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1356],\n",
      "         [ 0.0838],\n",
      "         [ 0.0910],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0063],\n",
      "         [-0.0095],\n",
      "         ...,\n",
      "         [-0.0185],\n",
      "         [-0.0185],\n",
      "         [-0.0185]],\n",
      "\n",
      "        [[ 0.1177],\n",
      "         [ 0.0357],\n",
      "         [ 0.1407],\n",
      "         ...,\n",
      "         [ 0.1223],\n",
      "         [ 0.1223],\n",
      "         [ 0.1223]],\n",
      "\n",
      "        [[ 0.0338],\n",
      "         [ 0.0379],\n",
      "         [ 0.0053],\n",
      "         ...,\n",
      "         [-0.0852],\n",
      "         [-0.0268],\n",
      "         [-0.0565]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.1401],\n",
      "         [ 0.0879],\n",
      "         [ 0.0952],\n",
      "         ...,\n",
      "         [ 0.1461],\n",
      "         [ 0.1461],\n",
      "         [ 0.1461]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0063],\n",
      "         [-0.0095],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1177],\n",
      "         [ 0.0357],\n",
      "         [ 0.1407],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0338],\n",
      "         [ 0.0379],\n",
      "         [ 0.0053],\n",
      "         ...,\n",
      "         [-0.0852],\n",
      "         [-0.0268],\n",
      "         [-0.0565]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1401],\n",
      "         [ 0.0879],\n",
      "         [ 0.0952],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0095],\n",
      "         ...,\n",
      "         [-0.0184],\n",
      "         [-0.0184],\n",
      "         [-0.0184]],\n",
      "\n",
      "        [[ 0.0389],\n",
      "         [-0.0420],\n",
      "         [ 0.0653],\n",
      "         ...,\n",
      "         [ 0.0411],\n",
      "         [ 0.0411],\n",
      "         [ 0.0411]],\n",
      "\n",
      "        [[ 0.1170],\n",
      "         [ 0.1228],\n",
      "         [ 0.0911],\n",
      "         ...,\n",
      "         [-0.0082],\n",
      "         [ 0.0449],\n",
      "         [ 0.0237]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.1079],\n",
      "         [ 0.0564],\n",
      "         [ 0.0634],\n",
      "         ...,\n",
      "         [ 0.1133],\n",
      "         [ 0.1133],\n",
      "         [ 0.1133]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0095],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0389],\n",
      "         [-0.0420],\n",
      "         [ 0.0653],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1170],\n",
      "         [ 0.1228],\n",
      "         [ 0.0911],\n",
      "         ...,\n",
      "         [-0.0082],\n",
      "         [ 0.0449],\n",
      "         [ 0.0237]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1079],\n",
      "         [ 0.0564],\n",
      "         [ 0.0634],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0095],\n",
      "         ...,\n",
      "         [-0.0184],\n",
      "         [-0.0184],\n",
      "         [-0.0184]],\n",
      "\n",
      "        [[ 0.0527],\n",
      "         [-0.0258],\n",
      "         [ 0.0882],\n",
      "         ...,\n",
      "         [ 0.0496],\n",
      "         [ 0.0496],\n",
      "         [ 0.0496]],\n",
      "\n",
      "        [[ 0.0377],\n",
      "         [ 0.0419],\n",
      "         [ 0.0102],\n",
      "         ...,\n",
      "         [-0.0839],\n",
      "         [-0.0285],\n",
      "         [-0.0539]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0679],\n",
      "         [ 0.0168],\n",
      "         [ 0.0238],\n",
      "         ...,\n",
      "         [ 0.0729],\n",
      "         [ 0.0729],\n",
      "         [ 0.0729]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0095],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0527],\n",
      "         [-0.0258],\n",
      "         [ 0.0882],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0377],\n",
      "         [ 0.0419],\n",
      "         [ 0.0102],\n",
      "         ...,\n",
      "         [-0.0839],\n",
      "         [-0.0285],\n",
      "         [-0.0539]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0679],\n",
      "         [ 0.0168],\n",
      "         [ 0.0238],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0095],\n",
      "         ...,\n",
      "         [-0.0184],\n",
      "         [-0.0184],\n",
      "         [-0.0184]],\n",
      "\n",
      "        [[-0.0285],\n",
      "         [-0.1050],\n",
      "         [ 0.0047],\n",
      "         ...,\n",
      "         [-0.0309],\n",
      "         [-0.0309],\n",
      "         [-0.0309]],\n",
      "\n",
      "        [[ 0.0078],\n",
      "         [ 0.0111],\n",
      "         [-0.0206],\n",
      "         ...,\n",
      "         [-0.1102],\n",
      "         [-0.0540],\n",
      "         [-0.0816]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[ 0.0164],\n",
      "         [-0.0355],\n",
      "         [-0.0290],\n",
      "         ...,\n",
      "         [ 0.0184],\n",
      "         [ 0.0184],\n",
      "         [ 0.0184]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0095],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0285],\n",
      "         [-0.1050],\n",
      "         [ 0.0047],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0078],\n",
      "         [ 0.0111],\n",
      "         [-0.0206],\n",
      "         ...,\n",
      "         [-0.1102],\n",
      "         [-0.0540],\n",
      "         [-0.0816]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1093],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0164],\n",
      "         [-0.0355],\n",
      "         [-0.0290],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[ 0.1299],\n",
      "         [ 0.0506],\n",
      "         [ 0.1564],\n",
      "         ...,\n",
      "         [ 0.1327],\n",
      "         [ 0.1327],\n",
      "         [ 0.1327]],\n",
      "\n",
      "        [[-0.0680],\n",
      "         [-0.0670],\n",
      "         [-0.0980],\n",
      "         ...,\n",
      "         [-0.1789],\n",
      "         [-0.1221],\n",
      "         [-0.1534]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0095],\n",
      "         [-0.0620],\n",
      "         [-0.0558],\n",
      "         ...,\n",
      "         [-0.0098],\n",
      "         [-0.0098],\n",
      "         [-0.0098]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0180],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1299],\n",
      "         [ 0.0506],\n",
      "         [ 0.1564],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0680],\n",
      "         [-0.0670],\n",
      "         [-0.0980],\n",
      "         ...,\n",
      "         [-0.1789],\n",
      "         [-0.1221],\n",
      "         [-0.1534]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0095],\n",
      "         [-0.0620],\n",
      "         [-0.0558],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[ 0.1484],\n",
      "         [ 0.0663],\n",
      "         [ 0.1706],\n",
      "         ...,\n",
      "         [ 0.1538],\n",
      "         [ 0.1538],\n",
      "         [ 0.1538]],\n",
      "\n",
      "        [[ 0.0507],\n",
      "         [ 0.0542],\n",
      "         [ 0.0218],\n",
      "         ...,\n",
      "         [-0.0677],\n",
      "         [-0.0075],\n",
      "         [-0.0390]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0233],\n",
      "         [-0.0763],\n",
      "         [-0.0702],\n",
      "         ...,\n",
      "         [-0.0249],\n",
      "         [-0.0249],\n",
      "         [-0.0249]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1484],\n",
      "         [ 0.0663],\n",
      "         [ 0.1706],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0507],\n",
      "         [ 0.0542],\n",
      "         [ 0.0218],\n",
      "         ...,\n",
      "         [-0.0677],\n",
      "         [-0.0075],\n",
      "         [-0.0390]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0233],\n",
      "         [-0.0763],\n",
      "         [-0.0702],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[ 0.1783],\n",
      "         [ 0.0956],\n",
      "         [ 0.1974],\n",
      "         ...,\n",
      "         [ 0.1849],\n",
      "         [ 0.1849],\n",
      "         [ 0.1849]],\n",
      "\n",
      "        [[ 0.0856],\n",
      "         [ 0.0885],\n",
      "         [ 0.0566],\n",
      "         ...,\n",
      "         [-0.0311],\n",
      "         [ 0.0295],\n",
      "         [-0.0028]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0308],\n",
      "         [-0.0841],\n",
      "         [-0.0781],\n",
      "         ...,\n",
      "         [-0.0331],\n",
      "         [-0.0331],\n",
      "         [-0.0331]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1783],\n",
      "         [ 0.0956],\n",
      "         [ 0.1974],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0856],\n",
      "         [ 0.0885],\n",
      "         [ 0.0566],\n",
      "         ...,\n",
      "         [-0.0311],\n",
      "         [ 0.0295],\n",
      "         [-0.0028]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0308],\n",
      "         [-0.0841],\n",
      "         [-0.0781],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[ 0.1097],\n",
      "         [ 0.0280],\n",
      "         [ 0.1327],\n",
      "         ...,\n",
      "         [ 0.1143],\n",
      "         [ 0.1143],\n",
      "         [ 0.1143]],\n",
      "\n",
      "        [[ 0.0675],\n",
      "         [ 0.0708],\n",
      "         [ 0.0389],\n",
      "         ...,\n",
      "         [-0.0520],\n",
      "         [ 0.0063],\n",
      "         [-0.0227]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0350],\n",
      "         [-0.0884],\n",
      "         [-0.0824],\n",
      "         ...,\n",
      "         [-0.0376],\n",
      "         [-0.0376],\n",
      "         [-0.0376]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1097],\n",
      "         [ 0.0280],\n",
      "         [ 0.1327],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0675],\n",
      "         [ 0.0708],\n",
      "         [ 0.0389],\n",
      "         ...,\n",
      "         [-0.0520],\n",
      "         [ 0.0063],\n",
      "         [-0.0227]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0350],\n",
      "         [-0.0884],\n",
      "         [-0.0824],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[ 0.0460],\n",
      "         [-0.0344],\n",
      "         [ 0.0727],\n",
      "         ...,\n",
      "         [ 0.0479],\n",
      "         [ 0.0479],\n",
      "         [ 0.0479]],\n",
      "\n",
      "        [[ 0.0451],\n",
      "         [ 0.0489],\n",
      "         [ 0.0167],\n",
      "         ...,\n",
      "         [-0.0746],\n",
      "         [-0.0167],\n",
      "         [-0.0454]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0372],\n",
      "         [-0.0907],\n",
      "         [-0.0847],\n",
      "         ...,\n",
      "         [-0.0400],\n",
      "         [-0.0400],\n",
      "         [-0.0400]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0460],\n",
      "         [-0.0344],\n",
      "         [ 0.0727],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0451],\n",
      "         [ 0.0489],\n",
      "         [ 0.0167],\n",
      "         ...,\n",
      "         [-0.0746],\n",
      "         [-0.0167],\n",
      "         [-0.0454]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0372],\n",
      "         [-0.0907],\n",
      "         [-0.0847],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[ 0.0133],\n",
      "         [-0.0662],\n",
      "         [ 0.0434],\n",
      "         ...,\n",
      "         [ 0.0129],\n",
      "         [ 0.0129],\n",
      "         [ 0.0129]],\n",
      "\n",
      "        [[ 0.1059],\n",
      "         [ 0.1114],\n",
      "         [ 0.0806],\n",
      "         ...,\n",
      "         [-0.0181],\n",
      "         [ 0.0319],\n",
      "         [ 0.0135]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0384],\n",
      "         [-0.0920],\n",
      "         [-0.0860],\n",
      "         ...,\n",
      "         [-0.0413],\n",
      "         [-0.0413],\n",
      "         [-0.0413]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0133],\n",
      "         [-0.0662],\n",
      "         [ 0.0434],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1059],\n",
      "         [ 0.1114],\n",
      "         [ 0.0806],\n",
      "         ...,\n",
      "         [-0.0181],\n",
      "         [ 0.0319],\n",
      "         [ 0.0135]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0384],\n",
      "         [-0.0920],\n",
      "         [-0.0860],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0036],\n",
      "         [-0.0828],\n",
      "         [ 0.0286],\n",
      "         ...,\n",
      "         [-0.0054],\n",
      "         [-0.0054],\n",
      "         [-0.0054]],\n",
      "\n",
      "        [[ 0.0237],\n",
      "         [ 0.0270],\n",
      "         [-0.0038],\n",
      "         ...,\n",
      "         [-0.0949],\n",
      "         [-0.0417],\n",
      "         [-0.0659]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0391],\n",
      "         [-0.0926],\n",
      "         [-0.0866],\n",
      "         ...,\n",
      "         [-0.0419],\n",
      "         [-0.0419],\n",
      "         [-0.0419]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0036],\n",
      "         [-0.0828],\n",
      "         [ 0.0286],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0237],\n",
      "         [ 0.0270],\n",
      "         [-0.0038],\n",
      "         ...,\n",
      "         [-0.0949],\n",
      "         [-0.0417],\n",
      "         [-0.0659]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0391],\n",
      "         [-0.0926],\n",
      "         [-0.0866],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0125],\n",
      "         [-0.0916],\n",
      "         [ 0.0208],\n",
      "         ...,\n",
      "         [-0.0151],\n",
      "         [-0.0151],\n",
      "         [-0.0151]],\n",
      "\n",
      "        [[ 0.0354],\n",
      "         [ 0.0398],\n",
      "         [ 0.0074],\n",
      "         ...,\n",
      "         [-0.0861],\n",
      "         [-0.0282],\n",
      "         [-0.0562]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0394],\n",
      "         [-0.0929],\n",
      "         [-0.0869],\n",
      "         ...,\n",
      "         [-0.0422],\n",
      "         [-0.0422],\n",
      "         [-0.0422]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0125],\n",
      "         [-0.0916],\n",
      "         [ 0.0208],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0354],\n",
      "         [ 0.0398],\n",
      "         [ 0.0074],\n",
      "         ...,\n",
      "         [-0.0861],\n",
      "         [-0.0282],\n",
      "         [-0.0562]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0394],\n",
      "         [-0.0929],\n",
      "         [-0.0869],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [-0.0964],\n",
      "         [ 0.0166],\n",
      "         ...,\n",
      "         [-0.0203],\n",
      "         [-0.0203],\n",
      "         [-0.0203]],\n",
      "\n",
      "        [[-0.0078],\n",
      "         [-0.0048],\n",
      "         [-0.0370],\n",
      "         ...,\n",
      "         [-0.1237],\n",
      "         [-0.0648],\n",
      "         [-0.0961]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0395],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0424],\n",
      "         [-0.0424],\n",
      "         [-0.0424]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [-0.0964],\n",
      "         [ 0.0166],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0078],\n",
      "         [-0.0048],\n",
      "         [-0.0370],\n",
      "         ...,\n",
      "         [-0.1237],\n",
      "         [-0.0648],\n",
      "         [-0.0961]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0395],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0199],\n",
      "         [-0.0990],\n",
      "         [ 0.0143],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        [[ 0.1678],\n",
      "         [ 0.1743],\n",
      "         [ 0.1422],\n",
      "         ...,\n",
      "         [ 0.0412],\n",
      "         [ 0.0955],\n",
      "         [ 0.0739]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0424],\n",
      "         [-0.0424],\n",
      "         [-0.0424]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0199],\n",
      "         [-0.0990],\n",
      "         [ 0.0143],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1678],\n",
      "         [ 0.1743],\n",
      "         [ 0.1422],\n",
      "         ...,\n",
      "         [ 0.0412],\n",
      "         [ 0.0955],\n",
      "         [ 0.0739]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0213],\n",
      "         [-0.1004],\n",
      "         [ 0.0131],\n",
      "         ...,\n",
      "         [-0.0245],\n",
      "         [-0.0245],\n",
      "         [-0.0245]],\n",
      "\n",
      "        [[ 0.0761],\n",
      "         [ 0.0809],\n",
      "         [ 0.0489],\n",
      "         ...,\n",
      "         [-0.0464],\n",
      "         [ 0.0088],\n",
      "         [-0.0159]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0932],\n",
      "         [-0.0872],\n",
      "         ...,\n",
      "         [-0.0424],\n",
      "         [-0.0424],\n",
      "         [-0.0424]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0213],\n",
      "         [-0.1004],\n",
      "         [ 0.0131],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0761],\n",
      "         [ 0.0809],\n",
      "         [ 0.0489],\n",
      "         ...,\n",
      "         [-0.0464],\n",
      "         [ 0.0088],\n",
      "         [-0.0159]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0932],\n",
      "         [-0.0872],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0220],\n",
      "         [-0.1011],\n",
      "         [ 0.0125],\n",
      "         ...,\n",
      "         [-0.0253],\n",
      "         [-0.0253],\n",
      "         [-0.0253]],\n",
      "\n",
      "        [[ 0.0919],\n",
      "         [ 0.0967],\n",
      "         [ 0.0647],\n",
      "         ...,\n",
      "         [-0.0321],\n",
      "         [ 0.0239],\n",
      "         [-0.0010]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0932],\n",
      "         [-0.0872],\n",
      "         ...,\n",
      "         [-0.0424],\n",
      "         [-0.0424],\n",
      "         [-0.0424]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0220],\n",
      "         [-0.1011],\n",
      "         [ 0.0125],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0919],\n",
      "         [ 0.0967],\n",
      "         [ 0.0647],\n",
      "         ...,\n",
      "         [-0.0321],\n",
      "         [ 0.0239],\n",
      "         [-0.0010]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0932],\n",
      "         [-0.0872],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0224],\n",
      "         [-0.1015],\n",
      "         [ 0.0121],\n",
      "         ...,\n",
      "         [-0.0257],\n",
      "         [-0.0257],\n",
      "         [-0.0257]],\n",
      "\n",
      "        [[ 0.1560],\n",
      "         [ 0.1616],\n",
      "         [ 0.1296],\n",
      "         ...,\n",
      "         [ 0.0283],\n",
      "         [ 0.0841],\n",
      "         [ 0.0612]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0932],\n",
      "         [-0.0872],\n",
      "         ...,\n",
      "         [-0.0424],\n",
      "         [-0.0424],\n",
      "         [-0.0424]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0224],\n",
      "         [-0.1015],\n",
      "         [ 0.0121],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1560],\n",
      "         [ 0.1616],\n",
      "         [ 0.1296],\n",
      "         ...,\n",
      "         [ 0.0283],\n",
      "         [ 0.0841],\n",
      "         [ 0.0612]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0932],\n",
      "         [-0.0872],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0225],\n",
      "         [-0.1017],\n",
      "         [ 0.0119],\n",
      "         ...,\n",
      "         [-0.0259],\n",
      "         [-0.0259],\n",
      "         [-0.0259]],\n",
      "\n",
      "        [[ 0.0784],\n",
      "         [ 0.0826],\n",
      "         [ 0.0509],\n",
      "         ...,\n",
      "         [-0.0440],\n",
      "         [ 0.0114],\n",
      "         [-0.0136]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0932],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0424],\n",
      "         [-0.0424],\n",
      "         [-0.0424]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0225],\n",
      "         [-0.1017],\n",
      "         [ 0.0119],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0784],\n",
      "         [ 0.0826],\n",
      "         [ 0.0509],\n",
      "         ...,\n",
      "         [-0.0440],\n",
      "         [ 0.0114],\n",
      "         [-0.0136]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0932],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0226],\n",
      "         [-0.1018],\n",
      "         [ 0.0119],\n",
      "         ...,\n",
      "         [-0.0260],\n",
      "         [-0.0260],\n",
      "         [-0.0260]],\n",
      "\n",
      "        [[-0.0553],\n",
      "         [-0.0534],\n",
      "         [-0.0843],\n",
      "         ...,\n",
      "         [-0.1694],\n",
      "         [-0.1136],\n",
      "         [-0.1422]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0424],\n",
      "         [-0.0424],\n",
      "         [-0.0424]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0226],\n",
      "         [-0.1018],\n",
      "         [ 0.0119],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0553],\n",
      "         [-0.0534],\n",
      "         [-0.0843],\n",
      "         ...,\n",
      "         [-0.1694],\n",
      "         [-0.1136],\n",
      "         [-0.1422]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0227],\n",
      "         [-0.1019],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [-0.0260],\n",
      "         [-0.0260],\n",
      "         [-0.0260]],\n",
      "\n",
      "        [[ 0.0686],\n",
      "         [ 0.0738],\n",
      "         [ 0.0419],\n",
      "         ...,\n",
      "         [-0.0548],\n",
      "         [ 0.0004],\n",
      "         [-0.0238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0423],\n",
      "         [-0.0423],\n",
      "         [-0.0423]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0227],\n",
      "         [-0.1019],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0686],\n",
      "         [ 0.0738],\n",
      "         [ 0.0419],\n",
      "         ...,\n",
      "         [-0.0548],\n",
      "         [ 0.0004],\n",
      "         [-0.0238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0227],\n",
      "         [-0.1019],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [-0.0260],\n",
      "         [-0.0260],\n",
      "         [-0.0260]],\n",
      "\n",
      "        [[ 0.0504],\n",
      "         [ 0.0552],\n",
      "         [ 0.0241],\n",
      "         ...,\n",
      "         [-0.0729],\n",
      "         [-0.0203],\n",
      "         [-0.0419]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0423],\n",
      "         [-0.0423],\n",
      "         [-0.0423]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0227],\n",
      "         [-0.1019],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0504],\n",
      "         [ 0.0552],\n",
      "         [ 0.0241],\n",
      "         ...,\n",
      "         [-0.0729],\n",
      "         [-0.0203],\n",
      "         [-0.0419]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        [[-0.0227],\n",
      "         [-0.1019],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [-0.0261],\n",
      "         [-0.0261],\n",
      "         [-0.0261]],\n",
      "\n",
      "        [[ 0.0642],\n",
      "         [ 0.0693],\n",
      "         [ 0.0383],\n",
      "         ...,\n",
      "         [-0.0595],\n",
      "         [-0.0079],\n",
      "         [-0.0282]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0439],\n",
      "         [-0.0439]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [-0.0110],\n",
      "         [-0.0110],\n",
      "         [-0.0110]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [-0.0423],\n",
      "         [-0.0423],\n",
      "         [-0.0423]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0179],\n",
      "         [ 0.0064],\n",
      "         [-0.0094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0227],\n",
      "         [-0.1019],\n",
      "         [ 0.0118],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0642],\n",
      "         [ 0.0693],\n",
      "         [ 0.0383],\n",
      "         ...,\n",
      "         [-0.0595],\n",
      "         [-0.0079],\n",
      "         [-0.0282]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0412],\n",
      "         [ 0.0128],\n",
      "         [-0.1094],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0091],\n",
      "         [ 0.0162],\n",
      "         [ 0.0622],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0396],\n",
      "         [-0.0931],\n",
      "         [-0.0871],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/25000 [00:03<4:01:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот в AttentiveModel сделали mask. Она выглядит так:\n",
      "torch.BoolTensor\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1956],\n",
      "         [0.2402],\n",
      "         [0.2441],\n",
      "         ...,\n",
      "         [0.1971],\n",
      "         [0.1971],\n",
      "         [0.1971]],\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.1299],\n",
      "         [0.1940],\n",
      "         ...,\n",
      "         [0.1971],\n",
      "         [0.1971],\n",
      "         [0.1971]],\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.2193],\n",
      "         [0.1872],\n",
      "         ...,\n",
      "         [0.1917],\n",
      "         [0.1934],\n",
      "         [0.1946]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.1202],\n",
      "         [0.2440],\n",
      "         ...,\n",
      "         [0.1971],\n",
      "         [0.1971],\n",
      "         [0.1971]],\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.2193],\n",
      "         [0.1701],\n",
      "         ...,\n",
      "         [0.1971],\n",
      "         [0.1971],\n",
      "         [0.1971]],\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.2193],\n",
      "         [0.1148],\n",
      "         ...,\n",
      "         [0.1971],\n",
      "         [0.1971],\n",
      "         [0.1971]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1956],\n",
      "         [0.2402],\n",
      "         [0.2441],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.1299],\n",
      "         [0.1940],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.2193],\n",
      "         [0.1872],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.1202],\n",
      "         [0.2440],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.2193],\n",
      "         [0.1701],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1956],\n",
      "         [0.2193],\n",
      "         [0.1148],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1342],\n",
      "         [0.1791],\n",
      "         [0.1815],\n",
      "         ...,\n",
      "         [0.1361],\n",
      "         [0.1361],\n",
      "         [0.1361]],\n",
      "\n",
      "        [[0.1214],\n",
      "         [0.0545],\n",
      "         [0.1200],\n",
      "         ...,\n",
      "         [0.1237],\n",
      "         [0.1237],\n",
      "         [0.1237]],\n",
      "\n",
      "        [[0.1252],\n",
      "         [0.1480],\n",
      "         [0.1152],\n",
      "         ...,\n",
      "         [0.1219],\n",
      "         [0.1237],\n",
      "         [0.1249]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1271],\n",
      "         [0.0517],\n",
      "         [0.1767],\n",
      "         ...,\n",
      "         [0.1293],\n",
      "         [0.1293],\n",
      "         [0.1293]],\n",
      "\n",
      "        [[0.1384],\n",
      "         [0.1622],\n",
      "         [0.1116],\n",
      "         ...,\n",
      "         [0.1404],\n",
      "         [0.1405],\n",
      "         [0.1405]],\n",
      "\n",
      "        [[0.1196],\n",
      "         [0.1432],\n",
      "         [0.0379],\n",
      "         ...,\n",
      "         [0.1215],\n",
      "         [0.1215],\n",
      "         [0.1215]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1342],\n",
      "         [0.1791],\n",
      "         [0.1815],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1214],\n",
      "         [0.0545],\n",
      "         [0.1200],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1252],\n",
      "         [0.1480],\n",
      "         [0.1152],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1271],\n",
      "         [0.0517],\n",
      "         [0.1767],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1384],\n",
      "         [0.1622],\n",
      "         [0.1116],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1196],\n",
      "         [0.1432],\n",
      "         [0.0379],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1477],\n",
      "         [ 0.1937],\n",
      "         [ 0.1948],\n",
      "         ...,\n",
      "         [ 0.1487],\n",
      "         [ 0.1487],\n",
      "         [ 0.1487]],\n",
      "\n",
      "        [[ 0.1368],\n",
      "         [ 0.0699],\n",
      "         [ 0.1362],\n",
      "         ...,\n",
      "         [ 0.1402],\n",
      "         [ 0.1402],\n",
      "         [ 0.1402]],\n",
      "\n",
      "        [[ 0.1221],\n",
      "         [ 0.1453],\n",
      "         [ 0.1122],\n",
      "         ...,\n",
      "         [ 0.1190],\n",
      "         [ 0.1208],\n",
      "         [ 0.1221]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1309],\n",
      "         [ 0.0565],\n",
      "         [ 0.1762],\n",
      "         ...,\n",
      "         [ 0.1358],\n",
      "         [ 0.1358],\n",
      "         [ 0.1358]],\n",
      "\n",
      "        [[ 0.0604],\n",
      "         [ 0.0844],\n",
      "         [ 0.0324],\n",
      "         ...,\n",
      "         [ 0.0619],\n",
      "         [ 0.0619],\n",
      "         [ 0.0620]],\n",
      "\n",
      "        [[ 0.0719],\n",
      "         [ 0.0969],\n",
      "         [-0.0086],\n",
      "         ...,\n",
      "         [ 0.0717],\n",
      "         [ 0.0717],\n",
      "         [ 0.0717]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1477],\n",
      "         [ 0.1937],\n",
      "         [ 0.1948],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1368],\n",
      "         [ 0.0699],\n",
      "         [ 0.1362],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1221],\n",
      "         [ 0.1453],\n",
      "         [ 0.1122],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1309],\n",
      "         [ 0.0565],\n",
      "         [ 0.1762],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0604],\n",
      "         [ 0.0844],\n",
      "         [ 0.0324],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0719],\n",
      "         [ 0.0969],\n",
      "         [-0.0086],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0508],\n",
      "         [ 0.0983],\n",
      "         [ 0.0978],\n",
      "         ...,\n",
      "         [ 0.0482],\n",
      "         [ 0.0482],\n",
      "         [ 0.0482]],\n",
      "\n",
      "        [[ 0.1126],\n",
      "         [ 0.0462],\n",
      "         [ 0.1109],\n",
      "         ...,\n",
      "         [ 0.1167],\n",
      "         [ 0.1167],\n",
      "         [ 0.1167]],\n",
      "\n",
      "        [[ 0.1063],\n",
      "         [ 0.1294],\n",
      "         [ 0.0962],\n",
      "         ...,\n",
      "         [ 0.1031],\n",
      "         [ 0.1049],\n",
      "         [ 0.1062]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1318],\n",
      "         [ 0.0600],\n",
      "         [ 0.1842],\n",
      "         ...,\n",
      "         [ 0.1330],\n",
      "         [ 0.1330],\n",
      "         [ 0.1330]],\n",
      "\n",
      "        [[-0.0198],\n",
      "         [ 0.0071],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0192],\n",
      "         [-0.0192],\n",
      "         [-0.0192]],\n",
      "\n",
      "        [[ 0.0006],\n",
      "         [ 0.0262],\n",
      "         [-0.0787],\n",
      "         ...,\n",
      "         [-0.0019],\n",
      "         [-0.0019],\n",
      "         [-0.0019]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0508],\n",
      "         [ 0.0983],\n",
      "         [ 0.0978],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1126],\n",
      "         [ 0.0462],\n",
      "         [ 0.1109],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1063],\n",
      "         [ 0.1294],\n",
      "         [ 0.0962],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1318],\n",
      "         [ 0.0600],\n",
      "         [ 0.1842],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0198],\n",
      "         [ 0.0071],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0006],\n",
      "         [ 0.0262],\n",
      "         [-0.0787],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0556],\n",
      "         [ 0.1025],\n",
      "         [ 0.1019],\n",
      "         ...,\n",
      "         [ 0.0528],\n",
      "         [ 0.0528],\n",
      "         [ 0.0528]],\n",
      "\n",
      "        [[ 0.0156],\n",
      "         [-0.0489],\n",
      "         [ 0.0173],\n",
      "         ...,\n",
      "         [ 0.0150],\n",
      "         [ 0.0150],\n",
      "         [ 0.0150]],\n",
      "\n",
      "        [[ 0.0358],\n",
      "         [ 0.0589],\n",
      "         [ 0.0256],\n",
      "         ...,\n",
      "         [ 0.0317],\n",
      "         [ 0.0334],\n",
      "         [ 0.0346]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0753],\n",
      "         [ 0.0037],\n",
      "         [ 0.1273],\n",
      "         ...,\n",
      "         [ 0.0762],\n",
      "         [ 0.0762],\n",
      "         [ 0.0762]],\n",
      "\n",
      "        [[ 0.0624],\n",
      "         [ 0.0862],\n",
      "         [ 0.0359],\n",
      "         ...,\n",
      "         [ 0.0660],\n",
      "         [ 0.0661],\n",
      "         [ 0.0661]],\n",
      "\n",
      "        [[-0.0259],\n",
      "         [ 0.0023],\n",
      "         [-0.1039],\n",
      "         ...,\n",
      "         [-0.0322],\n",
      "         [-0.0322],\n",
      "         [-0.0322]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0556],\n",
      "         [ 0.1025],\n",
      "         [ 0.1019],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0156],\n",
      "         [-0.0489],\n",
      "         [ 0.0173],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0358],\n",
      "         [ 0.0589],\n",
      "         [ 0.0256],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0753],\n",
      "         [ 0.0037],\n",
      "         [ 0.1273],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0624],\n",
      "         [ 0.0862],\n",
      "         [ 0.0359],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0259],\n",
      "         [ 0.0023],\n",
      "         [-0.1039],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 1.6870e-01],\n",
      "         [ 2.1277e-01],\n",
      "         [ 2.1614e-01],\n",
      "         ...,\n",
      "         [ 1.7278e-01],\n",
      "         [ 1.7279e-01],\n",
      "         [ 1.7279e-01]],\n",
      "\n",
      "        [[ 4.0765e-02],\n",
      "         [-2.3900e-02],\n",
      "         [ 4.4621e-02],\n",
      "         ...,\n",
      "         [ 3.7757e-02],\n",
      "         [ 3.7758e-02],\n",
      "         [ 3.7759e-02]],\n",
      "\n",
      "        [[ 7.7145e-02],\n",
      "         [ 9.7486e-02],\n",
      "         [ 6.5151e-02],\n",
      "         ...,\n",
      "         [ 7.6069e-02],\n",
      "         [ 7.7818e-02],\n",
      "         [ 7.9020e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.8671e-03],\n",
      "         [-7.2885e-02],\n",
      "         [ 5.4336e-02],\n",
      "         ...,\n",
      "         [-8.4937e-07],\n",
      "         [ 7.3016e-06],\n",
      "         [ 1.2890e-05]],\n",
      "\n",
      "        [[ 4.3531e-02],\n",
      "         [ 6.7100e-02],\n",
      "         [ 1.6359e-02],\n",
      "         ...,\n",
      "         [ 4.5529e-02],\n",
      "         [ 4.5549e-02],\n",
      "         [ 4.5564e-02]],\n",
      "\n",
      "        [[ 1.7189e-01],\n",
      "         [ 1.9524e-01],\n",
      "         [ 9.1951e-02],\n",
      "         ...,\n",
      "         [ 1.7657e-01],\n",
      "         [ 1.7657e-01],\n",
      "         [ 1.7657e-01]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1687],\n",
      "         [ 0.2128],\n",
      "         [ 0.2161],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0408],\n",
      "         [-0.0239],\n",
      "         [ 0.0446],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0771],\n",
      "         [ 0.0975],\n",
      "         [ 0.0652],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0019],\n",
      "         [-0.0729],\n",
      "         [ 0.0543],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0435],\n",
      "         [ 0.0671],\n",
      "         [ 0.0164],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1719],\n",
      "         [ 0.1952],\n",
      "         [ 0.0920],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0966],\n",
      "         [ 0.1420],\n",
      "         [ 0.1440],\n",
      "         ...,\n",
      "         [ 0.0991],\n",
      "         [ 0.0991],\n",
      "         [ 0.0991]],\n",
      "\n",
      "        [[-0.0124],\n",
      "         [-0.0771],\n",
      "         [-0.0106],\n",
      "         ...,\n",
      "         [-0.0142],\n",
      "         [-0.0142],\n",
      "         [-0.0142]],\n",
      "\n",
      "        [[-0.0591],\n",
      "         [-0.0361],\n",
      "         [-0.0684],\n",
      "         ...,\n",
      "         [-0.0599],\n",
      "         [-0.0582],\n",
      "         [-0.0570]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0253],\n",
      "         [-0.0476],\n",
      "         [ 0.0728],\n",
      "         ...,\n",
      "         [ 0.0323],\n",
      "         [ 0.0323],\n",
      "         [ 0.0323]],\n",
      "\n",
      "        [[ 0.0763],\n",
      "         [ 0.1013],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [ 0.0770],\n",
      "         [ 0.0770],\n",
      "         [ 0.0770]],\n",
      "\n",
      "        [[ 0.1368],\n",
      "         [ 0.1597],\n",
      "         [ 0.0549],\n",
      "         ...,\n",
      "         [ 0.1409],\n",
      "         [ 0.1409],\n",
      "         [ 0.1409]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0966],\n",
      "         [ 0.1420],\n",
      "         [ 0.1440],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0124],\n",
      "         [-0.0771],\n",
      "         [-0.0106],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0591],\n",
      "         [-0.0361],\n",
      "         [-0.0684],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0253],\n",
      "         [-0.0476],\n",
      "         [ 0.0728],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0763],\n",
      "         [ 0.1013],\n",
      "         [ 0.0483],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1368],\n",
      "         [ 0.1597],\n",
      "         [ 0.0549],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0550],\n",
      "         [-0.0084],\n",
      "         [-0.0090],\n",
      "         ...,\n",
      "         [-0.0517],\n",
      "         [-0.0517],\n",
      "         [-0.0517]],\n",
      "\n",
      "        [[ 0.0433],\n",
      "         [-0.0231],\n",
      "         [ 0.0444],\n",
      "         ...,\n",
      "         [ 0.0428],\n",
      "         [ 0.0428],\n",
      "         [ 0.0428]],\n",
      "\n",
      "        [[ 0.0833],\n",
      "         [ 0.0998],\n",
      "         [ 0.0698],\n",
      "         ...,\n",
      "         [ 0.0877],\n",
      "         [ 0.0894],\n",
      "         [ 0.0905]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0735],\n",
      "         [ 0.0032],\n",
      "         [ 0.1275],\n",
      "         ...,\n",
      "         [ 0.0751],\n",
      "         [ 0.0751],\n",
      "         [ 0.0751]],\n",
      "\n",
      "        [[ 0.0256],\n",
      "         [ 0.0492],\n",
      "         [-0.0022],\n",
      "         ...,\n",
      "         [ 0.0266],\n",
      "         [ 0.0266],\n",
      "         [ 0.0266]],\n",
      "\n",
      "        [[ 0.1191],\n",
      "         [ 0.1411],\n",
      "         [ 0.0376],\n",
      "         ...,\n",
      "         [ 0.1231],\n",
      "         [ 0.1231],\n",
      "         [ 0.1231]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0550],\n",
      "         [-0.0084],\n",
      "         [-0.0090],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0433],\n",
      "         [-0.0231],\n",
      "         [ 0.0444],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0833],\n",
      "         [ 0.0998],\n",
      "         [ 0.0698],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0735],\n",
      "         [ 0.0032],\n",
      "         [ 0.1275],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0256],\n",
      "         [ 0.0492],\n",
      "         [-0.0022],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1191],\n",
      "         [ 0.1411],\n",
      "         [ 0.0376],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0719],\n",
      "         [ 0.1181],\n",
      "         [ 0.1201],\n",
      "         ...,\n",
      "         [ 0.0751],\n",
      "         [ 0.0751],\n",
      "         [ 0.0751]],\n",
      "\n",
      "        [[ 0.0857],\n",
      "         [ 0.0182],\n",
      "         [ 0.0852],\n",
      "         ...,\n",
      "         [ 0.0876],\n",
      "         [ 0.0876],\n",
      "         [ 0.0876]],\n",
      "\n",
      "        [[ 0.1163],\n",
      "         [ 0.1365],\n",
      "         [ 0.1042],\n",
      "         ...,\n",
      "         [ 0.1168],\n",
      "         [ 0.1186],\n",
      "         [ 0.1198]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0237],\n",
      "         [-0.0464],\n",
      "         [ 0.0783],\n",
      "         ...,\n",
      "         [ 0.0249],\n",
      "         [ 0.0249],\n",
      "         [ 0.0249]],\n",
      "\n",
      "        [[ 0.0730],\n",
      "         [ 0.0995],\n",
      "         [ 0.0431],\n",
      "         ...,\n",
      "         [ 0.0713],\n",
      "         [ 0.0713],\n",
      "         [ 0.0713]],\n",
      "\n",
      "        [[ 0.1639],\n",
      "         [ 0.1873],\n",
      "         [ 0.0817],\n",
      "         ...,\n",
      "         [ 0.1680],\n",
      "         [ 0.1680],\n",
      "         [ 0.1680]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0719],\n",
      "         [ 0.1181],\n",
      "         [ 0.1201],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0857],\n",
      "         [ 0.0182],\n",
      "         [ 0.0852],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1163],\n",
      "         [ 0.1365],\n",
      "         [ 0.1042],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0237],\n",
      "         [-0.0464],\n",
      "         [ 0.0783],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0730],\n",
      "         [ 0.0995],\n",
      "         [ 0.0431],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1639],\n",
      "         [ 0.1873],\n",
      "         [ 0.0817],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1650],\n",
      "         [ 0.2094],\n",
      "         [ 0.2132],\n",
      "         ...,\n",
      "         [ 0.1692],\n",
      "         [ 0.1692],\n",
      "         [ 0.1692]],\n",
      "\n",
      "        [[ 0.0745],\n",
      "         [ 0.0098],\n",
      "         [ 0.0722],\n",
      "         ...,\n",
      "         [ 0.0803],\n",
      "         [ 0.0803],\n",
      "         [ 0.0803]],\n",
      "\n",
      "        [[ 0.0167],\n",
      "         [ 0.0383],\n",
      "         [ 0.0055],\n",
      "         ...,\n",
      "         [ 0.0147],\n",
      "         [ 0.0164],\n",
      "         [ 0.0176]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0055],\n",
      "         [-0.0745],\n",
      "         [ 0.0505],\n",
      "         ...,\n",
      "         [-0.0076],\n",
      "         [-0.0076],\n",
      "         [-0.0076]],\n",
      "\n",
      "        [[ 0.1205],\n",
      "         [ 0.1491],\n",
      "         [ 0.0913],\n",
      "         ...,\n",
      "         [ 0.1188],\n",
      "         [ 0.1188],\n",
      "         [ 0.1188]],\n",
      "\n",
      "        [[ 0.0801],\n",
      "         [ 0.1061],\n",
      "         [-0.0017],\n",
      "         ...,\n",
      "         [ 0.0810],\n",
      "         [ 0.0810],\n",
      "         [ 0.0810]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1650],\n",
      "         [ 0.2094],\n",
      "         [ 0.2132],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0745],\n",
      "         [ 0.0098],\n",
      "         [ 0.0722],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0167],\n",
      "         [ 0.0383],\n",
      "         [ 0.0055],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0055],\n",
      "         [-0.0745],\n",
      "         [ 0.0505],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1205],\n",
      "         [ 0.1491],\n",
      "         [ 0.0913],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0801],\n",
      "         [ 0.1061],\n",
      "         [-0.0017],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1001],\n",
      "         [ 0.1447],\n",
      "         [ 0.1467],\n",
      "         ...,\n",
      "         [ 0.1022],\n",
      "         [ 0.1022],\n",
      "         [ 0.1022]],\n",
      "\n",
      "        [[ 0.0640],\n",
      "         [-0.0008],\n",
      "         [ 0.0621],\n",
      "         ...,\n",
      "         [ 0.0697],\n",
      "         [ 0.0697],\n",
      "         [ 0.0697]],\n",
      "\n",
      "        [[ 0.1054],\n",
      "         [ 0.1273],\n",
      "         [ 0.0943],\n",
      "         ...,\n",
      "         [ 0.1044],\n",
      "         [ 0.1062],\n",
      "         [ 0.1074]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0084],\n",
      "         [-0.0614],\n",
      "         [ 0.0670],\n",
      "         ...,\n",
      "         [ 0.0073],\n",
      "         [ 0.0073],\n",
      "         [ 0.0073]],\n",
      "\n",
      "        [[ 0.0638],\n",
      "         [ 0.0917],\n",
      "         [ 0.0335],\n",
      "         ...,\n",
      "         [ 0.0623],\n",
      "         [ 0.0623],\n",
      "         [ 0.0623]],\n",
      "\n",
      "        [[-0.0308],\n",
      "         [-0.0042],\n",
      "         [-0.1100],\n",
      "         ...,\n",
      "         [-0.0330],\n",
      "         [-0.0330],\n",
      "         [-0.0330]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1001],\n",
      "         [ 0.1447],\n",
      "         [ 0.1467],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0640],\n",
      "         [-0.0008],\n",
      "         [ 0.0621],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1054],\n",
      "         [ 0.1273],\n",
      "         [ 0.0943],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0084],\n",
      "         [-0.0614],\n",
      "         [ 0.0670],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0638],\n",
      "         [ 0.0917],\n",
      "         [ 0.0335],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0308],\n",
      "         [-0.0042],\n",
      "         [-0.1100],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0772],\n",
      "         [ 0.1225],\n",
      "         [ 0.1243],\n",
      "         ...,\n",
      "         [ 0.0790],\n",
      "         [ 0.0790],\n",
      "         [ 0.0790]],\n",
      "\n",
      "        [[ 0.0213],\n",
      "         [-0.0441],\n",
      "         [ 0.0211],\n",
      "         ...,\n",
      "         [ 0.0233],\n",
      "         [ 0.0233],\n",
      "         [ 0.0233]],\n",
      "\n",
      "        [[ 0.1602],\n",
      "         [ 0.1820],\n",
      "         [ 0.1493],\n",
      "         ...,\n",
      "         [ 0.1596],\n",
      "         [ 0.1614],\n",
      "         [ 0.1626]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0206],\n",
      "         [-0.0476],\n",
      "         [ 0.0799],\n",
      "         ...,\n",
      "         [ 0.0168],\n",
      "         [ 0.0168],\n",
      "         [ 0.0168]],\n",
      "\n",
      "        [[ 0.0564],\n",
      "         [ 0.0836],\n",
      "         [ 0.0255],\n",
      "         ...,\n",
      "         [ 0.0538],\n",
      "         [ 0.0538],\n",
      "         [ 0.0539]],\n",
      "\n",
      "        [[ 0.0047],\n",
      "         [ 0.0285],\n",
      "         [-0.0755],\n",
      "         ...,\n",
      "         [ 0.0068],\n",
      "         [ 0.0068],\n",
      "         [ 0.0068]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0772],\n",
      "         [ 0.1225],\n",
      "         [ 0.1243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0213],\n",
      "         [-0.0441],\n",
      "         [ 0.0211],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1602],\n",
      "         [ 0.1820],\n",
      "         [ 0.1493],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0206],\n",
      "         [-0.0476],\n",
      "         [ 0.0799],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0564],\n",
      "         [ 0.0836],\n",
      "         [ 0.0255],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0047],\n",
      "         [ 0.0285],\n",
      "         [-0.0755],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0326],\n",
      "         [ 0.0783],\n",
      "         [ 0.0783],\n",
      "         ...,\n",
      "         [ 0.0317],\n",
      "         [ 0.0317],\n",
      "         [ 0.0317]],\n",
      "\n",
      "        [[-0.0050],\n",
      "         [-0.0701],\n",
      "         [-0.0033],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [-0.0059],\n",
      "         [-0.0059]],\n",
      "\n",
      "        [[ 0.1048],\n",
      "         [ 0.1265],\n",
      "         [ 0.0939],\n",
      "         ...,\n",
      "         [ 0.1042],\n",
      "         [ 0.1060],\n",
      "         [ 0.1072]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0237],\n",
      "         [-0.0908],\n",
      "         [ 0.0346],\n",
      "         ...,\n",
      "         [-0.0282],\n",
      "         [-0.0282],\n",
      "         [-0.0281]],\n",
      "\n",
      "        [[-0.0227],\n",
      "         [ 0.0052],\n",
      "         [-0.0544],\n",
      "         ...,\n",
      "         [-0.0261],\n",
      "         [-0.0261],\n",
      "         [-0.0261]],\n",
      "\n",
      "        [[-0.0215],\n",
      "         [ 0.0036],\n",
      "         [-0.1010],\n",
      "         ...,\n",
      "         [-0.0228],\n",
      "         [-0.0228],\n",
      "         [-0.0228]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0326],\n",
      "         [ 0.0783],\n",
      "         [ 0.0783],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0050],\n",
      "         [-0.0701],\n",
      "         [-0.0033],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1048],\n",
      "         [ 0.1265],\n",
      "         [ 0.0939],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0237],\n",
      "         [-0.0908],\n",
      "         [ 0.0346],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0227],\n",
      "         [ 0.0052],\n",
      "         [-0.0544],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0215],\n",
      "         [ 0.0036],\n",
      "         [-0.1010],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0065],\n",
      "         [ 0.0532],\n",
      "         [ 0.0519],\n",
      "         ...,\n",
      "         [ 0.0034],\n",
      "         [ 0.0034],\n",
      "         [ 0.0034]],\n",
      "\n",
      "        [[-0.0207],\n",
      "         [-0.0854],\n",
      "         [-0.0177],\n",
      "         ...,\n",
      "         [-0.0235],\n",
      "         [-0.0235],\n",
      "         [-0.0235]],\n",
      "\n",
      "        [[ 0.1103],\n",
      "         [ 0.1288],\n",
      "         [ 0.0976],\n",
      "         ...,\n",
      "         [ 0.1120],\n",
      "         [ 0.1137],\n",
      "         [ 0.1149]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0218],\n",
      "         [-0.0490],\n",
      "         [ 0.0753],\n",
      "         ...,\n",
      "         [ 0.0223],\n",
      "         [ 0.0223],\n",
      "         [ 0.0223]],\n",
      "\n",
      "        [[ 0.0283],\n",
      "         [ 0.0523],\n",
      "         [ 0.0007],\n",
      "         ...,\n",
      "         [ 0.0308],\n",
      "         [ 0.0309],\n",
      "         [ 0.0309]],\n",
      "\n",
      "        [[-0.0344],\n",
      "         [-0.0082],\n",
      "         [-0.1135],\n",
      "         ...,\n",
      "         [-0.0380],\n",
      "         [-0.0380],\n",
      "         [-0.0380]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0065],\n",
      "         [ 0.0532],\n",
      "         [ 0.0519],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0207],\n",
      "         [-0.0854],\n",
      "         [-0.0177],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1103],\n",
      "         [ 0.1288],\n",
      "         [ 0.0976],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0218],\n",
      "         [-0.0490],\n",
      "         [ 0.0753],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0283],\n",
      "         [ 0.0523],\n",
      "         [ 0.0007],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0344],\n",
      "         [-0.0082],\n",
      "         [-0.1135],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0087],\n",
      "         [ 0.0386],\n",
      "         [ 0.0366],\n",
      "         ...,\n",
      "         [-0.0132],\n",
      "         [-0.0132],\n",
      "         [-0.0132]],\n",
      "\n",
      "        [[-0.0300],\n",
      "         [-0.0945],\n",
      "         [-0.0262],\n",
      "         ...,\n",
      "         [-0.0339],\n",
      "         [-0.0338],\n",
      "         [-0.0338]],\n",
      "\n",
      "        [[-0.0209],\n",
      "         [-0.0004],\n",
      "         [-0.0320],\n",
      "         ...,\n",
      "         [-0.0210],\n",
      "         [-0.0193],\n",
      "         [-0.0182]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0011],\n",
      "         [-0.0713],\n",
      "         [ 0.0549],\n",
      "         ...,\n",
      "         [-0.0029],\n",
      "         [-0.0029],\n",
      "         [-0.0029]],\n",
      "\n",
      "        [[ 0.0061],\n",
      "         [ 0.0309],\n",
      "         [-0.0233],\n",
      "         ...,\n",
      "         [ 0.0061],\n",
      "         [ 0.0061],\n",
      "         [ 0.0061]],\n",
      "\n",
      "        [[-0.0417],\n",
      "         [-0.0148],\n",
      "         [-0.1204],\n",
      "         ...,\n",
      "         [-0.0466],\n",
      "         [-0.0466],\n",
      "         [-0.0466]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0087],\n",
      "         [ 0.0386],\n",
      "         [ 0.0366],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0300],\n",
      "         [-0.0945],\n",
      "         [-0.0262],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0209],\n",
      "         [-0.0004],\n",
      "         [-0.0320],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0011],\n",
      "         [-0.0713],\n",
      "         [ 0.0549],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0061],\n",
      "         [ 0.0309],\n",
      "         [-0.0233],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0417],\n",
      "         [-0.0148],\n",
      "         [-0.1204],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0176],\n",
      "         [ 0.0301],\n",
      "         [ 0.0276],\n",
      "         ...,\n",
      "         [-0.0230],\n",
      "         [-0.0230],\n",
      "         [-0.0230]],\n",
      "\n",
      "        [[-0.0355],\n",
      "         [-0.0999],\n",
      "         [-0.0313],\n",
      "         ...,\n",
      "         [-0.0399],\n",
      "         [-0.0399],\n",
      "         [-0.0399]],\n",
      "\n",
      "        [[ 0.0213],\n",
      "         [ 0.0473],\n",
      "         [ 0.0137],\n",
      "         ...,\n",
      "         [ 0.0139],\n",
      "         [ 0.0156],\n",
      "         [ 0.0168]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0156],\n",
      "         [-0.0850],\n",
      "         [ 0.0424],\n",
      "         ...,\n",
      "         [-0.0192],\n",
      "         [-0.0192],\n",
      "         [-0.0192]],\n",
      "\n",
      "        [[-0.0044],\n",
      "         [ 0.0213],\n",
      "         [-0.0349],\n",
      "         ...,\n",
      "         [-0.0062],\n",
      "         [-0.0061],\n",
      "         [-0.0061]],\n",
      "\n",
      "        [[-0.0460],\n",
      "         [-0.0187],\n",
      "         [-0.1246],\n",
      "         ...,\n",
      "         [-0.0517],\n",
      "         [-0.0517],\n",
      "         [-0.0517]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0176],\n",
      "         [ 0.0301],\n",
      "         [ 0.0276],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0355],\n",
      "         [-0.0999],\n",
      "         [-0.0313],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0213],\n",
      "         [ 0.0473],\n",
      "         [ 0.0137],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0156],\n",
      "         [-0.0850],\n",
      "         [ 0.0424],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0044],\n",
      "         [ 0.0213],\n",
      "         [-0.0349],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0460],\n",
      "         [-0.0187],\n",
      "         [-0.1246],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0228],\n",
      "         [ 0.0251],\n",
      "         [ 0.0224],\n",
      "         ...,\n",
      "         [-0.0286],\n",
      "         [-0.0286],\n",
      "         [-0.0286]],\n",
      "\n",
      "        [[-0.0387],\n",
      "         [-0.1030],\n",
      "         [-0.0342],\n",
      "         ...,\n",
      "         [-0.0435],\n",
      "         [-0.0435],\n",
      "         [-0.0435]],\n",
      "\n",
      "        [[ 0.0780],\n",
      "         [ 0.1047],\n",
      "         [ 0.0713],\n",
      "         ...,\n",
      "         [ 0.0699],\n",
      "         [ 0.0716],\n",
      "         [ 0.0728]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0244],\n",
      "         [-0.0934],\n",
      "         [ 0.0349],\n",
      "         ...,\n",
      "         [-0.0291],\n",
      "         [-0.0291],\n",
      "         [-0.0291]],\n",
      "\n",
      "        [[-0.0100],\n",
      "         [ 0.0162],\n",
      "         [-0.0412],\n",
      "         ...,\n",
      "         [-0.0128],\n",
      "         [-0.0128],\n",
      "         [-0.0128]],\n",
      "\n",
      "        [[-0.0486],\n",
      "         [-0.0211],\n",
      "         [-0.1271],\n",
      "         ...,\n",
      "         [-0.0547],\n",
      "         [-0.0547],\n",
      "         [-0.0547]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0228],\n",
      "         [ 0.0251],\n",
      "         [ 0.0224],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0387],\n",
      "         [-0.1030],\n",
      "         [-0.0342],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0780],\n",
      "         [ 0.1047],\n",
      "         [ 0.0713],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0244],\n",
      "         [-0.0934],\n",
      "         [ 0.0349],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0100],\n",
      "         [ 0.0162],\n",
      "         [-0.0412],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0486],\n",
      "         [-0.0211],\n",
      "         [-0.1271],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0258],\n",
      "         [ 0.0222],\n",
      "         [ 0.0194],\n",
      "         ...,\n",
      "         [-0.0319],\n",
      "         [-0.0319],\n",
      "         [-0.0319]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1048],\n",
      "         [-0.0360],\n",
      "         ...,\n",
      "         [-0.0455],\n",
      "         [-0.0455],\n",
      "         [-0.0455]],\n",
      "\n",
      "        [[ 0.0993],\n",
      "         [ 0.1255],\n",
      "         [ 0.0922],\n",
      "         ...,\n",
      "         [ 0.0926],\n",
      "         [ 0.0943],\n",
      "         [ 0.0955]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0296],\n",
      "         [-0.0983],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [-0.0349],\n",
      "         [-0.0349],\n",
      "         [-0.0349]],\n",
      "\n",
      "        [[-0.0133],\n",
      "         [ 0.0133],\n",
      "         [-0.0448],\n",
      "         ...,\n",
      "         [-0.0167],\n",
      "         [-0.0166],\n",
      "         [-0.0166]],\n",
      "\n",
      "        [[-0.0501],\n",
      "         [-0.0226],\n",
      "         [-0.1286],\n",
      "         ...,\n",
      "         [-0.0565],\n",
      "         [-0.0565],\n",
      "         [-0.0565]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0258],\n",
      "         [ 0.0222],\n",
      "         [ 0.0194],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0405],\n",
      "         [-0.1048],\n",
      "         [-0.0360],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0993],\n",
      "         [ 0.1255],\n",
      "         [ 0.0922],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0296],\n",
      "         [-0.0983],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0133],\n",
      "         [ 0.0133],\n",
      "         [-0.0448],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0501],\n",
      "         [-0.0226],\n",
      "         [-0.1286],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0275],\n",
      "         [ 0.0205],\n",
      "         [ 0.0176],\n",
      "         ...,\n",
      "         [-0.0338],\n",
      "         [-0.0338],\n",
      "         [-0.0338]],\n",
      "\n",
      "        [[-0.0416],\n",
      "         [-0.1059],\n",
      "         [-0.0370],\n",
      "         ...,\n",
      "         [-0.0467],\n",
      "         [-0.0467],\n",
      "         [-0.0467]],\n",
      "\n",
      "        [[ 0.0729],\n",
      "         [ 0.0986],\n",
      "         [ 0.0654],\n",
      "         ...,\n",
      "         [ 0.0655],\n",
      "         [ 0.0672],\n",
      "         [ 0.0684]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0327],\n",
      "         [-0.1013],\n",
      "         [ 0.0278],\n",
      "         ...,\n",
      "         [-0.0382],\n",
      "         [-0.0382],\n",
      "         [-0.0382]],\n",
      "\n",
      "        [[-0.0152],\n",
      "         [ 0.0115],\n",
      "         [-0.0469],\n",
      "         ...,\n",
      "         [-0.0189],\n",
      "         [-0.0188],\n",
      "         [-0.0188]],\n",
      "\n",
      "        [[-0.0511],\n",
      "         [-0.0234],\n",
      "         [-0.1295],\n",
      "         ...,\n",
      "         [-0.0575],\n",
      "         [-0.0575],\n",
      "         [-0.0575]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0275],\n",
      "         [ 0.0205],\n",
      "         [ 0.0176],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0416],\n",
      "         [-0.1059],\n",
      "         [-0.0370],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0729],\n",
      "         [ 0.0986],\n",
      "         [ 0.0654],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0327],\n",
      "         [-0.1013],\n",
      "         [ 0.0278],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0152],\n",
      "         [ 0.0115],\n",
      "         [-0.0469],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0511],\n",
      "         [-0.0234],\n",
      "         [-0.1295],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0286],\n",
      "         [ 0.0196],\n",
      "         [ 0.0166],\n",
      "         ...,\n",
      "         [-0.0348],\n",
      "         [-0.0348],\n",
      "         [-0.0348]],\n",
      "\n",
      "        [[-0.0423],\n",
      "         [-0.1065],\n",
      "         [-0.0376],\n",
      "         ...,\n",
      "         [-0.0474],\n",
      "         [-0.0474],\n",
      "         [-0.0474]],\n",
      "\n",
      "        [[ 0.1117],\n",
      "         [ 0.1342],\n",
      "         [ 0.1013],\n",
      "         ...,\n",
      "         [ 0.1098],\n",
      "         [ 0.1116],\n",
      "         [ 0.1128]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0344],\n",
      "         [-0.1030],\n",
      "         [ 0.0263],\n",
      "         ...,\n",
      "         [-0.0401],\n",
      "         [-0.0401],\n",
      "         [-0.0401]],\n",
      "\n",
      "        [[-0.0163],\n",
      "         [ 0.0105],\n",
      "         [-0.0481],\n",
      "         ...,\n",
      "         [-0.0201],\n",
      "         [-0.0201],\n",
      "         [-0.0201]],\n",
      "\n",
      "        [[-0.0516],\n",
      "         [-0.0240],\n",
      "         [-0.1301],\n",
      "         ...,\n",
      "         [-0.0582],\n",
      "         [-0.0582],\n",
      "         [-0.0582]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0286],\n",
      "         [ 0.0196],\n",
      "         [ 0.0166],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0423],\n",
      "         [-0.1065],\n",
      "         [-0.0376],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1117],\n",
      "         [ 0.1342],\n",
      "         [ 0.1013],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0344],\n",
      "         [-0.1030],\n",
      "         [ 0.0263],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0163],\n",
      "         [ 0.0105],\n",
      "         [-0.0481],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0516],\n",
      "         [-0.0240],\n",
      "         [-0.1301],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0291],\n",
      "         [ 0.0190],\n",
      "         [ 0.0160],\n",
      "         ...,\n",
      "         [-0.0355],\n",
      "         [-0.0355],\n",
      "         [-0.0355]],\n",
      "\n",
      "        [[-0.0427],\n",
      "         [-0.1069],\n",
      "         [-0.0380],\n",
      "         ...,\n",
      "         [-0.0478],\n",
      "         [-0.0478],\n",
      "         [-0.0478]],\n",
      "\n",
      "        [[ 0.0717],\n",
      "         [ 0.0927],\n",
      "         [ 0.0607],\n",
      "         ...,\n",
      "         [ 0.0715],\n",
      "         [ 0.0732],\n",
      "         [ 0.0744]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0354],\n",
      "         [-0.1039],\n",
      "         [ 0.0254],\n",
      "         ...,\n",
      "         [-0.0411],\n",
      "         [-0.0411],\n",
      "         [-0.0411]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [ 0.0100],\n",
      "         [-0.0487],\n",
      "         ...,\n",
      "         [-0.0208],\n",
      "         [-0.0207],\n",
      "         [-0.0207]],\n",
      "\n",
      "        [[-0.0519],\n",
      "         [-0.0243],\n",
      "         [-0.1304],\n",
      "         ...,\n",
      "         [-0.0585],\n",
      "         [-0.0585],\n",
      "         [-0.0585]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0291],\n",
      "         [ 0.0190],\n",
      "         [ 0.0160],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0427],\n",
      "         [-0.1069],\n",
      "         [-0.0380],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0717],\n",
      "         [ 0.0927],\n",
      "         [ 0.0607],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0354],\n",
      "         [-0.1039],\n",
      "         [ 0.0254],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [ 0.0100],\n",
      "         [-0.0487],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0519],\n",
      "         [-0.0243],\n",
      "         [-0.1304],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0295],\n",
      "         [ 0.0187],\n",
      "         [ 0.0157],\n",
      "         ...,\n",
      "         [-0.0358],\n",
      "         [-0.0358],\n",
      "         [-0.0358]],\n",
      "\n",
      "        [[-0.0429],\n",
      "         [-0.1071],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [-0.0480],\n",
      "         [-0.0480],\n",
      "         [-0.0480]],\n",
      "\n",
      "        [[ 0.1078],\n",
      "         [ 0.1322],\n",
      "         [ 0.0990],\n",
      "         ...,\n",
      "         [ 0.1044],\n",
      "         [ 0.1061],\n",
      "         [ 0.1074]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0359],\n",
      "         [-0.1045],\n",
      "         [ 0.0249],\n",
      "         ...,\n",
      "         [-0.0417],\n",
      "         [-0.0416],\n",
      "         [-0.0416]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0097],\n",
      "         [-0.0490],\n",
      "         ...,\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0521],\n",
      "         [-0.0244],\n",
      "         [-0.1306],\n",
      "         ...,\n",
      "         [-0.0587],\n",
      "         [-0.0587],\n",
      "         [-0.0587]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0295],\n",
      "         [ 0.0187],\n",
      "         [ 0.0157],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0429],\n",
      "         [-0.1071],\n",
      "         [-0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1078],\n",
      "         [ 0.1322],\n",
      "         [ 0.0990],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0359],\n",
      "         [-0.1045],\n",
      "         [ 0.0249],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0172],\n",
      "         [ 0.0097],\n",
      "         [-0.0490],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0521],\n",
      "         [-0.0244],\n",
      "         [-0.1306],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0297],\n",
      "         [ 0.0185],\n",
      "         [ 0.0155],\n",
      "         ...,\n",
      "         [-0.0360],\n",
      "         [-0.0360],\n",
      "         [-0.0360]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.1073],\n",
      "         [-0.0383],\n",
      "         ...,\n",
      "         [-0.0482],\n",
      "         [-0.0482],\n",
      "         [-0.0482]],\n",
      "\n",
      "        [[ 0.0819],\n",
      "         [ 0.1066],\n",
      "         [ 0.0734],\n",
      "         ...,\n",
      "         [ 0.0764],\n",
      "         [ 0.0782],\n",
      "         [ 0.0794]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0362],\n",
      "         [-0.1048],\n",
      "         [ 0.0246],\n",
      "         ...,\n",
      "         [-0.0419],\n",
      "         [-0.0419],\n",
      "         [-0.0419]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [-0.0213],\n",
      "         [-0.0212],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.0522],\n",
      "         [-0.0245],\n",
      "         [-0.1307],\n",
      "         ...,\n",
      "         [-0.0589],\n",
      "         [-0.0589],\n",
      "         [-0.0588]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0297],\n",
      "         [ 0.0185],\n",
      "         [ 0.0155],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0430],\n",
      "         [-0.1073],\n",
      "         [-0.0383],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0819],\n",
      "         [ 0.1066],\n",
      "         [ 0.0734],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0362],\n",
      "         [-0.1048],\n",
      "         [ 0.0246],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0522],\n",
      "         [-0.0245],\n",
      "         [-0.1307],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0298],\n",
      "         [ 0.0183],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [-0.0361],\n",
      "         [-0.0361],\n",
      "         [-0.0361]],\n",
      "\n",
      "        [[-0.0431],\n",
      "         [-0.1073],\n",
      "         [-0.0384],\n",
      "         ...,\n",
      "         [-0.0483],\n",
      "         [-0.0483],\n",
      "         [-0.0483]],\n",
      "\n",
      "        [[ 0.0469],\n",
      "         [ 0.0701],\n",
      "         [ 0.0370],\n",
      "         ...,\n",
      "         [ 0.0413],\n",
      "         [ 0.0430],\n",
      "         [ 0.0442]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0363],\n",
      "         [-0.1049],\n",
      "         [ 0.0245],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213]],\n",
      "\n",
      "        [[-0.0523],\n",
      "         [-0.0246],\n",
      "         [-0.1307],\n",
      "         ...,\n",
      "         [-0.0589],\n",
      "         [-0.0589],\n",
      "         [-0.0589]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0298],\n",
      "         [ 0.0183],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0431],\n",
      "         [-0.1073],\n",
      "         [-0.0384],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0469],\n",
      "         [ 0.0701],\n",
      "         [ 0.0370],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0363],\n",
      "         [-0.1049],\n",
      "         [ 0.0245],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0523],\n",
      "         [-0.0246],\n",
      "         [-0.1307],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0299],\n",
      "         [ 0.0183],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [-0.0362],\n",
      "         [-0.0362],\n",
      "         [-0.0362]],\n",
      "\n",
      "        [[-0.0432],\n",
      "         [-0.1074],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [-0.0483],\n",
      "         [-0.0483],\n",
      "         [-0.0483]],\n",
      "\n",
      "        [[ 0.0173],\n",
      "         [ 0.0416],\n",
      "         [ 0.0081],\n",
      "         ...,\n",
      "         [ 0.0109],\n",
      "         [ 0.0126],\n",
      "         [ 0.0138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1050],\n",
      "         [ 0.0244],\n",
      "         ...,\n",
      "         [-0.0421],\n",
      "         [-0.0421],\n",
      "         [-0.0421]],\n",
      "\n",
      "        [[-0.0175],\n",
      "         [ 0.0095],\n",
      "         [-0.0493],\n",
      "         ...,\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213]],\n",
      "\n",
      "        [[-0.0523],\n",
      "         [-0.0246],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0299],\n",
      "         [ 0.0183],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0432],\n",
      "         [-0.1074],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0173],\n",
      "         [ 0.0416],\n",
      "         [ 0.0081],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1050],\n",
      "         [ 0.0244],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0175],\n",
      "         [ 0.0095],\n",
      "         [-0.0493],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0523],\n",
      "         [-0.0246],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0299],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0362]],\n",
      "\n",
      "        [[-0.0432],\n",
      "         [-0.1074],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[ 0.0204],\n",
      "         [ 0.0463],\n",
      "         [ 0.0123],\n",
      "         ...,\n",
      "         [ 0.0147],\n",
      "         [ 0.0164],\n",
      "         [ 0.0177]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0244],\n",
      "         ...,\n",
      "         [-0.0421],\n",
      "         [-0.0421],\n",
      "         [-0.0421]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0213]],\n",
      "\n",
      "        [[-0.0523],\n",
      "         [-0.0246],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0299],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0432],\n",
      "         [-0.1074],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0204],\n",
      "         [ 0.0463],\n",
      "         [ 0.0123],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0244],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0523],\n",
      "         [-0.0246],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0299],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0432],\n",
      "         [-0.1074],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[ 0.0255],\n",
      "         [ 0.0520],\n",
      "         [ 0.0181],\n",
      "         ...,\n",
      "         [ 0.0171],\n",
      "         [ 0.0188],\n",
      "         [ 0.0200]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0421],\n",
      "         [-0.0421],\n",
      "         [-0.0421]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [-0.0213],\n",
      "         [-0.0213],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0299],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0432],\n",
      "         [-0.1074],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0255],\n",
      "         [ 0.0520],\n",
      "         [ 0.0181],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0432],\n",
      "         [-0.1075],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0281],\n",
      "         [-0.0040],\n",
      "         [-0.0374],\n",
      "         ...,\n",
      "         [-0.0342],\n",
      "         [-0.0325],\n",
      "         [-0.0313]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0421],\n",
      "         [-0.0421],\n",
      "         [-0.0421]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [-0.0213],\n",
      "         [-0.0212],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0432],\n",
      "         [-0.1075],\n",
      "         [-0.0385],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0281],\n",
      "         [-0.0040],\n",
      "         [-0.0374],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0933],\n",
      "         [-0.0684],\n",
      "         [-0.1018],\n",
      "         ...,\n",
      "         [-0.1005],\n",
      "         [-0.0988],\n",
      "         [-0.0977]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0421],\n",
      "         [-0.0421],\n",
      "         [-0.0421]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0933],\n",
      "         [-0.0684],\n",
      "         [-0.1018],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0011],\n",
      "         [ 0.0207],\n",
      "         [-0.0119],\n",
      "         ...,\n",
      "         [-0.0031],\n",
      "         [-0.0014],\n",
      "         [-0.0002]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0421],\n",
      "         [-0.0421],\n",
      "         [-0.0421]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0182],\n",
      "         [ 0.0152],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0011],\n",
      "         [ 0.0207],\n",
      "         [-0.0119],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0128],\n",
      "         [ 0.0108],\n",
      "         [-0.0226],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0166],\n",
      "         [-0.0154]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0421],\n",
      "         [-0.0421],\n",
      "         [-0.0421]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0212]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0128],\n",
      "         [ 0.0108],\n",
      "         [-0.0226],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0492],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0205],\n",
      "         [ 0.0043],\n",
      "         [-0.0294],\n",
      "         ...,\n",
      "         [-0.0281],\n",
      "         [-0.0265],\n",
      "         [-0.0253]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0421],\n",
      "         [-0.0421],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0212],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0205],\n",
      "         [ 0.0043],\n",
      "         [-0.0294],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-2.9991e-02],\n",
      "         [ 1.8141e-02],\n",
      "         [ 1.5142e-02],\n",
      "         ...,\n",
      "         [-3.6332e-02],\n",
      "         [-3.6325e-02],\n",
      "         [-3.6321e-02]],\n",
      "\n",
      "        [[-4.3269e-02],\n",
      "         [-1.0748e-01],\n",
      "         [-3.8573e-02],\n",
      "         ...,\n",
      "         [-4.8433e-02],\n",
      "         [-4.8432e-02],\n",
      "         [-4.8432e-02]],\n",
      "\n",
      "        [[-2.5553e-02],\n",
      "         [-8.8364e-05],\n",
      "         [-3.3886e-02],\n",
      "         ...,\n",
      "         [-3.4489e-02],\n",
      "         [-3.2814e-02],\n",
      "         [-3.1662e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6389e-02],\n",
      "         [-1.0508e-01],\n",
      "         [ 2.4336e-02],\n",
      "         ...,\n",
      "         [-4.2052e-02],\n",
      "         [-4.2045e-02],\n",
      "         [-4.2039e-02]],\n",
      "\n",
      "        [[-1.7364e-02],\n",
      "         [ 9.5260e-03],\n",
      "         [-4.9137e-02],\n",
      "         ...,\n",
      "         [-2.1174e-02],\n",
      "         [-2.1153e-02],\n",
      "         [-2.1139e-02]],\n",
      "\n",
      "        [[-5.2369e-02],\n",
      "         [-2.4673e-02],\n",
      "         [-1.3081e-01],\n",
      "         ...,\n",
      "         [-5.8996e-02],\n",
      "         [-5.8995e-02],\n",
      "         [-5.8994e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-2.9991e-02],\n",
      "         [ 1.8141e-02],\n",
      "         [ 1.5142e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-4.3269e-02],\n",
      "         [-1.0748e-01],\n",
      "         [-3.8573e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.5553e-02],\n",
      "         [-8.8364e-05],\n",
      "         [-3.3886e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6389e-02],\n",
      "         [-1.0508e-01],\n",
      "         [ 2.4336e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-1.7364e-02],\n",
      "         [ 9.5260e-03],\n",
      "         [-4.9137e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-5.2369e-02],\n",
      "         [-2.4673e-02],\n",
      "         [-1.3081e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0289],\n",
      "         [-0.0030],\n",
      "         [-0.0369],\n",
      "         ...,\n",
      "         [-0.0385],\n",
      "         [-0.0369],\n",
      "         [-0.0357]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0289],\n",
      "         [-0.0030],\n",
      "         [-0.0369],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0310],\n",
      "         [-0.0049],\n",
      "         [-0.0388],\n",
      "         ...,\n",
      "         [-0.0411],\n",
      "         [-0.0394],\n",
      "         [-0.0383]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0310],\n",
      "         [-0.0049],\n",
      "         [-0.0388],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0323],\n",
      "         [-0.0060],\n",
      "         [-0.0400],\n",
      "         ...,\n",
      "         [-0.0426],\n",
      "         [-0.0409],\n",
      "         [-0.0398]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0323],\n",
      "         [-0.0060],\n",
      "         [-0.0400],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0174],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0331],\n",
      "         [-0.0068],\n",
      "         [-0.0407],\n",
      "         ...,\n",
      "         [-0.0435],\n",
      "         [-0.0419],\n",
      "         [-0.0407]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0331],\n",
      "         [-0.0068],\n",
      "         [-0.0407],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0336],\n",
      "         [-0.0072],\n",
      "         [-0.0412],\n",
      "         ...,\n",
      "         [-0.0441],\n",
      "         [-0.0424],\n",
      "         [-0.0413]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0336],\n",
      "         [-0.0072],\n",
      "         [-0.0412],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0339],\n",
      "         [-0.0075],\n",
      "         [-0.0414],\n",
      "         ...,\n",
      "         [-0.0444],\n",
      "         [-0.0427],\n",
      "         [-0.0416]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0339],\n",
      "         [-0.0075],\n",
      "         [-0.0414],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0340],\n",
      "         [-0.0076],\n",
      "         [-0.0416],\n",
      "         ...,\n",
      "         [-0.0446],\n",
      "         [-0.0429],\n",
      "         [-0.0418]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0340],\n",
      "         [-0.0076],\n",
      "         [-0.0416],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0341],\n",
      "         [-0.0077],\n",
      "         [-0.0417],\n",
      "         ...,\n",
      "         [-0.0447],\n",
      "         [-0.0430],\n",
      "         [-0.0419]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0341],\n",
      "         [-0.0077],\n",
      "         [-0.0417],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [-0.0363],\n",
      "         [-0.0363],\n",
      "         [-0.0363]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [-0.0484],\n",
      "         [-0.0484],\n",
      "         [-0.0484]],\n",
      "\n",
      "        [[-0.0342],\n",
      "         [-0.0078],\n",
      "         [-0.0417],\n",
      "         ...,\n",
      "         [-0.0447],\n",
      "         [-0.0431],\n",
      "         [-0.0419]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [-0.0211],\n",
      "         [-0.0211],\n",
      "         [-0.0211]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [-0.0590],\n",
      "         [-0.0590],\n",
      "         [-0.0590]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0300],\n",
      "         [ 0.0181],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0433],\n",
      "         [-0.1075],\n",
      "         [-0.0386],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0342],\n",
      "         [-0.0078],\n",
      "         [-0.0417],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364],\n",
      "         [-0.1051],\n",
      "         [ 0.0243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0173],\n",
      "         [ 0.0095],\n",
      "         [-0.0491],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0524],\n",
      "         [-0.0247],\n",
      "         [-0.1308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/25000 [00:03<3:53:33,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот в AttentiveModel сделали mask. Она выглядит так:\n",
      "torch.BoolTensor\n",
      "tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False]])\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1927],\n",
      "         [0.1211],\n",
      "         [0.2440],\n",
      "         ...,\n",
      "         [0.1924],\n",
      "         [0.1924],\n",
      "         [0.1925]],\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.2048],\n",
      "         [0.2217],\n",
      "         ...,\n",
      "         [0.1278],\n",
      "         [0.1494],\n",
      "         [0.0945]],\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.2182],\n",
      "         [0.2225],\n",
      "         ...,\n",
      "         [0.1925],\n",
      "         [0.1925],\n",
      "         [0.1925]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.1301],\n",
      "         [0.0962],\n",
      "         ...,\n",
      "         [0.1896],\n",
      "         [0.1905],\n",
      "         [0.1911]],\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.2646],\n",
      "         [0.1829],\n",
      "         ...,\n",
      "         [0.1925],\n",
      "         [0.1925],\n",
      "         [0.1925]],\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.1561],\n",
      "         [0.2652],\n",
      "         ...,\n",
      "         [0.1916],\n",
      "         [0.1919],\n",
      "         [0.1921]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1927],\n",
      "         [0.1211],\n",
      "         [0.2440],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.2048],\n",
      "         [0.2217],\n",
      "         ...,\n",
      "         [0.1278],\n",
      "         [0.1494],\n",
      "         [0.0945]],\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.2182],\n",
      "         [0.2225],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.1301],\n",
      "         [0.0962],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.2646],\n",
      "         [0.1829],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1927],\n",
      "         [0.1561],\n",
      "         [0.2652],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1295],\n",
      "         [0.0578],\n",
      "         [0.1820],\n",
      "         ...,\n",
      "         [0.1297],\n",
      "         [0.1297],\n",
      "         [0.1297]],\n",
      "\n",
      "        [[0.1291],\n",
      "         [0.1401],\n",
      "         [0.1562],\n",
      "         ...,\n",
      "         [0.0657],\n",
      "         [0.0866],\n",
      "         [0.0299]],\n",
      "\n",
      "        [[0.1324],\n",
      "         [0.1575],\n",
      "         [0.1612],\n",
      "         ...,\n",
      "         [0.1329],\n",
      "         [0.1329],\n",
      "         [0.1329]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1255],\n",
      "         [0.0616],\n",
      "         [0.0287],\n",
      "         ...,\n",
      "         [0.1229],\n",
      "         [0.1238],\n",
      "         [0.1245]],\n",
      "\n",
      "        [[0.1232],\n",
      "         [0.1946],\n",
      "         [0.1114],\n",
      "         ...,\n",
      "         [0.1236],\n",
      "         [0.1236],\n",
      "         [0.1236]],\n",
      "\n",
      "        [[0.1258],\n",
      "         [0.0904],\n",
      "         [0.1975],\n",
      "         ...,\n",
      "         [0.1254],\n",
      "         [0.1257],\n",
      "         [0.1259]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[0.1295],\n",
      "         [0.0578],\n",
      "         [0.1820],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1291],\n",
      "         [0.1401],\n",
      "         [0.1562],\n",
      "         ...,\n",
      "         [0.0657],\n",
      "         [0.0866],\n",
      "         [0.0299]],\n",
      "\n",
      "        [[0.1324],\n",
      "         [0.1575],\n",
      "         [0.1612],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1255],\n",
      "         [0.0616],\n",
      "         [0.0287],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1232],\n",
      "         [0.1946],\n",
      "         [0.1114],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]],\n",
      "\n",
      "        [[0.1258],\n",
      "         [0.0904],\n",
      "         [0.1975],\n",
      "         ...,\n",
      "         [  -inf],\n",
      "         [  -inf],\n",
      "         [  -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1544],\n",
      "         [ 0.0833],\n",
      "         [ 0.2061],\n",
      "         ...,\n",
      "         [ 0.1557],\n",
      "         [ 0.1557],\n",
      "         [ 0.1557]],\n",
      "\n",
      "        [[ 0.1009],\n",
      "         [ 0.1119],\n",
      "         [ 0.1276],\n",
      "         ...,\n",
      "         [ 0.0357],\n",
      "         [ 0.0562],\n",
      "         [ 0.0019]],\n",
      "\n",
      "        [[ 0.1080],\n",
      "         [ 0.1342],\n",
      "         [ 0.1382],\n",
      "         ...,\n",
      "         [ 0.1071],\n",
      "         [ 0.1071],\n",
      "         [ 0.1071]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0882],\n",
      "         [ 0.0265],\n",
      "         [-0.0047],\n",
      "         ...,\n",
      "         [ 0.0832],\n",
      "         [ 0.0841],\n",
      "         [ 0.0848]],\n",
      "\n",
      "        [[ 0.1425],\n",
      "         [ 0.2147],\n",
      "         [ 0.1309],\n",
      "         ...,\n",
      "         [ 0.1439],\n",
      "         [ 0.1439],\n",
      "         [ 0.1439]],\n",
      "\n",
      "        [[ 0.1439],\n",
      "         [ 0.1083],\n",
      "         [ 0.2159],\n",
      "         ...,\n",
      "         [ 0.1444],\n",
      "         [ 0.1446],\n",
      "         [ 0.1448]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1544],\n",
      "         [ 0.0833],\n",
      "         [ 0.2061],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1009],\n",
      "         [ 0.1119],\n",
      "         [ 0.1276],\n",
      "         ...,\n",
      "         [ 0.0357],\n",
      "         [ 0.0562],\n",
      "         [ 0.0019]],\n",
      "\n",
      "        [[ 0.1080],\n",
      "         [ 0.1342],\n",
      "         [ 0.1382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0882],\n",
      "         [ 0.0265],\n",
      "         [-0.0047],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1425],\n",
      "         [ 0.2147],\n",
      "         [ 0.1309],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1439],\n",
      "         [ 0.1083],\n",
      "         [ 0.2159],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1414],\n",
      "         [ 0.0727],\n",
      "         [ 0.1927],\n",
      "         ...,\n",
      "         [ 0.1436],\n",
      "         [ 0.1437],\n",
      "         [ 0.1437]],\n",
      "\n",
      "        [[ 0.1533],\n",
      "         [ 0.1653],\n",
      "         [ 0.1812],\n",
      "         ...,\n",
      "         [ 0.0895],\n",
      "         [ 0.1095],\n",
      "         [ 0.0540]],\n",
      "\n",
      "        [[ 0.0304],\n",
      "         [ 0.0556],\n",
      "         [ 0.0589],\n",
      "         ...,\n",
      "         [ 0.0287],\n",
      "         [ 0.0287],\n",
      "         [ 0.0287]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0590],\n",
      "         [-0.0032],\n",
      "         [-0.0345],\n",
      "         ...,\n",
      "         [ 0.0543],\n",
      "         [ 0.0553],\n",
      "         [ 0.0559]],\n",
      "\n",
      "        [[ 0.1018],\n",
      "         [ 0.1732],\n",
      "         [ 0.0894],\n",
      "         ...,\n",
      "         [ 0.1034],\n",
      "         [ 0.1034],\n",
      "         [ 0.1034]],\n",
      "\n",
      "        [[ 0.1268],\n",
      "         [ 0.0918],\n",
      "         [ 0.1980],\n",
      "         ...,\n",
      "         [ 0.1271],\n",
      "         [ 0.1273],\n",
      "         [ 0.1275]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1414],\n",
      "         [ 0.0727],\n",
      "         [ 0.1927],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1533],\n",
      "         [ 0.1653],\n",
      "         [ 0.1812],\n",
      "         ...,\n",
      "         [ 0.0895],\n",
      "         [ 0.1095],\n",
      "         [ 0.0540]],\n",
      "\n",
      "        [[ 0.0304],\n",
      "         [ 0.0556],\n",
      "         [ 0.0589],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0590],\n",
      "         [-0.0032],\n",
      "         [-0.0345],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1018],\n",
      "         [ 0.1732],\n",
      "         [ 0.0894],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1268],\n",
      "         [ 0.0918],\n",
      "         [ 0.1980],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0641],\n",
      "         [-0.0027],\n",
      "         [ 0.1197],\n",
      "         ...,\n",
      "         [ 0.0633],\n",
      "         [ 0.0634],\n",
      "         [ 0.0634]],\n",
      "\n",
      "        [[ 0.1151],\n",
      "         [ 0.1268],\n",
      "         [ 0.1425],\n",
      "         ...,\n",
      "         [ 0.0545],\n",
      "         [ 0.0743],\n",
      "         [ 0.0165]],\n",
      "\n",
      "        [[ 0.0764],\n",
      "         [ 0.1023],\n",
      "         [ 0.1064],\n",
      "         ...,\n",
      "         [ 0.0754],\n",
      "         [ 0.0754],\n",
      "         [ 0.0754]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0123],\n",
      "         [-0.0497],\n",
      "         [-0.0799],\n",
      "         ...,\n",
      "         [ 0.0060],\n",
      "         [ 0.0069],\n",
      "         [ 0.0075]],\n",
      "\n",
      "        [[ 0.0963],\n",
      "         [ 0.1677],\n",
      "         [ 0.0838],\n",
      "         ...,\n",
      "         [ 0.0976],\n",
      "         [ 0.0976],\n",
      "         [ 0.0976]],\n",
      "\n",
      "        [[ 0.1063],\n",
      "         [ 0.0715],\n",
      "         [ 0.1771],\n",
      "         ...,\n",
      "         [ 0.1061],\n",
      "         [ 0.1064],\n",
      "         [ 0.1066]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0641],\n",
      "         [-0.0027],\n",
      "         [ 0.1197],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1151],\n",
      "         [ 0.1268],\n",
      "         [ 0.1425],\n",
      "         ...,\n",
      "         [ 0.0545],\n",
      "         [ 0.0743],\n",
      "         [ 0.0165]],\n",
      "\n",
      "        [[ 0.0764],\n",
      "         [ 0.1023],\n",
      "         [ 0.1064],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0123],\n",
      "         [-0.0497],\n",
      "         [-0.0799],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0963],\n",
      "         [ 0.1677],\n",
      "         [ 0.0838],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1063],\n",
      "         [ 0.0715],\n",
      "         [ 0.1771],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0993],\n",
      "         [ 0.0293],\n",
      "         [ 0.1509],\n",
      "         ...,\n",
      "         [ 0.1008],\n",
      "         [ 0.1008],\n",
      "         [ 0.1008]],\n",
      "\n",
      "        [[ 0.1445],\n",
      "         [ 0.1565],\n",
      "         [ 0.1728],\n",
      "         ...,\n",
      "         [ 0.0841],\n",
      "         [ 0.1039],\n",
      "         [ 0.0447]],\n",
      "\n",
      "        [[ 0.1131],\n",
      "         [ 0.1386],\n",
      "         [ 0.1430],\n",
      "         ...,\n",
      "         [ 0.1138],\n",
      "         [ 0.1138],\n",
      "         [ 0.1138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0325],\n",
      "         [-0.0943],\n",
      "         [-0.1238],\n",
      "         ...,\n",
      "         [-0.0392],\n",
      "         [-0.0383],\n",
      "         [-0.0377]],\n",
      "\n",
      "        [[-0.0017],\n",
      "         [ 0.0683],\n",
      "         [-0.0147],\n",
      "         ...,\n",
      "         [ 0.0013],\n",
      "         [ 0.0013],\n",
      "         [ 0.0013]],\n",
      "\n",
      "        [[ 0.0337],\n",
      "         [ 0.0010],\n",
      "         [ 0.1045],\n",
      "         ...,\n",
      "         [ 0.0321],\n",
      "         [ 0.0324],\n",
      "         [ 0.0326]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0993],\n",
      "         [ 0.0293],\n",
      "         [ 0.1509],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1445],\n",
      "         [ 0.1565],\n",
      "         [ 0.1728],\n",
      "         ...,\n",
      "         [ 0.0841],\n",
      "         [ 0.1039],\n",
      "         [ 0.0447]],\n",
      "\n",
      "        [[ 0.1131],\n",
      "         [ 0.1386],\n",
      "         [ 0.1430],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0325],\n",
      "         [-0.0943],\n",
      "         [-0.1238],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0017],\n",
      "         [ 0.0683],\n",
      "         [-0.0147],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0337],\n",
      "         [ 0.0010],\n",
      "         [ 0.1045],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0328],\n",
      "         [-0.0364],\n",
      "         [ 0.0848],\n",
      "         ...,\n",
      "         [ 0.0337],\n",
      "         [ 0.0337],\n",
      "         [ 0.0337]],\n",
      "\n",
      "        [[ 0.0375],\n",
      "         [ 0.0482],\n",
      "         [ 0.0639],\n",
      "         ...,\n",
      "         [-0.0199],\n",
      "         [-0.0002],\n",
      "         [-0.0602]],\n",
      "\n",
      "        [[ 0.0982],\n",
      "         [ 0.1213],\n",
      "         [ 0.1236],\n",
      "         ...,\n",
      "         [ 0.1017],\n",
      "         [ 0.1017],\n",
      "         [ 0.1017]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0221],\n",
      "         [-0.0403],\n",
      "         [-0.0718],\n",
      "         ...,\n",
      "         [ 0.0194],\n",
      "         [ 0.0204],\n",
      "         [ 0.0210]],\n",
      "\n",
      "        [[ 0.0652],\n",
      "         [ 0.1365],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [ 0.0706],\n",
      "         [ 0.0706],\n",
      "         [ 0.0706]],\n",
      "\n",
      "        [[ 0.0741],\n",
      "         [ 0.0377],\n",
      "         [ 0.1436],\n",
      "         ...,\n",
      "         [ 0.0757],\n",
      "         [ 0.0760],\n",
      "         [ 0.0762]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0328],\n",
      "         [-0.0364],\n",
      "         [ 0.0848],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0375],\n",
      "         [ 0.0482],\n",
      "         [ 0.0639],\n",
      "         ...,\n",
      "         [-0.0199],\n",
      "         [-0.0002],\n",
      "         [-0.0602]],\n",
      "\n",
      "        [[ 0.0982],\n",
      "         [ 0.1213],\n",
      "         [ 0.1236],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0221],\n",
      "         [-0.0403],\n",
      "         [-0.0718],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0652],\n",
      "         [ 0.1365],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0741],\n",
      "         [ 0.0377],\n",
      "         [ 0.1436],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0210],\n",
      "         [-0.0896],\n",
      "         [ 0.0355],\n",
      "         ...,\n",
      "         [-0.0233],\n",
      "         [-0.0232],\n",
      "         [-0.0232]],\n",
      "\n",
      "        [[ 0.0359],\n",
      "         [ 0.0469],\n",
      "         [ 0.0633],\n",
      "         ...,\n",
      "         [-0.0204],\n",
      "         [-0.0004],\n",
      "         [-0.0628]],\n",
      "\n",
      "        [[ 0.0387],\n",
      "         [ 0.0631],\n",
      "         [ 0.0661],\n",
      "         ...,\n",
      "         [ 0.0396],\n",
      "         [ 0.0396],\n",
      "         [ 0.0396]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0987],\n",
      "         [ 0.0368],\n",
      "         [ 0.0040],\n",
      "         ...,\n",
      "         [ 0.0972],\n",
      "         [ 0.0982],\n",
      "         [ 0.0988]],\n",
      "\n",
      "        [[ 0.0607],\n",
      "         [ 0.1311],\n",
      "         [ 0.0481],\n",
      "         ...,\n",
      "         [ 0.0635],\n",
      "         [ 0.0635],\n",
      "         [ 0.0635]],\n",
      "\n",
      "        [[ 0.0723],\n",
      "         [ 0.0362],\n",
      "         [ 0.1426],\n",
      "         ...,\n",
      "         [ 0.0750],\n",
      "         [ 0.0753],\n",
      "         [ 0.0755]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0210],\n",
      "         [-0.0896],\n",
      "         [ 0.0355],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0359],\n",
      "         [ 0.0469],\n",
      "         [ 0.0633],\n",
      "         ...,\n",
      "         [-0.0204],\n",
      "         [-0.0004],\n",
      "         [-0.0628]],\n",
      "\n",
      "        [[ 0.0387],\n",
      "         [ 0.0631],\n",
      "         [ 0.0661],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0987],\n",
      "         [ 0.0368],\n",
      "         [ 0.0040],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0607],\n",
      "         [ 0.1311],\n",
      "         [ 0.0481],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0723],\n",
      "         [ 0.0362],\n",
      "         [ 0.1426],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 6.0749e-02],\n",
      "         [-1.0531e-02],\n",
      "         [ 1.0718e-01],\n",
      "         ...,\n",
      "         [ 6.3844e-02],\n",
      "         [ 6.3879e-02],\n",
      "         [ 6.3903e-02]],\n",
      "\n",
      "        [[-2.5718e-02],\n",
      "         [-1.5823e-02],\n",
      "         [-1.8113e-04],\n",
      "         ...,\n",
      "         [-8.0406e-02],\n",
      "         [-6.0572e-02],\n",
      "         [-1.2243e-01]],\n",
      "\n",
      "        [[ 5.6388e-02],\n",
      "         [ 8.3324e-02],\n",
      "         [ 8.7675e-02],\n",
      "         ...,\n",
      "         [ 5.5414e-02],\n",
      "         [ 5.5415e-02],\n",
      "         [ 5.5415e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7678e-01],\n",
      "         [ 1.1354e-01],\n",
      "         [ 7.8454e-02],\n",
      "         ...,\n",
      "         [ 1.7763e-01],\n",
      "         [ 1.7862e-01],\n",
      "         [ 1.7929e-01]],\n",
      "\n",
      "        [[ 1.1800e-01],\n",
      "         [ 1.8999e-01],\n",
      "         [ 1.0616e-01],\n",
      "         ...,\n",
      "         [ 1.2050e-01],\n",
      "         [ 1.2051e-01],\n",
      "         [ 1.2051e-01]],\n",
      "\n",
      "        [[ 9.0854e-02],\n",
      "         [ 5.3857e-02],\n",
      "         [ 1.6089e-01],\n",
      "         ...,\n",
      "         [ 9.3410e-02],\n",
      "         [ 9.3688e-02],\n",
      "         [ 9.3880e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 6.0749e-02],\n",
      "         [-1.0531e-02],\n",
      "         [ 1.0718e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[-2.5718e-02],\n",
      "         [-1.5823e-02],\n",
      "         [-1.8113e-04],\n",
      "         ...,\n",
      "         [-8.0406e-02],\n",
      "         [-6.0572e-02],\n",
      "         [-1.2243e-01]],\n",
      "\n",
      "        [[ 5.6388e-02],\n",
      "         [ 8.3324e-02],\n",
      "         [ 8.7675e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7678e-01],\n",
      "         [ 1.1354e-01],\n",
      "         [ 7.8454e-02],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 1.1800e-01],\n",
      "         [ 1.8999e-01],\n",
      "         [ 1.0616e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]],\n",
      "\n",
      "        [[ 9.0854e-02],\n",
      "         [ 5.3857e-02],\n",
      "         [ 1.6089e-01],\n",
      "         ...,\n",
      "         [       -inf],\n",
      "         [       -inf],\n",
      "         [       -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0846],\n",
      "         [ 0.0150],\n",
      "         [ 0.1398],\n",
      "         ...,\n",
      "         [ 0.0832],\n",
      "         [ 0.0832],\n",
      "         [ 0.0832]],\n",
      "\n",
      "        [[ 0.0489],\n",
      "         [ 0.0602],\n",
      "         [ 0.0765],\n",
      "         ...,\n",
      "         [-0.0041],\n",
      "         [ 0.0156],\n",
      "         [-0.0487]],\n",
      "\n",
      "        [[ 0.0650],\n",
      "         [ 0.0897],\n",
      "         [ 0.0928],\n",
      "         ...,\n",
      "         [ 0.0665],\n",
      "         [ 0.0665],\n",
      "         [ 0.0665]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1954],\n",
      "         [ 0.1345],\n",
      "         [ 0.0999],\n",
      "         ...,\n",
      "         [ 0.1951],\n",
      "         [ 0.1961],\n",
      "         [ 0.1967]],\n",
      "\n",
      "        [[ 0.0481],\n",
      "         [ 0.1164],\n",
      "         [ 0.0351],\n",
      "         ...,\n",
      "         [ 0.0492],\n",
      "         [ 0.0492],\n",
      "         [ 0.0492]],\n",
      "\n",
      "        [[-0.0393],\n",
      "         [-0.0704],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [-0.0396],\n",
      "         [-0.0393],\n",
      "         [-0.0391]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0846],\n",
      "         [ 0.0150],\n",
      "         [ 0.1398],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0489],\n",
      "         [ 0.0602],\n",
      "         [ 0.0765],\n",
      "         ...,\n",
      "         [-0.0041],\n",
      "         [ 0.0156],\n",
      "         [-0.0487]],\n",
      "\n",
      "        [[ 0.0650],\n",
      "         [ 0.0897],\n",
      "         [ 0.0928],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1954],\n",
      "         [ 0.1345],\n",
      "         [ 0.0999],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0481],\n",
      "         [ 0.1164],\n",
      "         [ 0.0351],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0393],\n",
      "         [-0.0704],\n",
      "         [ 0.0304],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1009],\n",
      "         [ 0.0325],\n",
      "         [ 0.1570],\n",
      "         ...,\n",
      "         [ 0.0993],\n",
      "         [ 0.0994],\n",
      "         [ 0.0994]],\n",
      "\n",
      "        [[-0.0147],\n",
      "         [-0.0049],\n",
      "         [ 0.0102],\n",
      "         ...,\n",
      "         [-0.0623],\n",
      "         [-0.0431],\n",
      "         [-0.1085]],\n",
      "\n",
      "        [[ 0.0270],\n",
      "         [ 0.0526],\n",
      "         [ 0.0562],\n",
      "         ...,\n",
      "         [ 0.0259],\n",
      "         [ 0.0259],\n",
      "         [ 0.0259]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0412],\n",
      "         [-0.0183],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [ 0.0342],\n",
      "         [ 0.0351],\n",
      "         [ 0.0357]],\n",
      "\n",
      "        [[ 0.0045],\n",
      "         [ 0.0715],\n",
      "         [-0.0091],\n",
      "         ...,\n",
      "         [ 0.0027],\n",
      "         [ 0.0027],\n",
      "         [ 0.0027]],\n",
      "\n",
      "        [[ 0.0186],\n",
      "         [-0.0107],\n",
      "         [ 0.0914],\n",
      "         ...,\n",
      "         [ 0.0144],\n",
      "         [ 0.0147],\n",
      "         [ 0.0149]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1009],\n",
      "         [ 0.0325],\n",
      "         [ 0.1570],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0147],\n",
      "         [-0.0049],\n",
      "         [ 0.0102],\n",
      "         ...,\n",
      "         [-0.0623],\n",
      "         [-0.0431],\n",
      "         [-0.1085]],\n",
      "\n",
      "        [[ 0.0270],\n",
      "         [ 0.0526],\n",
      "         [ 0.0562],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0412],\n",
      "         [-0.0183],\n",
      "         [-0.0478],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0045],\n",
      "         [ 0.0715],\n",
      "         [-0.0091],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0186],\n",
      "         [-0.0107],\n",
      "         [ 0.0914],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1039],\n",
      "         [ 0.0335],\n",
      "         [ 0.1591],\n",
      "         ...,\n",
      "         [ 0.1029],\n",
      "         [ 0.1030],\n",
      "         [ 0.1030]],\n",
      "\n",
      "        [[-0.1219],\n",
      "         [-0.1138],\n",
      "         [-0.0989],\n",
      "         ...,\n",
      "         [-0.1687],\n",
      "         [-0.1487],\n",
      "         [-0.2142]],\n",
      "\n",
      "        [[ 0.0070],\n",
      "         [ 0.0335],\n",
      "         [ 0.0376],\n",
      "         ...,\n",
      "         [ 0.0038],\n",
      "         [ 0.0038],\n",
      "         [ 0.0038]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1522],\n",
      "         [ 0.0899],\n",
      "         [ 0.0588],\n",
      "         ...,\n",
      "         [ 0.1492],\n",
      "         [ 0.1502],\n",
      "         [ 0.1508]],\n",
      "\n",
      "        [[ 0.0010],\n",
      "         [ 0.0698],\n",
      "         [-0.0127],\n",
      "         ...,\n",
      "         [ 0.0046],\n",
      "         [ 0.0046],\n",
      "         [ 0.0046]],\n",
      "\n",
      "        [[-0.0632],\n",
      "         [-0.0905],\n",
      "         [ 0.0072],\n",
      "         ...,\n",
      "         [-0.0699],\n",
      "         [-0.0696],\n",
      "         [-0.0694]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1039],\n",
      "         [ 0.0335],\n",
      "         [ 0.1591],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.1219],\n",
      "         [-0.1138],\n",
      "         [-0.0989],\n",
      "         ...,\n",
      "         [-0.1687],\n",
      "         [-0.1487],\n",
      "         [-0.2142]],\n",
      "\n",
      "        [[ 0.0070],\n",
      "         [ 0.0335],\n",
      "         [ 0.0376],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1522],\n",
      "         [ 0.0899],\n",
      "         [ 0.0588],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0010],\n",
      "         [ 0.0698],\n",
      "         [-0.0127],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0632],\n",
      "         [-0.0905],\n",
      "         [ 0.0072],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0260],\n",
      "         [-0.0921],\n",
      "         [ 0.0346],\n",
      "         ...,\n",
      "         [-0.0318],\n",
      "         [-0.0317],\n",
      "         [-0.0317]],\n",
      "\n",
      "        [[-0.1375],\n",
      "         [-0.1301],\n",
      "         [-0.1155],\n",
      "         ...,\n",
      "         [-0.1863],\n",
      "         [-0.1660],\n",
      "         [-0.2298]],\n",
      "\n",
      "        [[-0.0037],\n",
      "         [ 0.0235],\n",
      "         [ 0.0279],\n",
      "         ...,\n",
      "         [-0.0081],\n",
      "         [-0.0081],\n",
      "         [-0.0081]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1405],\n",
      "         [ 0.0773],\n",
      "         [ 0.0452],\n",
      "         ...,\n",
      "         [ 0.1389],\n",
      "         [ 0.1399],\n",
      "         [ 0.1405]],\n",
      "\n",
      "        [[ 0.0507],\n",
      "         [ 0.1206],\n",
      "         [ 0.0382],\n",
      "         ...,\n",
      "         [ 0.0524],\n",
      "         [ 0.0524],\n",
      "         [ 0.0524]],\n",
      "\n",
      "        [[ 0.0123],\n",
      "         [-0.0169],\n",
      "         [ 0.0868],\n",
      "         ...,\n",
      "         [ 0.0081],\n",
      "         [ 0.0084],\n",
      "         [ 0.0086]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0260],\n",
      "         [-0.0921],\n",
      "         [ 0.0346],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.1375],\n",
      "         [-0.1301],\n",
      "         [-0.1155],\n",
      "         ...,\n",
      "         [-0.1863],\n",
      "         [-0.1660],\n",
      "         [-0.2298]],\n",
      "\n",
      "        [[-0.0037],\n",
      "         [ 0.0235],\n",
      "         [ 0.0279],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1405],\n",
      "         [ 0.0773],\n",
      "         [ 0.0452],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0507],\n",
      "         [ 0.1206],\n",
      "         [ 0.0382],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0123],\n",
      "         [-0.0169],\n",
      "         [ 0.0868],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1449],\n",
      "         [ 0.0740],\n",
      "         [ 0.1949],\n",
      "         ...,\n",
      "         [ 0.1473],\n",
      "         [ 0.1473],\n",
      "         [ 0.1474]],\n",
      "\n",
      "        [[-0.0860],\n",
      "         [-0.0773],\n",
      "         [-0.0625],\n",
      "         ...,\n",
      "         [-0.1353],\n",
      "         [-0.1153],\n",
      "         [-0.1789]],\n",
      "\n",
      "        [[-0.0096],\n",
      "         [ 0.0180],\n",
      "         [ 0.0227],\n",
      "         ...,\n",
      "         [-0.0147],\n",
      "         [-0.0147],\n",
      "         [-0.0147]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1340],\n",
      "         [ 0.0707],\n",
      "         [ 0.0385],\n",
      "         ...,\n",
      "         [ 0.1326],\n",
      "         [ 0.1336],\n",
      "         [ 0.1342]],\n",
      "\n",
      "        [[ 0.1356],\n",
      "         [ 0.2035],\n",
      "         [ 0.1244],\n",
      "         ...,\n",
      "         [ 0.1321],\n",
      "         [ 0.1321],\n",
      "         [ 0.1321]],\n",
      "\n",
      "        [[ 0.0117],\n",
      "         [-0.0195],\n",
      "         [ 0.0853],\n",
      "         ...,\n",
      "         [ 0.0093],\n",
      "         [ 0.0096],\n",
      "         [ 0.0098]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1449],\n",
      "         [ 0.0740],\n",
      "         [ 0.1949],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0860],\n",
      "         [-0.0773],\n",
      "         [-0.0625],\n",
      "         ...,\n",
      "         [-0.1353],\n",
      "         [-0.1153],\n",
      "         [-0.1789]],\n",
      "\n",
      "        [[-0.0096],\n",
      "         [ 0.0180],\n",
      "         [ 0.0227],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1340],\n",
      "         [ 0.0707],\n",
      "         [ 0.0385],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1356],\n",
      "         [ 0.2035],\n",
      "         [ 0.1244],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0117],\n",
      "         [-0.0195],\n",
      "         [ 0.0853],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1567],\n",
      "         [ 0.0866],\n",
      "         [ 0.2090],\n",
      "         ...,\n",
      "         [ 0.1576],\n",
      "         [ 0.1576],\n",
      "         [ 0.1576]],\n",
      "\n",
      "        [[-0.0032],\n",
      "         [ 0.0071],\n",
      "         [ 0.0215],\n",
      "         ...,\n",
      "         [-0.0638],\n",
      "         [-0.0444],\n",
      "         [-0.0986]],\n",
      "\n",
      "        [[-0.0128],\n",
      "         [ 0.0150],\n",
      "         [ 0.0198],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0183],\n",
      "         [-0.0183]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1293],\n",
      "         [ 0.0667],\n",
      "         [ 0.0354],\n",
      "         ...,\n",
      "         [ 0.1262],\n",
      "         [ 0.1272],\n",
      "         [ 0.1279]],\n",
      "\n",
      "        [[ 0.0900],\n",
      "         [ 0.1569],\n",
      "         [ 0.0780],\n",
      "         ...,\n",
      "         [ 0.0863],\n",
      "         [ 0.0863],\n",
      "         [ 0.0863]],\n",
      "\n",
      "        [[ 0.0153],\n",
      "         [-0.0184],\n",
      "         [ 0.0861],\n",
      "         ...,\n",
      "         [ 0.0153],\n",
      "         [ 0.0156],\n",
      "         [ 0.0158]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1567],\n",
      "         [ 0.0866],\n",
      "         [ 0.2090],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0032],\n",
      "         [ 0.0071],\n",
      "         [ 0.0215],\n",
      "         ...,\n",
      "         [-0.0638],\n",
      "         [-0.0444],\n",
      "         [-0.0986]],\n",
      "\n",
      "        [[-0.0128],\n",
      "         [ 0.0150],\n",
      "         [ 0.0198],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1293],\n",
      "         [ 0.0667],\n",
      "         [ 0.0354],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0900],\n",
      "         [ 0.1569],\n",
      "         [ 0.0780],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0153],\n",
      "         [-0.0184],\n",
      "         [ 0.0861],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1199],\n",
      "         [ 0.0508],\n",
      "         [ 0.1742],\n",
      "         ...,\n",
      "         [ 0.1195],\n",
      "         [ 0.1195],\n",
      "         [ 0.1196]],\n",
      "\n",
      "        [[ 0.0427],\n",
      "         [ 0.0543],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0023],\n",
      "         [-0.0530]],\n",
      "\n",
      "        [[-0.0146],\n",
      "         [ 0.0133],\n",
      "         [ 0.0181],\n",
      "         ...,\n",
      "         [-0.0204],\n",
      "         [-0.0204],\n",
      "         [-0.0204]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0279],\n",
      "         [-0.0877],\n",
      "         [-0.1165],\n",
      "         ...,\n",
      "         [-0.0364],\n",
      "         [-0.0355],\n",
      "         [-0.0349]],\n",
      "\n",
      "        [[ 0.1001],\n",
      "         [ 0.1698],\n",
      "         [ 0.0875],\n",
      "         ...,\n",
      "         [ 0.0988],\n",
      "         [ 0.0988],\n",
      "         [ 0.0988]],\n",
      "\n",
      "        [[ 0.0391],\n",
      "         [ 0.0094],\n",
      "         [ 0.1111],\n",
      "         ...,\n",
      "         [ 0.0347],\n",
      "         [ 0.0349],\n",
      "         [ 0.0351]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1199],\n",
      "         [ 0.0508],\n",
      "         [ 0.1742],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0427],\n",
      "         [ 0.0543],\n",
      "         [ 0.0685],\n",
      "         ...,\n",
      "         [-0.0212],\n",
      "         [-0.0023],\n",
      "         [-0.0530]],\n",
      "\n",
      "        [[-0.0146],\n",
      "         [ 0.0133],\n",
      "         [ 0.0181],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0279],\n",
      "         [-0.0877],\n",
      "         [-0.1165],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1001],\n",
      "         [ 0.1698],\n",
      "         [ 0.0875],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0391],\n",
      "         [ 0.0094],\n",
      "         [ 0.1111],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0274],\n",
      "         [-0.0404],\n",
      "         [ 0.0844],\n",
      "         ...,\n",
      "         [ 0.0250],\n",
      "         [ 0.0251],\n",
      "         [ 0.0251]],\n",
      "\n",
      "        [[ 0.0867],\n",
      "         [ 0.0980],\n",
      "         [ 0.1116],\n",
      "         ...,\n",
      "         [ 0.0154],\n",
      "         [ 0.0343],\n",
      "         [-0.0091]],\n",
      "\n",
      "        [[-0.0157],\n",
      "         [ 0.0123],\n",
      "         [ 0.0172],\n",
      "         ...,\n",
      "         [-0.0216],\n",
      "         [-0.0216],\n",
      "         [-0.0216]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0966],\n",
      "         [ 0.0350],\n",
      "         [ 0.0022],\n",
      "         ...,\n",
      "         [ 0.0969],\n",
      "         [ 0.0978],\n",
      "         [ 0.0985]],\n",
      "\n",
      "        [[ 0.0682],\n",
      "         [ 0.1383],\n",
      "         [ 0.0556],\n",
      "         ...,\n",
      "         [ 0.0680],\n",
      "         [ 0.0680],\n",
      "         [ 0.0680]],\n",
      "\n",
      "        [[-0.0126],\n",
      "         [-0.0435],\n",
      "         [ 0.0576],\n",
      "         ...,\n",
      "         [-0.0157],\n",
      "         [-0.0154],\n",
      "         [-0.0152]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0274],\n",
      "         [-0.0404],\n",
      "         [ 0.0844],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0867],\n",
      "         [ 0.0980],\n",
      "         [ 0.1116],\n",
      "         ...,\n",
      "         [ 0.0154],\n",
      "         [ 0.0343],\n",
      "         [-0.0091]],\n",
      "\n",
      "        [[-0.0157],\n",
      "         [ 0.0123],\n",
      "         [ 0.0172],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0966],\n",
      "         [ 0.0350],\n",
      "         [ 0.0022],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0682],\n",
      "         [ 0.1383],\n",
      "         [ 0.0556],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0126],\n",
      "         [-0.0435],\n",
      "         [ 0.0576],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0197],\n",
      "         [-0.0424],\n",
      "         [ 0.0842],\n",
      "         ...,\n",
      "         [ 0.0141],\n",
      "         [ 0.0141],\n",
      "         [ 0.0142]],\n",
      "\n",
      "        [[-0.0332],\n",
      "         [-0.0244],\n",
      "         [-0.0107],\n",
      "         ...,\n",
      "         [-0.0972],\n",
      "         [-0.0776],\n",
      "         [-0.1273]],\n",
      "\n",
      "        [[-0.0163],\n",
      "         [ 0.0118],\n",
      "         [ 0.0166],\n",
      "         ...,\n",
      "         [-0.0222],\n",
      "         [-0.0222],\n",
      "         [-0.0222]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0681],\n",
      "         [ 0.0048],\n",
      "         [-0.0275],\n",
      "         ...,\n",
      "         [ 0.0662],\n",
      "         [ 0.0672],\n",
      "         [ 0.0678]],\n",
      "\n",
      "        [[-0.0582],\n",
      "         [ 0.0070],\n",
      "         [-0.0723],\n",
      "         ...,\n",
      "         [-0.0602],\n",
      "         [-0.0602],\n",
      "         [-0.0602]],\n",
      "\n",
      "        [[ 0.0487],\n",
      "         [ 0.0164],\n",
      "         [ 0.1206],\n",
      "         ...,\n",
      "         [ 0.0461],\n",
      "         [ 0.0464],\n",
      "         [ 0.0466]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0197],\n",
      "         [-0.0424],\n",
      "         [ 0.0842],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0332],\n",
      "         [-0.0244],\n",
      "         [-0.0107],\n",
      "         ...,\n",
      "         [-0.0972],\n",
      "         [-0.0776],\n",
      "         [-0.1273]],\n",
      "\n",
      "        [[-0.0163],\n",
      "         [ 0.0118],\n",
      "         [ 0.0166],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0681],\n",
      "         [ 0.0048],\n",
      "         [-0.0275],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0582],\n",
      "         [ 0.0070],\n",
      "         [-0.0723],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0487],\n",
      "         [ 0.0164],\n",
      "         [ 0.1206],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-1.0075e-01],\n",
      "         [-1.6471e-01],\n",
      "         [-3.4978e-02],\n",
      "         ...,\n",
      "         [-1.0443e-01],\n",
      "         [-1.0440e-01],\n",
      "         [-1.0437e-01]],\n",
      "\n",
      "        [[-4.3617e-02],\n",
      "         [-3.3561e-02],\n",
      "         [-1.8212e-02],\n",
      "         ...,\n",
      "         [-1.0125e-01],\n",
      "         [-8.0819e-02],\n",
      "         [-1.3747e-01]],\n",
      "\n",
      "        [[-1.6605e-02],\n",
      "         [ 1.1439e-02],\n",
      "         [ 1.6326e-02],\n",
      "         ...,\n",
      "         [-2.2587e-02],\n",
      "         [-2.2587e-02],\n",
      "         [-2.2587e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.0937e-03],\n",
      "         [-5.6718e-02],\n",
      "         [-8.6985e-02],\n",
      "         ...,\n",
      "         [ 7.8171e-05],\n",
      "         [ 1.0141e-03],\n",
      "         [ 1.6543e-03]],\n",
      "\n",
      "        [[ 4.7607e-02],\n",
      "         [ 1.1558e-01],\n",
      "         [ 3.5418e-02],\n",
      "         ...,\n",
      "         [ 4.2825e-02],\n",
      "         [ 4.2827e-02],\n",
      "         [ 4.2828e-02]],\n",
      "\n",
      "        [[ 9.3127e-02],\n",
      "         [ 5.8387e-02],\n",
      "         [ 1.6503e-01],\n",
      "         ...,\n",
      "         [ 9.2482e-02],\n",
      "         [ 9.2766e-02],\n",
      "         [ 9.2962e-02]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.1008],\n",
      "         [-0.1647],\n",
      "         [-0.0350],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0436],\n",
      "         [-0.0336],\n",
      "         [-0.0182],\n",
      "         ...,\n",
      "         [-0.1012],\n",
      "         [-0.0808],\n",
      "         [-0.1375]],\n",
      "\n",
      "        [[-0.0166],\n",
      "         [ 0.0114],\n",
      "         [ 0.0163],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0051],\n",
      "         [-0.0567],\n",
      "         [-0.0870],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0476],\n",
      "         [ 0.1156],\n",
      "         [ 0.0354],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0931],\n",
      "         [ 0.0584],\n",
      "         [ 0.1650],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0709],\n",
      "         [-0.1400],\n",
      "         [-0.0166],\n",
      "         ...,\n",
      "         [-0.0697],\n",
      "         [-0.0697],\n",
      "         [-0.0697]],\n",
      "\n",
      "        [[ 0.0857],\n",
      "         [ 0.0985],\n",
      "         [ 0.1156],\n",
      "         ...,\n",
      "         [ 0.0317],\n",
      "         [ 0.0518],\n",
      "         [-0.0124]],\n",
      "\n",
      "        [[-0.0168],\n",
      "         [ 0.0112],\n",
      "         [ 0.0161],\n",
      "         ...,\n",
      "         [-0.0228],\n",
      "         [-0.0228],\n",
      "         [-0.0228]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0769],\n",
      "         [ 0.0141],\n",
      "         [-0.0179],\n",
      "         ...,\n",
      "         [ 0.0739],\n",
      "         [ 0.0748],\n",
      "         [ 0.0755]],\n",
      "\n",
      "        [[ 0.0269],\n",
      "         [ 0.0958],\n",
      "         [ 0.0139],\n",
      "         ...,\n",
      "         [ 0.0255],\n",
      "         [ 0.0255],\n",
      "         [ 0.0255]],\n",
      "\n",
      "        [[ 0.0789],\n",
      "         [ 0.0426],\n",
      "         [ 0.1493],\n",
      "         ...,\n",
      "         [ 0.0818],\n",
      "         [ 0.0821],\n",
      "         [ 0.0823]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0709],\n",
      "         [-0.1400],\n",
      "         [-0.0166],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0857],\n",
      "         [ 0.0985],\n",
      "         [ 0.1156],\n",
      "         ...,\n",
      "         [ 0.0317],\n",
      "         [ 0.0518],\n",
      "         [-0.0124]],\n",
      "\n",
      "        [[-0.0168],\n",
      "         [ 0.0112],\n",
      "         [ 0.0161],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0769],\n",
      "         [ 0.0141],\n",
      "         [-0.0179],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0269],\n",
      "         [ 0.0958],\n",
      "         [ 0.0139],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0789],\n",
      "         [ 0.0426],\n",
      "         [ 0.1493],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.1079],\n",
      "         [-0.1777],\n",
      "         [-0.0529],\n",
      "         ...,\n",
      "         [-0.1064],\n",
      "         [-0.1063],\n",
      "         [-0.1063]],\n",
      "\n",
      "        [[-0.0597],\n",
      "         [-0.0507],\n",
      "         [-0.0359],\n",
      "         ...,\n",
      "         [-0.1083],\n",
      "         [-0.0888],\n",
      "         [-0.1532]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [ 0.0111],\n",
      "         [ 0.0160],\n",
      "         ...,\n",
      "         [-0.0229],\n",
      "         [-0.0229],\n",
      "         [-0.0229]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0637],\n",
      "         [ 0.0014],\n",
      "         [-0.0308],\n",
      "         ...,\n",
      "         [ 0.0614],\n",
      "         [ 0.0624],\n",
      "         [ 0.0631]],\n",
      "\n",
      "        [[-0.0153],\n",
      "         [ 0.0549],\n",
      "         [-0.0285],\n",
      "         ...,\n",
      "         [-0.0124],\n",
      "         [-0.0124],\n",
      "         [-0.0124]],\n",
      "\n",
      "        [[ 0.0700],\n",
      "         [ 0.0341],\n",
      "         [ 0.1407],\n",
      "         ...,\n",
      "         [ 0.0725],\n",
      "         [ 0.0728],\n",
      "         [ 0.0730]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.1079],\n",
      "         [-0.1777],\n",
      "         [-0.0529],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0597],\n",
      "         [-0.0507],\n",
      "         [-0.0359],\n",
      "         ...,\n",
      "         [-0.1083],\n",
      "         [-0.0888],\n",
      "         [-0.1532]],\n",
      "\n",
      "        [[-0.0169],\n",
      "         [ 0.0111],\n",
      "         [ 0.0160],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0637],\n",
      "         [ 0.0014],\n",
      "         [-0.0308],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0153],\n",
      "         [ 0.0549],\n",
      "         [-0.0285],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0700],\n",
      "         [ 0.0341],\n",
      "         [ 0.1407],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0012],\n",
      "         [-0.0687],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [ 0.0040],\n",
      "         [ 0.0041],\n",
      "         [ 0.0041]],\n",
      "\n",
      "        [[ 0.0425],\n",
      "         [ 0.0532],\n",
      "         [ 0.0693],\n",
      "         ...,\n",
      "         [-0.0085],\n",
      "         [ 0.0114],\n",
      "         [-0.0539]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [ 0.0111],\n",
      "         [ 0.0160],\n",
      "         ...,\n",
      "         [-0.0230],\n",
      "         [-0.0230],\n",
      "         [-0.0230]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0887],\n",
      "         [ 0.0267],\n",
      "         [-0.0050],\n",
      "         ...,\n",
      "         [ 0.0851],\n",
      "         [ 0.0861],\n",
      "         [ 0.0867]],\n",
      "\n",
      "        [[ 0.0084],\n",
      "         [ 0.0795],\n",
      "         [-0.0045],\n",
      "         ...,\n",
      "         [ 0.0114],\n",
      "         [ 0.0115],\n",
      "         [ 0.0115]],\n",
      "\n",
      "        [[ 0.1051],\n",
      "         [ 0.0702],\n",
      "         [ 0.1768],\n",
      "         ...,\n",
      "         [ 0.1071],\n",
      "         [ 0.1074],\n",
      "         [ 0.1076]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0012],\n",
      "         [-0.0687],\n",
      "         [ 0.0525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0425],\n",
      "         [ 0.0532],\n",
      "         [ 0.0693],\n",
      "         ...,\n",
      "         [-0.0085],\n",
      "         [ 0.0114],\n",
      "         [-0.0539]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [ 0.0111],\n",
      "         [ 0.0160],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0887],\n",
      "         [ 0.0267],\n",
      "         [-0.0050],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0084],\n",
      "         [ 0.0795],\n",
      "         [-0.0045],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1051],\n",
      "         [ 0.0702],\n",
      "         [ 0.1768],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0053],\n",
      "         [-0.0645],\n",
      "         [ 0.0565],\n",
      "         ...,\n",
      "         [ 0.0072],\n",
      "         [ 0.0072],\n",
      "         [ 0.0073]],\n",
      "\n",
      "        [[ 0.0823],\n",
      "         [ 0.0938],\n",
      "         [ 0.1097],\n",
      "         ...,\n",
      "         [ 0.0255],\n",
      "         [ 0.0451],\n",
      "         [-0.0160]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [ 0.0110],\n",
      "         [ 0.0159],\n",
      "         ...,\n",
      "         [-0.0230],\n",
      "         [-0.0230],\n",
      "         [-0.0230]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1718],\n",
      "         [ 0.1082],\n",
      "         [ 0.0736],\n",
      "         ...,\n",
      "         [ 0.1723],\n",
      "         [ 0.1733],\n",
      "         [ 0.1740]],\n",
      "\n",
      "        [[ 0.0657],\n",
      "         [ 0.1368],\n",
      "         [ 0.0527],\n",
      "         ...,\n",
      "         [ 0.0707],\n",
      "         [ 0.0707],\n",
      "         [ 0.0707]],\n",
      "\n",
      "        [[ 0.0882],\n",
      "         [ 0.0554],\n",
      "         [ 0.1598],\n",
      "         ...,\n",
      "         [ 0.0874],\n",
      "         [ 0.0877],\n",
      "         [ 0.0879]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0053],\n",
      "         [-0.0645],\n",
      "         [ 0.0565],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0823],\n",
      "         [ 0.0938],\n",
      "         [ 0.1097],\n",
      "         ...,\n",
      "         [ 0.0255],\n",
      "         [ 0.0451],\n",
      "         [-0.0160]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [ 0.0110],\n",
      "         [ 0.0159],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1718],\n",
      "         [ 0.1082],\n",
      "         [ 0.0736],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0657],\n",
      "         [ 0.1368],\n",
      "         [ 0.0527],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0882],\n",
      "         [ 0.0554],\n",
      "         [ 0.1598],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0285],\n",
      "         [-0.0947],\n",
      "         [ 0.0302],\n",
      "         ...,\n",
      "         [-0.0324],\n",
      "         [-0.0323],\n",
      "         [-0.0323]],\n",
      "\n",
      "        [[ 0.0260],\n",
      "         [ 0.0364],\n",
      "         [ 0.0516],\n",
      "         ...,\n",
      "         [-0.0235],\n",
      "         [-0.0044],\n",
      "         [-0.0685]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0110],\n",
      "         [ 0.0159],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1929],\n",
      "         [ 0.1316],\n",
      "         [ 0.0975],\n",
      "         ...,\n",
      "         [ 0.1924],\n",
      "         [ 0.1934],\n",
      "         [ 0.1941]],\n",
      "\n",
      "        [[ 0.0611],\n",
      "         [ 0.1317],\n",
      "         [ 0.0482],\n",
      "         ...,\n",
      "         [ 0.0659],\n",
      "         [ 0.0659],\n",
      "         [ 0.0659]],\n",
      "\n",
      "        [[ 0.1683],\n",
      "         [ 0.1341],\n",
      "         [ 0.2408],\n",
      "         ...,\n",
      "         [ 0.1690],\n",
      "         [ 0.1693],\n",
      "         [ 0.1695]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0285],\n",
      "         [-0.0947],\n",
      "         [ 0.0302],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0260],\n",
      "         [ 0.0364],\n",
      "         [ 0.0516],\n",
      "         ...,\n",
      "         [-0.0235],\n",
      "         [-0.0044],\n",
      "         [-0.0685]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0110],\n",
      "         [ 0.0159],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1929],\n",
      "         [ 0.1316],\n",
      "         [ 0.0975],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0611],\n",
      "         [ 0.1317],\n",
      "         [ 0.0482],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1683],\n",
      "         [ 0.1341],\n",
      "         [ 0.2408],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0701],\n",
      "         [ 0.0015],\n",
      "         [ 0.1255],\n",
      "         ...,\n",
      "         [ 0.0693],\n",
      "         [ 0.0694],\n",
      "         [ 0.0694]],\n",
      "\n",
      "        [[ 0.0741],\n",
      "         [ 0.0850],\n",
      "         [ 0.1007],\n",
      "         ...,\n",
      "         [ 0.0210],\n",
      "         [ 0.0404],\n",
      "         [-0.0226]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0110],\n",
      "         [ 0.0159],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1672],\n",
      "         [ 0.1053],\n",
      "         [ 0.0719],\n",
      "         ...,\n",
      "         [ 0.1664],\n",
      "         [ 0.1674],\n",
      "         [ 0.1681]],\n",
      "\n",
      "        [[ 0.0217],\n",
      "         [ 0.0908],\n",
      "         [ 0.0083],\n",
      "         ...,\n",
      "         [ 0.0230],\n",
      "         [ 0.0230],\n",
      "         [ 0.0230]],\n",
      "\n",
      "        [[ 0.1121],\n",
      "         [ 0.0807],\n",
      "         [ 0.1830],\n",
      "         ...,\n",
      "         [ 0.1108],\n",
      "         [ 0.1111],\n",
      "         [ 0.1113]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0701],\n",
      "         [ 0.0015],\n",
      "         [ 0.1255],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0741],\n",
      "         [ 0.0850],\n",
      "         [ 0.1007],\n",
      "         ...,\n",
      "         [ 0.0210],\n",
      "         [ 0.0404],\n",
      "         [-0.0226]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0110],\n",
      "         [ 0.0159],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1672],\n",
      "         [ 0.1053],\n",
      "         [ 0.0719],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0217],\n",
      "         [ 0.0908],\n",
      "         [ 0.0083],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1121],\n",
      "         [ 0.0807],\n",
      "         [ 0.1830],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0903],\n",
      "         [ 0.0194],\n",
      "         [ 0.1415],\n",
      "         ...,\n",
      "         [ 0.0927],\n",
      "         [ 0.0927],\n",
      "         [ 0.0927]],\n",
      "\n",
      "        [[ 0.0664],\n",
      "         [ 0.0775],\n",
      "         [ 0.0922],\n",
      "         ...,\n",
      "         [ 0.0041],\n",
      "         [ 0.0235],\n",
      "         [-0.0310]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0110],\n",
      "         [ 0.0159],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1792],\n",
      "         [ 0.1163],\n",
      "         [ 0.0829],\n",
      "         ...,\n",
      "         [ 0.1789],\n",
      "         [ 0.1799],\n",
      "         [ 0.1806]],\n",
      "\n",
      "        [[-0.0016],\n",
      "         [ 0.0662],\n",
      "         [-0.0150],\n",
      "         ...,\n",
      "         [-0.0030],\n",
      "         [-0.0030],\n",
      "         [-0.0030]],\n",
      "\n",
      "        [[ 0.0640],\n",
      "         [ 0.0298],\n",
      "         [ 0.1346],\n",
      "         ...,\n",
      "         [ 0.0638],\n",
      "         [ 0.0641],\n",
      "         [ 0.0643]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0903],\n",
      "         [ 0.0194],\n",
      "         [ 0.1415],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0664],\n",
      "         [ 0.0775],\n",
      "         [ 0.0922],\n",
      "         ...,\n",
      "         [ 0.0041],\n",
      "         [ 0.0235],\n",
      "         [-0.0310]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0110],\n",
      "         [ 0.0159],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1792],\n",
      "         [ 0.1163],\n",
      "         [ 0.0829],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0016],\n",
      "         [ 0.0662],\n",
      "         [-0.0150],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0640],\n",
      "         [ 0.0298],\n",
      "         [ 0.1346],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1343],\n",
      "         [ 0.0612],\n",
      "         [ 0.1788],\n",
      "         ...,\n",
      "         [ 0.1391],\n",
      "         [ 0.1391],\n",
      "         [ 0.1391]],\n",
      "\n",
      "        [[ 0.0684],\n",
      "         [ 0.0792],\n",
      "         [ 0.0949],\n",
      "         ...,\n",
      "         [ 0.0049],\n",
      "         [ 0.0251],\n",
      "         [-0.0311]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0110],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1040],\n",
      "         [ 0.0421],\n",
      "         [ 0.0097],\n",
      "         ...,\n",
      "         [ 0.1015],\n",
      "         [ 0.1025],\n",
      "         [ 0.1032]],\n",
      "\n",
      "        [[-0.0154],\n",
      "         [ 0.0515],\n",
      "         [-0.0289],\n",
      "         ...,\n",
      "         [-0.0187],\n",
      "         [-0.0187],\n",
      "         [-0.0187]],\n",
      "\n",
      "        [[ 0.1030],\n",
      "         [ 0.0713],\n",
      "         [ 0.1751],\n",
      "         ...,\n",
      "         [ 0.1010],\n",
      "         [ 0.1013],\n",
      "         [ 0.1014]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1343],\n",
      "         [ 0.0612],\n",
      "         [ 0.1788],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0684],\n",
      "         [ 0.0792],\n",
      "         [ 0.0949],\n",
      "         ...,\n",
      "         [ 0.0049],\n",
      "         [ 0.0251],\n",
      "         [-0.0311]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0110],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1040],\n",
      "         [ 0.0421],\n",
      "         [ 0.0097],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0154],\n",
      "         [ 0.0515],\n",
      "         [-0.0289],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1030],\n",
      "         [ 0.0713],\n",
      "         [ 0.1751],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0897],\n",
      "         [ 0.0187],\n",
      "         [ 0.1410],\n",
      "         ...,\n",
      "         [ 0.0936],\n",
      "         [ 0.0937],\n",
      "         [ 0.0937]],\n",
      "\n",
      "        [[ 0.0937],\n",
      "         [ 0.1051],\n",
      "         [ 0.1208],\n",
      "         ...,\n",
      "         [ 0.0341],\n",
      "         [ 0.0537],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0378],\n",
      "         [-0.0238],\n",
      "         [-0.0542],\n",
      "         ...,\n",
      "         [ 0.0327],\n",
      "         [ 0.0337],\n",
      "         [ 0.0343]],\n",
      "\n",
      "        [[-0.0237],\n",
      "         [ 0.0426],\n",
      "         [-0.0372],\n",
      "         ...,\n",
      "         [-0.0282],\n",
      "         [-0.0282],\n",
      "         [-0.0282]],\n",
      "\n",
      "        [[ 0.0815],\n",
      "         [ 0.0522],\n",
      "         [ 0.1525],\n",
      "         ...,\n",
      "         [ 0.0776],\n",
      "         [ 0.0779],\n",
      "         [ 0.0781]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0897],\n",
      "         [ 0.0187],\n",
      "         [ 0.1410],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0937],\n",
      "         [ 0.1051],\n",
      "         [ 0.1208],\n",
      "         ...,\n",
      "         [ 0.0341],\n",
      "         [ 0.0537],\n",
      "         [-0.0049]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0378],\n",
      "         [-0.0238],\n",
      "         [-0.0542],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0237],\n",
      "         [ 0.0426],\n",
      "         [-0.0372],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0815],\n",
      "         [ 0.0522],\n",
      "         [ 0.1525],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0703],\n",
      "         [ 0.0026],\n",
      "         [ 0.1265],\n",
      "         ...,\n",
      "         [ 0.0696],\n",
      "         [ 0.0697],\n",
      "         [ 0.0697]],\n",
      "\n",
      "        [[ 0.1156],\n",
      "         [ 0.1271],\n",
      "         [ 0.1431],\n",
      "         ...,\n",
      "         [ 0.0589],\n",
      "         [ 0.0785],\n",
      "         [ 0.0172]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0040],\n",
      "         [-0.0572],\n",
      "         [-0.0865],\n",
      "         ...,\n",
      "         [-0.0033],\n",
      "         [-0.0024],\n",
      "         [-0.0018]],\n",
      "\n",
      "        [[-0.0287],\n",
      "         [ 0.0372],\n",
      "         [-0.0421],\n",
      "         ...,\n",
      "         [-0.0339],\n",
      "         [-0.0339],\n",
      "         [-0.0339]],\n",
      "\n",
      "        [[ 0.0444],\n",
      "         [ 0.0147],\n",
      "         [ 0.1156],\n",
      "         ...,\n",
      "         [ 0.0401],\n",
      "         [ 0.0404],\n",
      "         [ 0.0406]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0703],\n",
      "         [ 0.0026],\n",
      "         [ 0.1265],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1156],\n",
      "         [ 0.1271],\n",
      "         [ 0.1431],\n",
      "         ...,\n",
      "         [ 0.0589],\n",
      "         [ 0.0785],\n",
      "         [ 0.0172]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0040],\n",
      "         [-0.0572],\n",
      "         [-0.0865],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0287],\n",
      "         [ 0.0372],\n",
      "         [-0.0421],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0444],\n",
      "         [ 0.0147],\n",
      "         [ 0.1156],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0709],\n",
      "         [ 0.0030],\n",
      "         [ 0.1279],\n",
      "         ...,\n",
      "         [ 0.0689],\n",
      "         [ 0.0689],\n",
      "         [ 0.0689]],\n",
      "\n",
      "        [[ 0.0264],\n",
      "         [ 0.0365],\n",
      "         [ 0.0515],\n",
      "         ...,\n",
      "         [-0.0310],\n",
      "         [-0.0114],\n",
      "         [-0.0703]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0138],\n",
      "         [-0.0749],\n",
      "         [-0.1037],\n",
      "         ...,\n",
      "         [-0.0225],\n",
      "         [-0.0216],\n",
      "         [-0.0209]],\n",
      "\n",
      "        [[-0.0317],\n",
      "         [ 0.0340],\n",
      "         [-0.0451],\n",
      "         ...,\n",
      "         [-0.0373],\n",
      "         [-0.0373],\n",
      "         [-0.0373]],\n",
      "\n",
      "        [[ 0.0136],\n",
      "         [-0.0177],\n",
      "         [ 0.0843],\n",
      "         ...,\n",
      "         [ 0.0113],\n",
      "         [ 0.0116],\n",
      "         [ 0.0118]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0709],\n",
      "         [ 0.0030],\n",
      "         [ 0.1279],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0264],\n",
      "         [ 0.0365],\n",
      "         [ 0.0515],\n",
      "         ...,\n",
      "         [-0.0310],\n",
      "         [-0.0114],\n",
      "         [-0.0703]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0138],\n",
      "         [-0.0749],\n",
      "         [-0.1037],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0317],\n",
      "         [ 0.0340],\n",
      "         [-0.0451],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0136],\n",
      "         [-0.0177],\n",
      "         [ 0.0843],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0699],\n",
      "         [ 0.0026],\n",
      "         [ 0.1280],\n",
      "         ...,\n",
      "         [ 0.0668],\n",
      "         [ 0.0668],\n",
      "         [ 0.0669]],\n",
      "\n",
      "        [[ 0.0704],\n",
      "         [ 0.0807],\n",
      "         [ 0.0965],\n",
      "         ...,\n",
      "         [ 0.0111],\n",
      "         [ 0.0315],\n",
      "         [-0.0284]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0234],\n",
      "         [-0.0845],\n",
      "         [-0.1130],\n",
      "         ...,\n",
      "         [-0.0329],\n",
      "         [-0.0320],\n",
      "         [-0.0313]],\n",
      "\n",
      "        [[-0.0334],\n",
      "         [ 0.0321],\n",
      "         [-0.0469],\n",
      "         ...,\n",
      "         [-0.0393],\n",
      "         [-0.0393],\n",
      "         [-0.0393]],\n",
      "\n",
      "        [[ 0.0676],\n",
      "         [ 0.0379],\n",
      "         [ 0.1400],\n",
      "         ...,\n",
      "         [ 0.0634],\n",
      "         [ 0.0637],\n",
      "         [ 0.0639]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0699],\n",
      "         [ 0.0026],\n",
      "         [ 0.1280],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0704],\n",
      "         [ 0.0807],\n",
      "         [ 0.0965],\n",
      "         ...,\n",
      "         [ 0.0111],\n",
      "         [ 0.0315],\n",
      "         [-0.0284]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0234],\n",
      "         [-0.0845],\n",
      "         [-0.1130],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0334],\n",
      "         [ 0.0321],\n",
      "         [-0.0469],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0676],\n",
      "         [ 0.0379],\n",
      "         [ 0.1400],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1023],\n",
      "         [ 0.0327],\n",
      "         [ 0.1558],\n",
      "         ...,\n",
      "         [ 0.1021],\n",
      "         [ 0.1021],\n",
      "         [ 0.1022]],\n",
      "\n",
      "        [[ 0.1067],\n",
      "         [ 0.1172],\n",
      "         [ 0.1335],\n",
      "         ...,\n",
      "         [ 0.0450],\n",
      "         [ 0.0656],\n",
      "         [ 0.0063]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0287],\n",
      "         [-0.0898],\n",
      "         [-0.1182],\n",
      "         ...,\n",
      "         [-0.0386],\n",
      "         [-0.0377],\n",
      "         [-0.0370]],\n",
      "\n",
      "        [[-0.0345],\n",
      "         [ 0.0309],\n",
      "         [-0.0480],\n",
      "         ...,\n",
      "         [-0.0405],\n",
      "         [-0.0405],\n",
      "         [-0.0405]],\n",
      "\n",
      "        [[ 0.0429],\n",
      "         [ 0.0133],\n",
      "         [ 0.1166],\n",
      "         ...,\n",
      "         [ 0.0388],\n",
      "         [ 0.0391],\n",
      "         [ 0.0393]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.1023],\n",
      "         [ 0.0327],\n",
      "         [ 0.1558],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.1067],\n",
      "         [ 0.1172],\n",
      "         [ 0.1335],\n",
      "         ...,\n",
      "         [ 0.0450],\n",
      "         [ 0.0656],\n",
      "         [ 0.0063]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0287],\n",
      "         [-0.0898],\n",
      "         [-0.1182],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0345],\n",
      "         [ 0.0309],\n",
      "         [-0.0480],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0429],\n",
      "         [ 0.0133],\n",
      "         [ 0.1166],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0491],\n",
      "         [-0.0164],\n",
      "         [ 0.1087],\n",
      "         ...,\n",
      "         [ 0.0454],\n",
      "         [ 0.0454],\n",
      "         [ 0.0454]],\n",
      "\n",
      "        [[ 0.0846],\n",
      "         [ 0.0939],\n",
      "         [ 0.1090],\n",
      "         ...,\n",
      "         [ 0.0345],\n",
      "         [ 0.0540],\n",
      "         [-0.0099]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0315],\n",
      "         [-0.0928],\n",
      "         [-0.1210],\n",
      "         ...,\n",
      "         [-0.0417],\n",
      "         [-0.0408],\n",
      "         [-0.0402]],\n",
      "\n",
      "        [[-0.0352],\n",
      "         [ 0.0302],\n",
      "         [-0.0486],\n",
      "         ...,\n",
      "         [-0.0413],\n",
      "         [-0.0413],\n",
      "         [-0.0413]],\n",
      "\n",
      "        [[ 0.0413],\n",
      "         [ 0.0134],\n",
      "         [ 0.1132],\n",
      "         ...,\n",
      "         [ 0.0352],\n",
      "         [ 0.0355],\n",
      "         [ 0.0357]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0491],\n",
      "         [-0.0164],\n",
      "         [ 0.1087],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0846],\n",
      "         [ 0.0939],\n",
      "         [ 0.1090],\n",
      "         ...,\n",
      "         [ 0.0345],\n",
      "         [ 0.0540],\n",
      "         [-0.0099]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0315],\n",
      "         [-0.0928],\n",
      "         [-0.1210],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0352],\n",
      "         [ 0.0302],\n",
      "         [-0.0486],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0413],\n",
      "         [ 0.0134],\n",
      "         [ 0.1132],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0323],\n",
      "         [-0.0356],\n",
      "         [ 0.0915],\n",
      "         ...,\n",
      "         [ 0.0293],\n",
      "         [ 0.0294],\n",
      "         [ 0.0294]],\n",
      "\n",
      "        [[ 0.0917],\n",
      "         [ 0.1020],\n",
      "         [ 0.1174],\n",
      "         ...,\n",
      "         [ 0.0351],\n",
      "         [ 0.0550],\n",
      "         [-0.0059]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0331],\n",
      "         [-0.0944],\n",
      "         [-0.1226],\n",
      "         ...,\n",
      "         [-0.0434],\n",
      "         [-0.0425],\n",
      "         [-0.0418]],\n",
      "\n",
      "        [[-0.0355],\n",
      "         [ 0.0298],\n",
      "         [-0.0490],\n",
      "         ...,\n",
      "         [-0.0417],\n",
      "         [-0.0417],\n",
      "         [-0.0417]],\n",
      "\n",
      "        [[ 0.0940],\n",
      "         [ 0.0623],\n",
      "         [ 0.1655],\n",
      "         ...,\n",
      "         [ 0.0918],\n",
      "         [ 0.0921],\n",
      "         [ 0.0923]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0323],\n",
      "         [-0.0356],\n",
      "         [ 0.0915],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0917],\n",
      "         [ 0.1020],\n",
      "         [ 0.1174],\n",
      "         ...,\n",
      "         [ 0.0351],\n",
      "         [ 0.0550],\n",
      "         [-0.0059]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0331],\n",
      "         [-0.0944],\n",
      "         [-0.1226],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0355],\n",
      "         [ 0.0298],\n",
      "         [-0.0490],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0940],\n",
      "         [ 0.0623],\n",
      "         [ 0.1655],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0486],\n",
      "         [-0.0204],\n",
      "         [ 0.1035],\n",
      "         ...,\n",
      "         [ 0.0485],\n",
      "         [ 0.0485],\n",
      "         [ 0.0485]],\n",
      "\n",
      "        [[ 0.0504],\n",
      "         [ 0.0611],\n",
      "         [ 0.0776],\n",
      "         ...,\n",
      "         [-0.0016],\n",
      "         [ 0.0183],\n",
      "         [-0.0474]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0340],\n",
      "         [-0.0952],\n",
      "         [-0.1235],\n",
      "         ...,\n",
      "         [-0.0443],\n",
      "         [-0.0434],\n",
      "         [-0.0428]],\n",
      "\n",
      "        [[-0.0358],\n",
      "         [ 0.0296],\n",
      "         [-0.0493],\n",
      "         ...,\n",
      "         [-0.0420],\n",
      "         [-0.0420],\n",
      "         [-0.0420]],\n",
      "\n",
      "        [[-0.0552],\n",
      "         [-0.0815],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0622],\n",
      "         [-0.0620],\n",
      "         [-0.0618]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0486],\n",
      "         [-0.0204],\n",
      "         [ 0.1035],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0504],\n",
      "         [ 0.0611],\n",
      "         [ 0.0776],\n",
      "         ...,\n",
      "         [-0.0016],\n",
      "         [ 0.0183],\n",
      "         [-0.0474]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0340],\n",
      "         [-0.0952],\n",
      "         [-0.1235],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0358],\n",
      "         [ 0.0296],\n",
      "         [-0.0493],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0552],\n",
      "         [-0.0815],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0136],\n",
      "         [-0.0539],\n",
      "         [ 0.0714],\n",
      "         ...,\n",
      "         [ 0.0107],\n",
      "         [ 0.0108],\n",
      "         [ 0.0108]],\n",
      "\n",
      "        [[ 0.0003],\n",
      "         [ 0.0108],\n",
      "         [ 0.0267],\n",
      "         ...,\n",
      "         [-0.0502],\n",
      "         [-0.0306],\n",
      "         [-0.0956]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0344],\n",
      "         [-0.0957],\n",
      "         [-0.1239],\n",
      "         ...,\n",
      "         [-0.0448],\n",
      "         [-0.0439],\n",
      "         [-0.0433]],\n",
      "\n",
      "        [[-0.0359],\n",
      "         [ 0.0294],\n",
      "         [-0.0494],\n",
      "         ...,\n",
      "         [-0.0422],\n",
      "         [-0.0422],\n",
      "         [-0.0422]],\n",
      "\n",
      "        [[ 0.0049],\n",
      "         [-0.0201],\n",
      "         [ 0.0772],\n",
      "         ...,\n",
      "         [-0.0042],\n",
      "         [-0.0040],\n",
      "         [-0.0038]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[ 0.0136],\n",
      "         [-0.0539],\n",
      "         [ 0.0714],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0003],\n",
      "         [ 0.0108],\n",
      "         [ 0.0267],\n",
      "         ...,\n",
      "         [-0.0502],\n",
      "         [-0.0306],\n",
      "         [-0.0956]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0344],\n",
      "         [-0.0957],\n",
      "         [-0.1239],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0359],\n",
      "         [ 0.0294],\n",
      "         [-0.0494],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0049],\n",
      "         [-0.0201],\n",
      "         [ 0.0772],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0046],\n",
      "         [-0.0711],\n",
      "         [ 0.0555],\n",
      "         ...,\n",
      "         [-0.0094],\n",
      "         [-0.0094],\n",
      "         [-0.0093]],\n",
      "\n",
      "        [[-0.0021],\n",
      "         [ 0.0077],\n",
      "         [ 0.0231],\n",
      "         ...,\n",
      "         [-0.0526],\n",
      "         [-0.0330],\n",
      "         [-0.0976]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0347],\n",
      "         [-0.0960],\n",
      "         [-0.1242],\n",
      "         ...,\n",
      "         [-0.0450],\n",
      "         [-0.0441],\n",
      "         [-0.0435]],\n",
      "\n",
      "        [[-0.0360],\n",
      "         [ 0.0293],\n",
      "         [-0.0495],\n",
      "         ...,\n",
      "         [-0.0423],\n",
      "         [-0.0423],\n",
      "         [-0.0423]],\n",
      "\n",
      "        [[-0.0124],\n",
      "         [-0.0419],\n",
      "         [ 0.0582],\n",
      "         ...,\n",
      "         [-0.0170],\n",
      "         [-0.0168],\n",
      "         [-0.0166]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0046],\n",
      "         [-0.0711],\n",
      "         [ 0.0555],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0021],\n",
      "         [ 0.0077],\n",
      "         [ 0.0231],\n",
      "         ...,\n",
      "         [-0.0526],\n",
      "         [-0.0330],\n",
      "         [-0.0976]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0347],\n",
      "         [-0.0960],\n",
      "         [-0.1242],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0360],\n",
      "         [ 0.0293],\n",
      "         [-0.0495],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0124],\n",
      "         [-0.0419],\n",
      "         [ 0.0582],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n",
      "че происходит в AttentionLayer: at до применения маски:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0144],\n",
      "         [-0.0804],\n",
      "         [ 0.0472],\n",
      "         ...,\n",
      "         [-0.0204],\n",
      "         [-0.0203],\n",
      "         [-0.0203]],\n",
      "\n",
      "        [[ 0.0323],\n",
      "         [ 0.0429],\n",
      "         [ 0.0582],\n",
      "         ...,\n",
      "         [-0.0253],\n",
      "         [-0.0056],\n",
      "         [-0.0651]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0231],\n",
      "         [-0.0231],\n",
      "         [-0.0231]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0348],\n",
      "         [-0.0961],\n",
      "         [-0.1243],\n",
      "         ...,\n",
      "         [-0.0452],\n",
      "         [-0.0443],\n",
      "         [-0.0436]],\n",
      "\n",
      "        [[-0.0361],\n",
      "         [ 0.0292],\n",
      "         [-0.0496],\n",
      "         ...,\n",
      "         [-0.0424],\n",
      "         [-0.0424],\n",
      "         [-0.0424]],\n",
      "\n",
      "        [[ 0.0333],\n",
      "         [ 0.0008],\n",
      "         [ 0.1053],\n",
      "         ...,\n",
      "         [ 0.0321],\n",
      "         [ 0.0324],\n",
      "         [ 0.0326]]], grad_fn=<AddBackward0>)\n",
      "после применения:\n",
      "torch.FloatTensor\n",
      "tensor([[[-0.0144],\n",
      "         [-0.0804],\n",
      "         [ 0.0472],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0323],\n",
      "         [ 0.0429],\n",
      "         [ 0.0582],\n",
      "         ...,\n",
      "         [-0.0253],\n",
      "         [-0.0056],\n",
      "         [-0.0651]],\n",
      "\n",
      "        [[-0.0171],\n",
      "         [ 0.0109],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0348],\n",
      "         [-0.0961],\n",
      "         [-0.1243],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[-0.0361],\n",
      "         [ 0.0292],\n",
      "         [-0.0496],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]],\n",
      "\n",
      "        [[ 0.0333],\n",
      "         [ 0.0008],\n",
      "         [ 0.1053],\n",
      "         ...,\n",
      "         [   -inf],\n",
      "         [   -inf],\n",
      "         [   -inf]]], grad_fn=<IndexPutBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/25000 [00:04<4:15:08,  1.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20992/2289265608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mloss_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in trange(25000):\n",
    "    step = len(attn_metrics['train_loss']) + 1\n",
    "    batch_ix = np.random.randint(len(train_inp), size=batch_size)\n",
    "    batch_inp = inp_voc.to_matrix(train_inp[batch_ix]).to(device)\n",
    "    batch_out = out_voc.to_matrix(train_out[batch_ix]).to(device)\n",
    "    \n",
    "    loss_t = compute_loss(attn_model, batch_inp, batch_out)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss_t.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    attn_metrics['train_loss'].append((step, loss_t.item()))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        attn_metrics['dev_bleu'].append((step, compute_bleu(attn_model, dev_inp, dev_out)))\n",
    "        \n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,4))\n",
    "        for i, (name, history) in enumerate(sorted(attn_metrics.items())):\n",
    "            plt.subplot(1, len(attn_metrics), i + 1)\n",
    "            plt.title(name)\n",
    "            plt.plot(*zip(*history))\n",
    "            plt.grid()\n",
    "        plt.show()\n",
    "        print(\"Mean loss=%.3f\" % np.mean(attn_metrics['train_loss'][-10:], axis=0)[1], flush=True)\n",
    "        \n",
    "# Note: it's okay if bleu oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(attn_model, open(\"attention_concat_passzeros\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(metrics, open(\"metrics\", \"wb\"))\n",
    "pickle.dump(attn_metrics, open(\"attn_metrics\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 17.836467678280236)\n",
      "(25000, 23.82235468968225)\n"
     ]
    }
   ],
   "source": [
    "# <YOUR CODE: measure final BLEU>\n",
    "print(metrics[\"dev_bleu\"][-1])\n",
    "print(attn_metrics[\"dev_bleu\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"BLEU evaluation comparison\")\n",
    "\n",
    "gru_keys = [x[0] for x in metrics['dev_bleu']]\n",
    "gru_vals = gaussian_filter1d([x[1] for x in metrics['dev_bleu']], sigma=10)\n",
    "\n",
    "attn_keys = [x[0] for x in attn_metrics['dev_bleu']]\n",
    "attn_vals = gaussian_filter1d([x[1] for x in attn_metrics['dev_bleu']], sigma=10)\n",
    "\n",
    "plt.plot(gru_keys, gru_vals, c='red', label=\"gru, no attention\")\n",
    "plt.plot(attn_keys, attn_vals, c='blue', label=\"gru, attention with concat and passzeros\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing model attention (2 points)\n",
    "\n",
    "After training the attentive translation model, you can check it's sanity by visualizing its attention weights.\n",
    "\n",
    "We provided you with a function that draws attention maps using [`Bokeh`](https://bokeh.pydata.org/en/latest/index.html). Once you managed to produce something better than random noise, please save at least 3 attention maps and __submit them to anytask__ alongside this notebook to get the max grade. Saving bokeh figures as __cell outputs is not enough!__ (TAs can't see saved bokeh figures in anytask). You can save bokeh images as screenshots or using this button:\n",
    "\n",
    "![bokeh_panel](https://github.com/yandexdataschool/nlp_course/raw/2019/resources/bokeh_panel.png)\n",
    "\n",
    "__Note:__ you're not locked into using bokeh. If you prefer a different visualization method, feel free to use that instead of bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"83656\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"83656\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"83656\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"83656\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"83656\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting as pl\n",
    "import bokeh.models as bm\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()\n",
    "\n",
    "def draw_attention(inp_line, translation, probs):\n",
    "    \"\"\" An intentionally ambiguous function to visualize attention weights \"\"\"\n",
    "    inp_tokens = inp_voc.tokenize(inp_line)\n",
    "    trans_tokens = out_voc.tokenize(translation)\n",
    "    probs = probs[:len(trans_tokens), :len(inp_tokens)]\n",
    "    \n",
    "    fig = pl.figure(x_range=(0, len(inp_tokens)), y_range=(0, len(trans_tokens)),\n",
    "                    x_axis_type=None, y_axis_type=None, tools=[])\n",
    "    fig.image([probs[::-1]], 0, 0, len(inp_tokens), len(trans_tokens))\n",
    "\n",
    "    fig.add_layout(bm.LinearAxis(axis_label='source tokens'), 'above')\n",
    "    fig.xaxis.ticker = np.arange(len(inp_tokens)) + 0.5\n",
    "    fig.xaxis.major_label_overrides = dict(zip(np.arange(len(inp_tokens)) + 0.5, inp_tokens))\n",
    "    fig.xaxis.major_label_orientation = 45\n",
    "\n",
    "    fig.add_layout(bm.LinearAxis(axis_label='translation tokens'), 'left')\n",
    "    fig.yaxis.ticker = np.arange(len(trans_tokens)) + 0.5\n",
    "    fig.yaxis.major_label_overrides = dict(zip(np.arange(len(trans_tokens)) + 0.5, trans_tokens[::-1]))\n",
    "    \n",
    "    show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = dev_inp[::500]\n",
    "\n",
    "trans, states = attn_model.translate_lines(inp)\n",
    "\n",
    "# select attention probs from model state (you may need to change this for your custom model)\n",
    "# attention_probs below must have shape [batch_size, translation_length, input_length], extracted from states\n",
    "# e.g. if attention probs are at the end of each state, use np.stack([state[-1] for state in states], axis=1)\n",
    "attention_probs = np.stack([state[-1][:,:,0].detach().cpu().numpy() for i, state in enumerate(states)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"f4abb492-293c-45b8-9504-8efdac124a86\" data-root-id=\"83657\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"3e7a5715-e2d2-4db1-9bab-d2b84d746981\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"above\":[{\"id\":\"83679\"}],\"left\":[{\"id\":\"83682\"}],\"renderers\":[{\"id\":\"83677\"}],\"title\":{\"id\":\"84765\"},\"toolbar\":{\"id\":\"83666\"},\"x_range\":{\"id\":\"83658\"},\"x_scale\":{\"id\":\"83662\"},\"y_range\":{\"id\":\"83660\"},\"y_scale\":{\"id\":\"83664\"}},\"id\":\"83657\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"84768\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"84770\",\"type\":\"AllLabels\"},{\"attributes\":{\"axis_label\":\"source tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"84769\"},\"group\":null,\"major_label_orientation\":45,\"major_label_overrides\":{\"0.5\":\"_BOS_\",\"1.5\":\"\\u0432\",\"10.5\":\"_EOS_\",\"2.5\":\"\\u0440\\u0430\\u0441\\u043f\\u043e\\u0440\\u044f\\u0436\\u0435\\u043d\\u0438\\u0438\",\"3.5\":\"\\u0433\\u043e\\u0441\\u0442\\u0435\\u0439\",\"4.5\":\"\\u043e\\u0431\\u0449\\u0430\\u044f\",\"5.5\":\"\\u043a\\u0443\\u0445\\u043d\\u044f\",\"6.5\":\"\\u0438\",\"7.5\":\"\\u043e\\u0431\\u0449\\u0430\\u044f\",\"8.5\":\"\\u0433\\u043e\\u0441\\u0442\\u0438\\u043d\\u0430\\u044f\",\"9.5\":\".\"},\"major_label_policy\":{\"id\":\"84770\"},\"ticker\":{\"id\":\"83680\"}},\"id\":\"83679\",\"type\":\"LinearAxis\"},{\"attributes\":{\"color_mapper\":{\"id\":\"83672\"},\"dh\":{\"value\":12},\"dw\":{\"value\":11},\"global_alpha\":{\"value\":0.1},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"83671\",\"type\":\"Image\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"83667\"},\"glyph\":{\"id\":\"83668\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"83674\"},\"nonselection_glyph\":{\"id\":\"83671\"},\"view\":{\"id\":\"83678\"}},\"id\":\"83677\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"84772\",\"type\":\"Selection\"},{\"attributes\":{\"color_mapper\":{\"id\":\"83675\"},\"dh\":{\"value\":12},\"dw\":{\"value\":11},\"global_alpha\":{\"value\":0.2},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"83674\",\"type\":\"Image\"},{\"attributes\":{\"end\":12},\"id\":\"83660\",\"type\":\"Range1d\"},{\"attributes\":{\"end\":11},\"id\":\"83658\",\"type\":\"Range1d\"},{\"attributes\":{\"source\":{\"id\":\"83667\"}},\"id\":\"83678\",\"type\":\"CDSView\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"84765\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"83662\",\"type\":\"LinearScale\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5]},\"id\":\"83683\",\"type\":\"FixedTicker\"},{\"attributes\":{},\"id\":\"83666\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"84771\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"83675\",\"type\":\"LinearColorMapper\"},{\"attributes\":{\"data\":{\"image\":[{\"__ndarray__\":\"/zgQO81yizx6/147th2KOUk3LD0a94E9USLYPKtbpz0No14+nVAfPkjwxz7ExBo+7ZevPG4PQTyW0pw8kzMfPd5flzyIwac7+4u7PL1b9zySRno9260eP7GJgjumD/46UqtFO+baKTvzug08Q89TPNulRDtKB7w8ZIsTPd+B8z1jOEk/EbNLN0MpTjnQ2CA5Nu9WODDkPDtUGTg8d/irO5d3GT22doY9a1RLPkS0LT8sHws1JGlANhTakjZnODY3+cChOtl+HDuFAbU7gbsEP0bLkz4UJxk+xMcLPWDuMDuSPEQ6vn4tO7m6+zohg6k8+s22PAL8CT7KsXw9weLjPjD42z1s1kw+Wg+7OAkmvTmAyHE6yyQ/OlNIzzyo2gI+IRiVPvQ01T2Cl6g+5yCdPdwsMj1eWjQ3VaifOb8eiTkuer85fkYlPdprwz41tLM+WuiJPAvM1T3eDmI9QUJLPRcfijdijjw4iPtHOsVqcjlwvpk9jnHIPlqeqj6zCSM7uLLmPFcUFT63q7s8vOQqOvi20TsjqQg8rosSPB6YDD8Xmzc+9p27PXGqRz1KTSs9SgoyPYpIsDx4s3U7EG4nPWg0YT6093A9EBYnPsrOnz4QjLA92/y8O9NmmjzTuXU9xPP5PBbjtTp1T7k8SwpcPW+ciz3HTbM9qlysPpT9Lz7KZhM90usEPmqFpj2SNzM8\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[12,11]}]},\"selected\":{\"id\":\"84772\"},\"selection_policy\":{\"id\":\"84771\"}},\"id\":\"83667\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"83669\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"84767\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"83664\",\"type\":\"LinearScale\"},{\"attributes\":{\"color_mapper\":{\"id\":\"83669\"},\"dh\":{\"value\":12},\"dw\":{\"value\":11},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"83668\",\"type\":\"Image\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5]},\"id\":\"83680\",\"type\":\"FixedTicker\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"83672\",\"type\":\"LinearColorMapper\"},{\"attributes\":{\"axis_label\":\"translation tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"84767\"},\"group\":null,\"major_label_overrides\":{\"0.5\":\"_EOS_\",\"1.5\":\".\",\"10.5\":\"there\",\"11.5\":\"_BOS_\",\"2.5\":\"lounge\",\"3.5\":\"shared\",\"4.5\":\"a\",\"5.5\":\"and\",\"6.5\":\"kitchen\",\"7.5\":\"shared\",\"8.5\":\"a\",\"9.5\":\"is\"},\"major_label_policy\":{\"id\":\"84768\"},\"ticker\":{\"id\":\"83683\"}},\"id\":\"83682\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"84769\",\"type\":\"BasicTickFormatter\"}],\"root_ids\":[\"83657\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "  const render_items = [{\"docid\":\"3e7a5715-e2d2-4db1-9bab-d2b84d746981\",\"root_ids\":[\"83657\"],\"roots\":{\"83657\":\"f4abb492-293c-45b8-9504-8efdac124a86\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "83657"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"7c79f101-7a4f-4e34-8a6a-30bd0c6281b7\" data-root-id=\"84813\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"152c3fde-2367-428d-bc86-fb9812d95576\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"above\":[{\"id\":\"84835\"}],\"left\":[{\"id\":\"84838\"}],\"renderers\":[{\"id\":\"84833\"}],\"title\":{\"id\":\"85929\"},\"toolbar\":{\"id\":\"84822\"},\"x_range\":{\"id\":\"84814\"},\"x_scale\":{\"id\":\"84818\"},\"y_range\":{\"id\":\"84816\"},\"y_scale\":{\"id\":\"84820\"}},\"id\":\"84813\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"84822\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"85932\",\"type\":\"AllLabels\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5,13.5,14.5]},\"id\":\"84836\",\"type\":\"FixedTicker\"},{\"attributes\":{\"source\":{\"id\":\"84823\"}},\"id\":\"84834\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"85936\",\"type\":\"Selection\"},{\"attributes\":{\"axis_label\":\"source tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"85933\"},\"group\":null,\"major_label_orientation\":45,\"major_label_overrides\":{\"0.5\":\"_BOS_\",\"1.5\":\"\\u043a\\u0440\\u043e\\u043c\\u0435\",\"10.5\":\"\\u0438\",\"11.5\":\"\\u0431\\u0435\\u0441\\u043f\\u043b\\u0430\\u0442\\u043d\\u0430\\u044f\",\"12.5\":\"\\u043f\\u0430\\u0440\\u043a\\u043e\\u0432\\u043a\\u0430\",\"13.5\":\".\",\"14.5\":\"_EOS_\",\"2.5\":\"\\u0442\\u043e\\u0433\\u043e\",\"3.5\":\",\",\"4.5\":\"\\u043f\\u0440\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f\",\"5.5\":\"\\u043f\\u0440\\u043e\\u043a\\u0430\\u0442\",\"6.5\":\"\\u0432\\u0435\\u043b\\u043e\\u0441\\u0438\\u043f\\u0435\\u0434\\u043e\\u0432\",\"7.5\":\",\",\"8.5\":\"\\u0443\\u0441\\u043b\\u0443\\u0433\\u0438\",\"9.5\":\"\\u0442\\u0440\\u0430\\u043d\\u0441\\u0444\\u0435\\u0440\\u0430\"},\"major_label_policy\":{\"id\":\"85934\"},\"ticker\":{\"id\":\"84836\"}},\"id\":\"84835\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"85931\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"84818\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"85934\",\"type\":\"AllLabels\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"84831\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"85933\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"84825\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"84820\",\"type\":\"LinearScale\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"84823\"},\"glyph\":{\"id\":\"84824\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"84830\"},\"nonselection_glyph\":{\"id\":\"84827\"},\"view\":{\"id\":\"84834\"}},\"id\":\"84833\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"color_mapper\":{\"id\":\"84828\"},\"dh\":{\"value\":15},\"dw\":{\"value\":15},\"global_alpha\":{\"value\":0.1},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"84827\",\"type\":\"Image\"},{\"attributes\":{},\"id\":\"85935\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data\":{\"image\":[{\"__ndarray__\":\"QzKoO4wZqDvbLVM7kAdvO7PCezvvrh482DSKOlcevzkIOCc8JglnPFphxz1SU0k6K3LqPFUu0D3VGDc/hBLXPtjuVD530M89HMicPOjqujydyzg70Nq7OvCAvDo+Uls8DdRFPMvGqjsaMsU7mrIVPDvJKjy5nyo+RhcCPJu8SzoAUQk8VyqiOtmKZDxlBgM6WXX4Our01TrrcBg8NliAPORjgjsvOOc7F/UmPfVfnT0rYU8/pmwHOAliazXqcGg3muK+NmaTSjilM7Y3qyaZOGTIlDeczBc6CC1qPMuJRzwyzUQ7h1olPrQN4j7Uxbs+3+JIO9cZyjzlbdI8DujxPZTY9TxeVQU9weLRPArrZDwUHik+JbaAPcuH+z3tdMM8TI1APnKjQD1atO49X9w8NkQtHzcMPdE3dCy7OPauNjkv1Bs7gLv4O3u5jTstzU49uNmGPU8dOD+13Vo6R+QqO0fgQTxb1Ak+uKSpN59wjTl3VUE5MvO3OWUwTjur8HA88EIpPCaGhDuJbp49bQAZPnZONj8svg87o+ZHO0kStzuN9ow8tplUPI56ejzAao48/DlNPRvZrjxG/IQ8CjENPXkdkD2rjwc+utYLPuKg0j4Po0E8rQGBPDSYpzyrHgk9LRw+OWBKeDumSVw50lYmOm0EPDqdSSU8NGnDPCflpD2uTug+r0WKPntLFD5hz0k6A08fO0iObTssApY7TJR8OETCJjjKzY85w4wROnNB9DpJULM98WtzPmENqD3UktQ+c82gPRzBrD0y7Vs42nU0OlBZpDtJ5MY7W6rKOHtD5ToyGnQ6TopHO9QtHzvvAEY9xiaYPrNhmT6YW4k+iJh4PbZgWDwIpm45RMhNOgUhHjveVIs6fBbEOfwe7zrzUMY62y8+PPIdQztdQcg95TlNPlaUaz57o7A+qpG9PUQoFDyrDmY6EOj5OiolVDt/+Vc6CLAxO8cBqzy1IGE7tfe7OyEh9DsFnbo9V8EPPjTVJT6irqw+ANNAPlQMsTyHa7Y6s5pFOwXefztfojE8RgWSOw2EdTxu4vM76u+0PCLz0zzIQag9zONjPnZECT7Amqs+Zw2vPQA7Rj2UE+k5Q+WdO78fDzxmlFw7tGKPOVjVUjx9+b48smzWPICAjT1msx89eaG3PoQArT6HXXo9ELFBPCjmwzygQ3M6rZgdPJlxwDwgePE6\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[15,15]}]},\"selected\":{\"id\":\"85936\"},\"selection_policy\":{\"id\":\"85935\"}},\"id\":\"84823\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"end\":15},\"id\":\"84814\",\"type\":\"Range1d\"},{\"attributes\":{\"end\":15},\"id\":\"84816\",\"type\":\"Range1d\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"85929\",\"type\":\"Title\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5,13.5,14.5]},\"id\":\"84839\",\"type\":\"FixedTicker\"},{\"attributes\":{\"axis_label\":\"translation tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"85931\"},\"group\":null,\"major_label_overrides\":{\"0.5\":\"_EOS_\",\"1.5\":\".\",\"10.5\":\"offers\",\"11.5\":\"also\",\"12.5\":\"hotel\",\"13.5\":\"the\",\"14.5\":\"_BOS_\",\"2.5\":\"parking\",\"3.5\":\"free\",\"4.5\":\"and\",\"5.5\":\"shuttle\",\"6.5\":\"a\",\"7.5\":\",\",\"8.5\":\"rental\",\"9.5\":\"bike\"},\"major_label_policy\":{\"id\":\"85932\"},\"ticker\":{\"id\":\"84839\"}},\"id\":\"84838\",\"type\":\"LinearAxis\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"84828\",\"type\":\"LinearColorMapper\"},{\"attributes\":{\"color_mapper\":{\"id\":\"84825\"},\"dh\":{\"value\":15},\"dw\":{\"value\":15},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"84824\",\"type\":\"Image\"},{\"attributes\":{\"color_mapper\":{\"id\":\"84831\"},\"dh\":{\"value\":15},\"dw\":{\"value\":15},\"global_alpha\":{\"value\":0.2},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"84830\",\"type\":\"Image\"}],\"root_ids\":[\"84813\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "  const render_items = [{\"docid\":\"152c3fde-2367-428d-bc86-fb9812d95576\",\"root_ids\":[\"84813\"],\"roots\":{\"84813\":\"7c79f101-7a4f-4e34-8a6a-30bd0c6281b7\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "84813"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"e1ee2c6f-68cd-46fd-8edb-124525d20be8\" data-root-id=\"85977\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"f6b68e80-42ca-4ec7-9b7e-fd282f4fae64\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"above\":[{\"id\":\"85999\"}],\"left\":[{\"id\":\"86002\"}],\"renderers\":[{\"id\":\"85997\"}],\"title\":{\"id\":\"87101\"},\"toolbar\":{\"id\":\"85986\"},\"x_range\":{\"id\":\"85978\"},\"x_scale\":{\"id\":\"85982\"},\"y_range\":{\"id\":\"85980\"},\"y_scale\":{\"id\":\"85984\"}},\"id\":\"85977\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"87106\",\"type\":\"AllLabels\"},{\"attributes\":{\"color_mapper\":{\"id\":\"85989\"},\"dh\":{\"value\":11},\"dw\":{\"value\":13},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"85988\",\"type\":\"Image\"},{\"attributes\":{\"color_mapper\":{\"id\":\"85992\"},\"dh\":{\"value\":11},\"dw\":{\"value\":13},\"global_alpha\":{\"value\":0.1},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"85991\",\"type\":\"Image\"},{\"attributes\":{},\"id\":\"87105\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"color_mapper\":{\"id\":\"85995\"},\"dh\":{\"value\":11},\"dw\":{\"value\":13},\"global_alpha\":{\"value\":0.2},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"85994\",\"type\":\"Image\"},{\"attributes\":{\"source\":{\"id\":\"85987\"}},\"id\":\"85998\",\"type\":\"CDSView\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"85989\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"85982\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"85986\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"87107\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data\":{\"image\":[{\"__ndarray__\":\"rJQ4O3Qg4D0oYuQ7FCKNPgozYz3a7Jc+1F/PPZ4z7Dyh9rY8d8u9PPXXoTwP6U47B+pePRtdCT7AVw09jzi1PItdOT1A8aA9S5IqPpQb4Dx1bWw93UrjPCXfpj0SiuE9aRczPFtVUD6Wg6E7lerOO2PzWzy9Sp0+qP6UPYZ10D66i5w8sD3BO++rTzxX7pY8L7ucOxvOpjt/Wvo9QonWPN42sDwctFU9s+3RPhumIT3aiU8+5WfAPIkVjDymsmY9MuClPcVQHTzcHKE7JIdjPZA5Gj5Eu8U9SJd+PfFxxT0rcgA+h1lHPhS6Hj3NT0A9nVWmPCFj7Dx9MLI72n5cPJmW9j0GDc07pViRO71t2zynpqo9DaYOPeEBGz02XVQ8RZaLPEvi0zwl/Ts+hX/rPey1Aj1EIdc+WyzjOYyuljgsWB46y9H+OkS0xjmE5RE60lF2OfMFsznCbSI6czGRPOFqaj/pfC49Pv+ZPJHt4jo4Pi46dViWO4PZCj2zNUs81QIqPFR1kTsqczQ8ppInPRuhtT3zsBE/oyVNPfM5MD4F/Ns74OpFPDmrWD281A4/8NgHPtOomj2g9ug8MCLxPDqEMT3tINU8vTASPED9PzwUs2o8kF4pOrfk/DvymB49CVm4PkfhLT6s+CE+1xs3PauNPj2NdLw9jNlKPGefvDzMo788zhS7PLUCXzqh1zY6lOtwO5aLuTuqYzE+MP6oPvElmT0AQtc8w2PrPd5fKj4lIQ09dCECPcBxGD0=\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[11,13]}]},\"selected\":{\"id\":\"87108\"},\"selection_policy\":{\"id\":\"87107\"}},\"id\":\"85987\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"87103\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"end\":11},\"id\":\"85980\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"87104\",\"type\":\"AllLabels\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"87101\",\"type\":\"Title\"},{\"attributes\":{\"end\":13},\"id\":\"85978\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"87108\",\"type\":\"Selection\"},{\"attributes\":{\"axis_label\":\"translation tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"87103\"},\"group\":null,\"major_label_overrides\":{\"0.5\":\"_EOS_\",\"1.5\":\".\",\"10.5\":\"_BOS_\",\"2.5\":\"property\",\"3.5\":\"the\",\"4.5\":\"from\",\"5.5\":\"km\",\"6.5\":\"26\",\"7.5\":\"is\",\"8.5\":\"town\",\"9.5\":\"the\"},\"major_label_policy\":{\"id\":\"87104\"},\"ticker\":{\"id\":\"86003\"}},\"id\":\"86002\",\"type\":\"LinearAxis\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5]},\"id\":\"86003\",\"type\":\"FixedTicker\"},{\"attributes\":{},\"id\":\"85984\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis_label\":\"source tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"87105\"},\"group\":null,\"major_label_orientation\":45,\"major_label_overrides\":{\"0.5\":\"_BOS_\",\"1.5\":\"\\u0440\\u0430\\u0441\\u0441\\u0442\\u043e\\u044f\\u043d\\u0438\\u0435\",\"10.5\":\"\\u043a\\u043c\",\"11.5\":\".\",\"12.5\":\"_EOS_\",\"2.5\":\"\\u0434\\u043e\",\"3.5\":\"\\u0433\\u043e\\u0440\\u043e\\u0434\\u0430\",\"4.5\":\"\\u043a\\u0438@@\",\"5.5\":\"\\u0441\\u0441\\u0438@@\",\"6.5\":\"\\u043c@@\",\"7.5\":\"\\u043c\\u0438\",\"8.5\":\"\\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u043b\\u044f\\u0435\\u0442\",\"9.5\":\"26\"},\"major_label_policy\":{\"id\":\"87106\"},\"ticker\":{\"id\":\"86000\"}},\"id\":\"85999\",\"type\":\"LinearAxis\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5]},\"id\":\"86000\",\"type\":\"FixedTicker\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"85992\",\"type\":\"LinearColorMapper\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"85987\"},\"glyph\":{\"id\":\"85988\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"85994\"},\"nonselection_glyph\":{\"id\":\"85991\"},\"view\":{\"id\":\"85998\"}},\"id\":\"85997\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"85995\",\"type\":\"LinearColorMapper\"}],\"root_ids\":[\"85977\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "  const render_items = [{\"docid\":\"f6b68e80-42ca-4ec7-9b7e-fd282f4fae64\",\"root_ids\":[\"85977\"],\"roots\":{\"85977\":\"e1ee2c6f-68cd-46fd-8edb-124525d20be8\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "85977"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"2988fe4f-c382-415a-b397-edeb1ff07174\" data-root-id=\"87149\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"919a6131-c437-4518-b401-4e58e4d1eddb\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"above\":[{\"id\":\"87171\"}],\"left\":[{\"id\":\"87174\"}],\"renderers\":[{\"id\":\"87169\"}],\"title\":{\"id\":\"88281\"},\"toolbar\":{\"id\":\"87158\"},\"x_range\":{\"id\":\"87150\"},\"x_scale\":{\"id\":\"87154\"},\"y_range\":{\"id\":\"87152\"},\"y_scale\":{\"id\":\"87156\"}},\"id\":\"87149\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"87158\",\"type\":\"Toolbar\"},{\"attributes\":{\"color_mapper\":{\"id\":\"87164\"},\"dh\":{\"value\":33},\"dw\":{\"value\":32},\"global_alpha\":{\"value\":0.1},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"87163\",\"type\":\"Image\"},{\"attributes\":{},\"id\":\"88285\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"color_mapper\":{\"id\":\"87167\"},\"dh\":{\"value\":33},\"dw\":{\"value\":32},\"global_alpha\":{\"value\":0.2},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"87166\",\"type\":\"Image\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"87161\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"88284\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"88287\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"88288\",\"type\":\"Selection\"},{\"attributes\":{\"axis_label\":\"source tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"88285\"},\"group\":null,\"major_label_orientation\":45,\"major_label_overrides\":{\"0.5\":\"_BOS_\",\"1.5\":\"\\u0430\\u043f\\u0430\\u0440\\u0442\\u0430\\u043c\\u0435\\u043d\\u0442\\u044b\",\"10.5\":\"\\u0441\\u0430\\u0434\\u043e\\u043c\",\"11.5\":\",\",\"12.5\":\"\\u043a\\u043e\\u043d\\u0434\\u0438\\u0446\\u0438\\u043e\\u043d\\u0435\\u0440\\u043e\\u043c\",\"13.5\":\"\\u0438\",\"14.5\":\"\\u0442\\u0435\\u0440\\u0440\\u0430\\u0441\\u043e\\u0439\",\"15.5\":\"\\u0434\\u043b\\u044f\",\"16.5\":\"\\u0437\\u0430\\u0433\\u0430\\u0440\\u0430\",\"17.5\":\"\\u0440\\u0430\\u0441\\u043f\\u043e\\u043b\\u043e\\u0436\\u0435\\u043d\\u044b\",\"18.5\":\"\\u0432\",\"19.5\":\"5\",\"2.5\":\"\\u0432\",\"20.5\":\"\\u043c\\u0438\\u043d\\u0443\\u0442\\u0430\\u0445\",\"21.5\":\"\\u0445\\u043e\\u0434\\u044c\\u0431\\u044b\",\"22.5\":\"\\u043e\\u0442\",\"23.5\":\"\\u043f\\u043b\\u044f\\u0436\\u0430\",\"24.5\":\"\\u043d\\u0430\",\"25.5\":\"\\u043a\\u0443\\u0440\\u043e\\u0440\\u0442\\u0435\",\"26.5\":\"\\u043a\\u0430@@\",\"27.5\":\"\\u0431\\u043e\",\"28.5\":\"-\",\"29.5\":\"\\u0440\\u043e\\u0439\",\"3.5\":\"\\u043f\\u0435\\u043d\\u0442@@\",\"30.5\":\".\",\"31.5\":\"_EOS_\",\"4.5\":\"\\u0445\\u0430\\u0443\\u0441\\u0435\",\"5.5\":\"\\u0441\",\"6.5\":\"\\u043e\\u0431\\u0449\\u0438\\u043c\",\"7.5\":\"\\u043e\\u0442\\u043a\\u0440\\u044b\\u0442\\u044b\\u043c\",\"8.5\":\"\\u0431\\u0430\\u0441\\u0441\\u0435\\u0439\\u043d\\u043e\\u043c\",\"9.5\":\",\"},\"major_label_policy\":{\"id\":\"88286\"},\"ticker\":{\"id\":\"87172\"}},\"id\":\"87171\",\"type\":\"LinearAxis\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5,13.5,14.5,15.5,16.5,17.5,18.5,19.5,20.5,21.5,22.5,23.5,24.5,25.5,26.5,27.5,28.5,29.5,30.5,31.5]},\"id\":\"87172\",\"type\":\"FixedTicker\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"87164\",\"type\":\"LinearColorMapper\"},{\"attributes\":{\"end\":32},\"id\":\"87150\",\"type\":\"Range1d\"},{\"attributes\":{\"axis_label\":\"translation tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"88283\"},\"group\":null,\"major_label_overrides\":{\"0.5\":\"_EOS_\",\"1.5\":\".\",\"10.5\":\"conditioning\",\"11.5\":\"air\",\"12.5\":\"features\",\"13.5\":\"foot\",\"14.5\":\"on\",\"15.5\":\"apartment\",\"16.5\":\",\",\"17.5\":\"garden\",\"18.5\":\"spacious\",\"19.5\":\"a\",\"2.5\":\"terrace\",\"20.5\":\"in\",\"21.5\":\"villa\",\"22.5\":\"studio\",\"23.5\":\"a\",\"24.5\":\",\",\"25.5\":\"complex\",\"26.5\":\"hectare\",\"27.5\":\"-\",\"28.5\":\"7\",\"29.5\":\"a\",\"3.5\":\"sun\",\"30.5\":\"in\",\"31.5\":\"located\",\"32.5\":\"_BOS_\",\"4.5\":\"a\",\"5.5\":\"and\",\"6.5\":\"terrace\",\"7.5\":\"sun\",\"8.5\":\"a\",\"9.5\":\",\"},\"major_label_policy\":{\"id\":\"88284\"},\"ticker\":{\"id\":\"87175\"}},\"id\":\"87174\",\"type\":\"LinearAxis\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"87167\",\"type\":\"LinearColorMapper\"},{\"attributes\":{\"source\":{\"id\":\"87159\"}},\"id\":\"87170\",\"type\":\"CDSView\"},{\"attributes\":{\"data\":{\"image\":[{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[33,32]}]},\"selected\":{\"id\":\"88288\"},\"selection_policy\":{\"id\":\"88287\"}},\"id\":\"87159\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"88281\",\"type\":\"Title\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"87159\"},\"glyph\":{\"id\":\"87160\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"87166\"},\"nonselection_glyph\":{\"id\":\"87163\"},\"view\":{\"id\":\"87170\"}},\"id\":\"87169\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"88283\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"87156\",\"type\":\"LinearScale\"},{\"attributes\":{\"end\":33},\"id\":\"87152\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"87154\",\"type\":\"LinearScale\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5,13.5,14.5,15.5,16.5,17.5,18.5,19.5,20.5,21.5,22.5,23.5,24.5,25.5,26.5,27.5,28.5,29.5,30.5,31.5,32.5]},\"id\":\"87175\",\"type\":\"FixedTicker\"},{\"attributes\":{},\"id\":\"88286\",\"type\":\"AllLabels\"},{\"attributes\":{\"color_mapper\":{\"id\":\"87161\"},\"dh\":{\"value\":33},\"dw\":{\"value\":32},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"87160\",\"type\":\"Image\"}],\"root_ids\":[\"87149\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "  const render_items = [{\"docid\":\"919a6131-c437-4518-b401-4e58e4d1eddb\",\"root_ids\":[\"87149\"],\"roots\":{\"87149\":\"2988fe4f-c382-415a-b397-edeb1ff07174\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "87149"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div class=\"bk-root\" id=\"52f92c42-cefe-4ac0-8c2f-48a54666a40e\" data-root-id=\"88329\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"1817e6e9-2768-4ee7-a862-79b0906dab84\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"above\":[{\"id\":\"88351\"}],\"left\":[{\"id\":\"88354\"}],\"renderers\":[{\"id\":\"88349\"}],\"title\":{\"id\":\"89469\"},\"toolbar\":{\"id\":\"88338\"},\"x_range\":{\"id\":\"88330\"},\"x_scale\":{\"id\":\"88334\"},\"y_range\":{\"id\":\"88332\"},\"y_scale\":{\"id\":\"88336\"}},\"id\":\"88329\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"88334\",\"type\":\"LinearScale\"},{\"attributes\":{\"end\":23},\"id\":\"88330\",\"type\":\"Range1d\"},{\"attributes\":{\"color_mapper\":{\"id\":\"88344\"},\"dh\":{\"value\":20},\"dw\":{\"value\":23},\"global_alpha\":{\"value\":0.1},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"88343\",\"type\":\"Image\"},{\"attributes\":{},\"id\":\"89475\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"88347\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"89473\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"88336\",\"type\":\"LinearScale\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"88339\"},\"glyph\":{\"id\":\"88340\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"88346\"},\"nonselection_glyph\":{\"id\":\"88343\"},\"view\":{\"id\":\"88350\"}},\"id\":\"88349\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"88341\",\"type\":\"LinearColorMapper\"},{\"attributes\":{\"end\":20},\"id\":\"88332\",\"type\":\"Range1d\"},{\"attributes\":{\"data\":{\"image\":[{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[20,23]}]},\"selected\":{\"id\":\"89476\"},\"selection_policy\":{\"id\":\"89475\"}},\"id\":\"88339\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"89472\",\"type\":\"AllLabels\"},{\"attributes\":{\"coordinates\":null,\"group\":null},\"id\":\"89469\",\"type\":\"Title\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5,13.5,14.5,15.5,16.5,17.5,18.5,19.5,20.5,21.5,22.5]},\"id\":\"88352\",\"type\":\"FixedTicker\"},{\"attributes\":{\"axis_label\":\"translation tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"89471\"},\"group\":null,\"major_label_overrides\":{\"0.5\":\"_EOS_\",\"1.5\":\".\",\"10.5\":\"in\",\"11.5\":\"located\",\"12.5\":\"is\",\"13.5\":\"g\",\"14.5\":\"kru@@\",\"15.5\":\"ho\",\"16.5\":\"g@@\",\"17.5\":\"am\",\"18.5\":\"apartment\",\"19.5\":\"_BOS_\",\"2.5\":\"house\",\"3.5\":\"opera\",\"4.5\":\"the\",\"5.5\":\"from\",\"6.5\":\"metres\",\"7.5\":\"200\",\"8.5\":\",\",\"9.5\":\"moscow\"},\"major_label_policy\":{\"id\":\"89472\"},\"ticker\":{\"id\":\"88355\"}},\"id\":\"88354\",\"type\":\"LinearAxis\"},{\"attributes\":{\"color_mapper\":{\"id\":\"88347\"},\"dh\":{\"value\":20},\"dw\":{\"value\":23},\"global_alpha\":{\"value\":0.2},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"88346\",\"type\":\"Image\"},{\"attributes\":{\"axis_label\":\"source tokens\",\"coordinates\":null,\"formatter\":{\"id\":\"89473\"},\"group\":null,\"major_label_orientation\":45,\"major_label_overrides\":{\"0.5\":\"_BOS_\",\"1.5\":\"\\u0430\\u043f\\u0430\\u0440\\u0442\\u0430\\u043c\\u0435\\u043d\\u0442\\u044b\",\"10.5\":\"square\",\"11.5\":\"\\u043d\\u0430\\u0445\\u043e\\u0434\\u044f\\u0442\\u0441\\u044f\",\"12.5\":\"\\u0432\",\"13.5\":\"\\u043c\\u043e\\u0441\\u043a\\u0432\\u0435\",\"14.5\":\",\",\"15.5\":\"\\u0432\",\"16.5\":\"200\",\"17.5\":\"\\u043c\\u0435\\u0442\\u0440\\u0430\\u0445\",\"18.5\":\"\\u043e\\u0442\",\"19.5\":\"\\u0431\\u043e\\u043b\\u044c\\u0448\\u043e\\u0433\\u043e\",\"2.5\":\"mo@@\",\"20.5\":\"\\u0442\\u0435\\u0430\\u0442\\u0440\\u0430\",\"21.5\":\".\",\"22.5\":\"_EOS_\",\"3.5\":\"s@@\",\"4.5\":\"co@@\",\"5.5\":\"w\",\"6.5\":\"point\",\"7.5\":\"-\",\"8.5\":\"loft\",\"9.5\":\"red\"},\"major_label_policy\":{\"id\":\"89474\"},\"ticker\":{\"id\":\"88352\"}},\"id\":\"88351\",\"type\":\"LinearAxis\"},{\"attributes\":{\"color_mapper\":{\"id\":\"88341\"},\"dh\":{\"value\":20},\"dw\":{\"value\":23},\"image\":{\"field\":\"image\"},\"x\":{\"value\":0},\"y\":{\"value\":0}},\"id\":\"88340\",\"type\":\"Image\"},{\"attributes\":{\"source\":{\"id\":\"88339\"}},\"id\":\"88350\",\"type\":\"CDSView\"},{\"attributes\":{\"ticks\":[0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5,13.5,14.5,15.5,16.5,17.5,18.5,19.5]},\"id\":\"88355\",\"type\":\"FixedTicker\"},{\"attributes\":{},\"id\":\"89474\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"89471\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"palette\":[\"#000000\",\"#252525\",\"#525252\",\"#737373\",\"#969696\",\"#bdbdbd\",\"#d9d9d9\",\"#f0f0f0\",\"#ffffff\"]},\"id\":\"88344\",\"type\":\"LinearColorMapper\"},{\"attributes\":{},\"id\":\"88338\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"89476\",\"type\":\"Selection\"}],\"root_ids\":[\"88329\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "  const render_items = [{\"docid\":\"1817e6e9-2768-4ee7-a862-79b0906dab84\",\"root_ids\":[\"88329\"],\"roots\":{\"88329\":\"52f92c42-cefe-4ac0-8c2f-48a54666a40e\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "88329"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    draw_attention(inp[i], trans[i], attention_probs[i])\n",
    "    \n",
    "# Does it look fine already? don't forget to save images for anytask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note 1:__ If the attention maps are not iterpretable, try starting encoder from zeros (instead of dec_start), forcing model to use attention.\n",
    "\n",
    "__Note 2:__ If you're studying this course as a YSDA student, please submit __attention screenshots__ alongside your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbIIngNVlrtt"
   },
   "source": [
    "## Goind deeper (2++ points each)\n",
    "\n",
    "We want you to find the best model for the task. Use everything you know.\n",
    "\n",
    "* different recurrent units: rnn/gru/lstm; deeper architectures\n",
    "* bidirectional encoder, different attention methods for decoder (additive, dot-product, multi-head)\n",
    "* word dropout, training schedules, anything you can imagine\n",
    "* replace greedy inference with beam search\n",
    "\n",
    "For a better grasp of seq2seq We recommend you to conduct at least one experiment from one of the bullet-points or your alternative ideas. As usual, describe what you tried and what results you obtained in a short report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2rzAj_xtlrtt"
   },
   "source": [
    "`[your report/log here or anywhere you please]`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "edk_oVg0lrtW"
   ],
   "name": "practice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
